{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoML_LAMPS.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PaCxQYCA9GMU",
        "hK5qjZlW9lVs",
        "FwlsvGoDrgqy",
        "suyGXvdRGxrv",
        "4yQWX7QTB7Ce",
        "FgNFL-HsCE5F",
        "Uel3kCnHG88v",
        "meKxSv8JIf6o",
        "9N2JZ3-XIpkG",
        "9_rDfUP5I7Ki",
        "zUl7jFBCybn9",
        "w3RSl536yrnr",
        "HQfhsuf3tCCK",
        "cXhEUYWdi1CR",
        "4746jxTL6E4A",
        "l8b30PZF6PsY",
        "Dryt48K_616G",
        "moLrGBBi7AaY",
        "NDLUCiNi7T-G",
        "KWd32Qtz7irF",
        "oveqB1fDhyX3"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniciuswv/AutoML---Classification-of-Electrical-Charges-in-Smart-Grid/blob/main/AutoML_LAMPS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xzq_sjVd7llk"
      },
      "source": [
        "![Logo PPGEN.png](data:image/png;base64,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)\n",
        "\n",
        "_____\n",
        "**Programa de Pós-graduação em Energia - PPGEN   |   Universidade Federal do Espírito Santo - UFES**\n",
        "_____\n",
        "**As part of the dissertation:** \"*Automated adjustment of hyperparameters in convolutional neural network to identify similar electrical loads in smart grid.*\"\n",
        "_____\n",
        "**Developers:**\n",
        "Vinicius Wittig Vianna (PPGEN) - viniciuswv@gmail.com;\n",
        "Wanderley Cardoso Celeste (DCEL/PPGEN) - wanderley.celeste@ufes.br;\n",
        "Helder Roberto de Oliveira (DEE/PPGEE) - helder.rocha@ufes.br;\n",
        "Leonardo Jose Silvestre (DCEL) - leonardo.silvestre@ufes.br\n",
        "_____\n",
        "This code was developed as a dissertation project by (VIANNA, 2021), for the implementation and investigation of an two stages based optimization for automatically configuring a hyperparameters set of interest in the convolutional neural network (CNN) originally developed in (FIRMES, 2020), whose objective is to classify 16 possible combinations of two types of highly similar electrical charges (lamps and PCs) on a test bench.\n",
        "\n",
        "\n",
        "**Abstract:**\n",
        "\n",
        "*  The first step is to apply the Hill Climb(down) optimization, in order to investigate how far it is possible to reduce the data (organized in \"cases\") while maintaining the network's **test accuracy** greater than or equal to 95%.\n",
        "\n",
        "*  The second step is to apply the Bayesian optimization, in order to investigate whether it's possible to make the network **valid accuracy** close to 100%, by automatically selecting a good set of hyperparameters.\n",
        "\n",
        "*  Was necessary to adjust some network learning parameters to improve the robustness and stability during training and validation, otherwise, the Hillclimb optimizer could be stuck in a local minimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaCxQYCA9GMU"
      },
      "source": [
        "# 1.Libraries and frameworks import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiYqNlQtQ9ds"
      },
      "source": [
        "Import of the necessary tools and verification of the graphics card provided by Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uvnL9fA8ukk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e6fa16-2a3d-434f-db77-cd95b68c8fde"
      },
      "source": [
        "# Canceling miscellaneous cautions:\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        " \n",
        "# General modeling in the dataset:\n",
        "!pip install pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import random as python_random\n",
        "import scipy.io\n",
        "import time\n",
        "import datetime\n",
        "from numpy import array\n",
        "from decimal import Decimal\n",
        "from numpy import savetxt\n",
        " \n",
        "# Data pre-processing methods:\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        " \n",
        "# Conversion of vectors into a binary class matrix:\n",
        "from keras.utils import to_categorical\n",
        " \n",
        "# Indexing of samples for training, validation and test:\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "# Neural network architecture (TensorFlow and Keras):\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import backend\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.models import load_model\n",
        "from tensorflow.python.keras.layers import *\n",
        "from tensorflow.python.keras.callbacks import *\n",
        "from tensorflow.python.keras.optimizers import *\n",
        "\n",
        "# Scikit-optimize (2nd stage of optimization):\n",
        "!pip install scikit-optimize\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from skopt.utils import use_named_args\n",
        "import skopt.plots\n",
        "from skopt import callbacks\n",
        "from skopt.callbacks import CheckpointSaver\n",
        "from skopt.callbacks import TimerCallback\n",
        " \n",
        "# Confusion matrix:\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import itertools\n",
        " \n",
        "# Plotting tools:\n",
        "!pip install matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.ticker as ticker\n",
        "from keras.utils.vis_utils import plot_model\n",
        " \n",
        "# TensorDash (to check metrics by \"TensorDash\" Android app):\n",
        "!pip install tensor-dash\n",
        "from tensordash.tensordash import Tensordash"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/03/be33e89f55866065a02e515c5b319304a801a9f1027a9b311a9b1d1f8dc7/scikit_optimize-0.8.1-py2.py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 6.9MB/s \n",
            "\u001b[?25hCollecting pyaml>=16.9\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-20.4.0 scikit-optimize-0.8.1\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Collecting tensor-dash\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/a7/d6714fea01209936e23bdd1db91c61c94a8f6ee718fede28afbff63241d4/tensor_dash-1.8.1-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from tensor-dash) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tensor-dash) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tensor-dash) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tensor-dash) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tensor-dash) (2.10)\n",
            "Installing collected packages: tensor-dash\n",
            "Successfully installed tensor-dash-1.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSZ-f9TZu4jo"
      },
      "source": [
        "**Verification of the graphics card (GPU):**\r\n",
        "*   If hardware acelerator option is \"on\", then it's expected a Tesla T4, P100 or V100 models (V100>P100>T4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn9UYoeZ9wUX",
        "outputId": "2cad3852-6e27-45a6-8d9b-fd80f31ec96f"
      },
      "source": [
        "# Verificando o modelo da GPU utilizada:\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 8452918755871735275, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15469833088\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 2363986398490055896\n",
              " physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK5qjZlW9lVs"
      },
      "source": [
        "# 2.Dataset import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqublYYYXNcb"
      },
      "source": [
        "* The dataset is imported directly from Google Drive, just mount the virtual drive and establish the path of the root folder.\n",
        "\n",
        "* Already loaded, the Pandas dataframe object (tabular data) is converted to Numpy array (two-dimensional matrix)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzsZuqfn9XiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c42023c5-81ec-4a2c-afeb-0fd93d9a2a14"
      },
      "source": [
        "# Módulo de importação de dados a partir do Google Drive:\n",
        "from google.colab import drive\n",
        "# Montando o Google Drive na máquina virtual do Colaboratory:\n",
        "drive.mount('/content/drive')\n",
        " \n",
        "# Importação do dataset original de corrente das lâmpadas:\n",
        "path = '/content/drive/My Drive/MESTRADO - UFES/Bancos de dados/Banco de dados A1_0 lampadas/modeled_current/'\n",
        "\n",
        "path = path + 'current.csv'\n",
        "\n",
        "allData  = pd.read_csv(path, delimiter=';')\n",
        " \n",
        "# Transformação do dataframe em array:\n",
        "data0 = np.asarray(allData)\n",
        "\n",
        "# Adequação do tamanho total da base de dados:\n",
        "data = data0[0:999600, :]\n",
        " \n",
        "# Verificação do shape requerido:\n",
        "print('\\nThe matrix shape is:',data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "The matrix shape is: (999600, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwlsvGoDrgqy"
      },
      "source": [
        "# 3.First stage architecture (subset, model , train/test and optimizer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2vNcB00c7Ng"
      },
      "source": [
        "**In this section, the functions responsible for the subset, train and optimization of CNN are implemented:**\n",
        "\n",
        "\n",
        "* 3.1 (subset) Function that makes the subset ordered according to the number of cases required;\n",
        "* 3.2 (create_model) Function that creates the model and saves its architecture and initial weights;\n",
        "* 3.3 (fit_model) Function that trains and validates the created model;\n",
        "* 3.4 (test_model) Function that tests the model created and trained;\n",
        "* 3.5 (hillclimb) Function that uses the Hill Climbing heuristic to minimize the cost (test accuracy)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suyGXvdRGxrv"
      },
      "source": [
        "## 3.1 Preprocessing and subset function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaWKvmU2ONsl"
      },
      "source": [
        "**Observations:**\r\n",
        "\r\n",
        "*   The data manipulation and the labels creation are the same as in (FIRMES, 2020).\r\n",
        "* It was designed two strategies (investigation purposes) for the dataset processing:\r\n",
        " \r\n",
        "\r\n",
        "1.   Preprocessing BEFORE the data subset;\r\n",
        "2.   Preprocessing AFTER the data subset.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yQWX7QTB7Ce"
      },
      "source": [
        "### 3.1.1 Preprocessing BEFORE subset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UE5t_nQIKAu",
        "outputId": "e8a1d998-c9d0-4643-e5f3-8665cfa450e8"
      },
      "source": [
        "# PRÉ-PROCESSAMENTO ANTES DO SUBSET:\n",
        "# Processamento da base de dados (Normalização do conjunto inteiro):\n",
        "# O detalhamento deste processamento está na dissertação.\n",
        " \n",
        "data_transp = data.transpose() # Transposição: (999600,16) para (16,999600)\n",
        "# (Cuidado com o transpose. Se rodar a célula mais de uma vez, ele volta para a\n",
        "#  forma original da matriz e então dá erro!)\n",
        "\n",
        "# Redução dos dados para exatamente 999600 linhas (Verificar FIRMES, 2020):\n",
        "data_adj = data_transp[:, 0:999600]\n",
        "\n",
        "print('The transposed shape is:', data_adj.shape)\n",
        " \n",
        "data3d = data_adj.reshape(16, 600, 1666) # Reshape matriz 2D para 3D.\n",
        " \n",
        "# Criação dos labels:\n",
        "allData = np.empty((0,1667))\n",
        "ones = np.ones(600)\n",
        "\n",
        "# Separa os dados, atribuindo os labels das classes:\n",
        "for i in range(0, 16):\n",
        "  labels = i * ones\n",
        "  dataClass = data3d[i,:,:]\n",
        "  dataClass = np.column_stack((dataClass,labels))\n",
        "  allData = np.vstack((allData,dataClass))\n",
        " \n",
        "X = allData[:,:-1] # Fatia: todas as linhas, todas as colunas (menos a última).\n",
        "Y = allData[:,-1] # Fatia: todas as linhas, só a última coluna.\n",
        "\n",
        "# Procedimento para normalização/padronização da base como um todo:\n",
        "# Serão investigados três tipos de pré-processamento:\n",
        "scaler = StandardScaler()\n",
        "minmax = MinMaxScaler()\n",
        "powert = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "\n",
        "# Teste dos pré-processadores:-------------------------------------------------\n",
        "#Xt = minmax.fit_transform(X) # Testando com o método MinMaxScaler...\n",
        "Xt = scaler.fit_transform(X) # Testando com o método StandardScaler...\n",
        "#Xt = powert.fit_transform(X)  # Testando com o método PowerTransformer...\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "print('The preprocessed (Xt) data shape is:', Xt.shape)\n",
        "\n",
        "Xt  # Verificação breve dos dados pré-processados..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The transposed shape is: (16, 999600)\n",
            "The preprocessed (Xt) data shape is: (9600, 1666)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.47371101, 1.47380066, 1.47363811, ..., 1.47366888, 1.47383405,\n",
              "        1.47364487],\n",
              "       [1.4738908 , 1.47380066, 1.47381792, ..., 1.47402841, 1.47365428,\n",
              "        1.47382466],\n",
              "       [1.4738908 , 1.47371076, 1.47390782, ..., 1.47375876, 1.47374416,\n",
              "        1.47373476],\n",
              "       ...,\n",
              "       [1.47784629, 1.47613811, 1.47750408, ..., 1.47726415, 1.47662054,\n",
              "        1.47589217],\n",
              "       [1.47712711, 1.47649771, 1.47615549, ..., 1.47717427, 1.47644077,\n",
              "        1.47715066],\n",
              "       [1.47766649, 1.47640781, 1.47696465, ..., 1.47600581, 1.47769918,\n",
              "        1.4767012 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbwA7-LW1oHK"
      },
      "source": [
        "Below it's presented the function that **subsets** data by cases quantity:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqtfapuTycvo"
      },
      "source": [
        "# Função que faz o subset balanceado no dataset e nos labels criados:\n",
        "\n",
        "def subset(X, Y, n_cases):\n",
        "  '''\n",
        "  X: dataset pré-processado.\n",
        "  Y: labels criados.\n",
        "  n_cases: nº de casos que se deseja manter para cada classe.\n",
        "  '''\n",
        "  \n",
        "  Xnew = [] # Armazena o subset da base de dados.\n",
        "  Ynew = [] # Armazena o subset dos rótulos criados.\n",
        "  \n",
        "  # De cada classe (600 linhas), reduz conforme a quantidade de CASOS requerida.\n",
        "  for i in range(0, 9600, 600):\n",
        "    for j in X[i:i+n_cases]:\n",
        "      Xnew.append(j) # Adiciona os dados na nova lista.\n",
        "  \n",
        "  Xsubset = np.asarray(Xnew) # Transforma a lista em array, novamente.\n",
        "\n",
        "  # De cada classe (600 linhas), reduz conforme a quantidade de LABELS requerida.\n",
        "  for i in range(0, 9600, 600):\n",
        "    for j in Y[i:i+n_cases]:\n",
        "      Ynew.append(j) # Adiciona os dados na nova lista.\n",
        "  \n",
        "  Ysubset = np.asarray(Ynew) # Transforma a lista em array, novamente.\n",
        "\n",
        "  # Converte Y (labels) para categórico:\n",
        "  #(Isto é, converte o vetor de classe (inteiros) em matriz de classe binária)\n",
        "  Ysubset = to_categorical(Ysubset)\n",
        " \n",
        "  # Separação das amostras de treinamento, validação e teste:\n",
        "  # Indexação de 20% para TESTE:\n",
        "  X_train_val, X_test, Y_train_val, Y_test = train_test_split(Xsubset,\n",
        "                                                              Ysubset,\n",
        "                                                              test_size=0.20,\n",
        "                                                              random_state=42)\n",
        "  \n",
        "  # Do TREINAMENTO, indexa 20% para VALIDAÇÃO:\n",
        "  X_train, X_val, Y_train, Y_val = train_test_split(X_train_val,\n",
        "                                                    Y_train_val,\n",
        "                                                    test_size=0.20,\n",
        "                                                    random_state=42)\n",
        " \n",
        "  X_train = X_train.astype('float32')\n",
        "  X_val = X_val.astype('float32')\n",
        " \n",
        "  # Reshape das dimensões de X_train, X_val e X_test para se adequar à CNN:\n",
        "  X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
        "  X_val = X_val.reshape(X_val.shape[0],X_val.shape[1],1)\n",
        "  X_test = X_test.reshape(X_test.shape[0], X_test.shape[1],1)\n",
        " \n",
        "  return X_train, Y_train, X_val, Y_val, X_test, Y_test, n_cases\n",
        "\n",
        "\n",
        "# Caso queira testar a função:\n",
        "#X_train, Y_train, X_val, Y_val, X_test, Y_test, n_cases = subset(Xt, Y, 600)\n",
        "#print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape, n_cases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQgdpRsJxaNO"
      },
      "source": [
        "**Don't need to run this next cell!**\r\n",
        "\r\n",
        "Was conduced an **experiment** solicited by Wanderley. The pre-processing method here was not applied directly in the whole dataset, but in \"case-by-case\" method. Was expected this method could handle better with the data, but this hipothesis couldn't be proved (low accuracy was identified).\r\n",
        "\r\n",
        "**Obs.:** This piece of code was left here in case of any experiments with different types of preprocessing in future works (and it took a lot of time to develop too :D)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMu1MpXLvB2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "063b5af3-d409-46b6-c61b-a2b1ff349785"
      },
      "source": [
        "# Processamento da base de dados (Normalização de caso em caso):\n",
        "# O detalhamento deste processamento está na dissertação.\n",
        " \n",
        "data_transp2 = data.transpose() # Transposição: (999600,16) para (16,999600)\n",
        "\n",
        "data_adj2 = data_transp2[:, 0:999600] # Reduzindo o dataset para exatamente 999600 amostras.\n",
        "\n",
        "print('The transposed shape is:', data_adj2.shape)\n",
        "\n",
        "data3d2 = data_adj2.reshape(16, 600, 1666) # Reshape matriz 2D para 3D.\n",
        "# (Cuidado com o transpose. Se rodar a célula mais de uma vez, ele volta para a\n",
        "#  forma original da matriz e então dá erro!)\n",
        " \n",
        "# Criação dos labels:\n",
        "allData = np.empty((0,1667))\n",
        "ones = np.ones(600)\n",
        "\n",
        "# Separa os dados, atribuindo os rótulos das classes:\n",
        "for i in range(0, 16):\n",
        "  labels = i * ones\n",
        "  dataClass = data3d2[i,:,:]\n",
        "  dataClass = np.column_stack((dataClass,labels))\n",
        "  allData = np.vstack((allData,dataClass))\n",
        " \n",
        "X = allData[:,:-1] # Fatia: todas as linhas, todas as colunas (menos a última).\n",
        "Y = allData[:,-1] # Fatia: todas as linhas, só a última coluna.\n",
        "\n",
        "# Procedimento para normalização/padronização a cada caso (1666 amostras):\n",
        "# Serão investigados três tipos de pré-processamento:\n",
        "scaler = StandardScaler()\n",
        "minmax = MinMaxScaler()\n",
        "powertr = PowerTransformer()\n",
        "\n",
        "Xn = [] # Lista que armazena os casos normalizados.\n",
        "Xs = [] # Lista que armazena os casos padronizados.\n",
        "Xp = [] # Lista que armazena os casos padronizados.\n",
        "\n",
        "# Padronizando/normalizando de caso em caso (cada 1666 amostras):\n",
        "for i in range(0,9600):\n",
        "  Xi = X[i,:]\n",
        "  Xi = Xi.reshape((-1,1)) # Reshape p/ adequar a entrada à ferramenta.\n",
        "  Zminmax = minmax.fit_transform(Xi)\n",
        "  Xn.append(Zminmax) # Atualiza a respectiva lista.\n",
        "  Zscaler = scaler.fit_transform(Xi)\n",
        "  Xs.append(Zscaler) # Atualiza a respectiva lista.\n",
        "  Zpower = powertr.fit_transform(Xi)\n",
        "  Xp.append(Zpower) # Atualiza a respectiva lista.\n",
        "\n",
        "Xn = np.asarray(Xn).reshape((9600, 1666)) # Transforma a lista em array, novamente.\n",
        "Xs = np.asarray(Xs).reshape((9600, 1666)) # Transforma a lista em array, novamente.\n",
        "Xp = np.asarray(Xp).reshape((9600, 1666)) # Transforma a lista em array, novamente.\n",
        "\n",
        "print('The standardized (Xs) data shape is:', Xs.shape,\n",
        "      '\\nThe normalized (Xn) data shape is:', Xn.shape,\n",
        "      '\\nThe transformed (Xp) data shape is:', Xp.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The transposed shape is: (16, 999600)\n",
            "The standardized (Xs) data shape is: (9600, 1666) \n",
            "The normalized (Xn) data shape is: (9600, 1666) \n",
            "The transformed (Xp) data shape is: (9600, 1666)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6QWZIpd3wae"
      },
      "source": [
        "Below it's only a sketch of the \"balanced subset\" design, that was applied to the main function (above). Was left here for general purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCr890bEfKvY",
        "outputId": "7add67cf-4abf-4360-a019-ef024b758b5b"
      },
      "source": [
        "# Teste do raciocínio para redução balanceada de amostras e labels de cada classe:\n",
        "\n",
        "uns = np.ones(600)\n",
        "empty = np.empty(600)\n",
        "Yzn = []\n",
        "for i in range(0,16):\n",
        "  Yz = i*uns\n",
        "  Yzn.append(Yz)\n",
        "\n",
        "# Reshape dos labels criados:\n",
        "Yzn = np.asarray(Yzn).reshape((9600,1))\n",
        "\n",
        "Yzn_ = [] # Armazena o subset dos labels criados.\n",
        "\n",
        "for i in range(0, 9600, 600):\n",
        "    for j in Yzn[i:i+1]: # O último dígito é a qtde. de casos que deseja manter.\n",
        "      Yzn_.append(j) # Adiciona os dados na nova lista.\n",
        "  \n",
        "Yznsubset = np.asarray(Yzn_) # Transforma a lista em array, novamente.\n",
        "\n",
        "Yznsubset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.],\n",
              "       [ 1.],\n",
              "       [ 2.],\n",
              "       [ 3.],\n",
              "       [ 4.],\n",
              "       [ 5.],\n",
              "       [ 6.],\n",
              "       [ 7.],\n",
              "       [ 8.],\n",
              "       [ 9.],\n",
              "       [10.],\n",
              "       [11.],\n",
              "       [12.],\n",
              "       [13.],\n",
              "       [14.],\n",
              "       [15.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgNFL-HsCE5F"
      },
      "source": [
        "### 3.1.2 Preprocessing AFTER subset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRGh8yXjRoDF"
      },
      "source": [
        "# FUNÇÃO QUE FAZ O SUBSET E PREPARAÇÃO DO BANCO DE DADOS (EXATAMENTE COMO O VICTOR FEZ):\r\n",
        "\r\n",
        "def subsetB(cases_num):\r\n",
        "  '''\r\n",
        "  cases_num: qtde. de casos que se deseja manter;\r\n",
        "  Retorna os inputs de treinamento/validação/teste para a CNN;\r\n",
        "  Preparação dos dados exatamente como realizado em FIRMES, 2020;\r\n",
        "  A rejeição dos casos é feita antes da preparação dos dados para a CNN\r\n",
        "  simulando uma situação real de coleta de poucas amostras/casos.\r\n",
        "  '''\r\n",
        "  \r\n",
        "  n_cases = cases_num  # Armazena a qtde. de casos utilizada para insights mais à frente.\r\n",
        " \r\n",
        "  data_transp = data.transpose() # Transposição - (999600,16) para (16,999600)\r\n",
        "\r\n",
        "  data_sub = data_transp[:,:(1666 * cases_num)] # Fatiamento de colunas de acordo com a qtde. de casos requerida.\r\n",
        " \r\n",
        "  dataf = data_sub.reshape(16, cases_num, 1666) # Reshape matriz 2D para 3D (considerando casos totais)\r\n",
        " \r\n",
        "  # Criação dos labels:\r\n",
        "  allData = np.empty((0,1667))\r\n",
        "  ones = np.ones(cases_num)\r\n",
        "  # Separa os dados, atribuindo rótulo:\r\n",
        "  for i in range(0,16):\r\n",
        "    labels = i * ones\r\n",
        "    dataClass = dataf[i,:,:]\r\n",
        "    dataClass = np.column_stack((dataClass,labels))\r\n",
        "    allData = np.vstack((allData,dataClass))\r\n",
        " \r\n",
        "  X = allData[:,:-1] # Todas as linhas, todas as colunas (menos a última)\r\n",
        "  Y = allData[:,-1] # Todas as linhas, \r\n",
        " \r\n",
        "  # Normalização dos dados:\r\n",
        "  #(Transforma os dados para média zero e desvio padrão igual a um)\r\n",
        "  scaler = StandardScaler()\r\n",
        "  X = scaler.fit_transform(X)\r\n",
        " \r\n",
        "  # Converte Y para categórico:\r\n",
        "  #(Converte o vetor de classe (inteiros) em matriz de classe binária)\r\n",
        "  Y = to_categorical(Y)\r\n",
        " \r\n",
        "  # Separação das amostras de treinamento, validação e teste:\r\n",
        "  # Indexação de 20% para TESTE:\r\n",
        "  X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\r\n",
        "  # Do TREINAMENTO, indexa 20% para VALIDAÇÃO:\r\n",
        "  X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.20, random_state=42)\r\n",
        " \r\n",
        "  X_train = X_train.astype('float32')\r\n",
        "  X_val = X_val.astype('float32')\r\n",
        " \r\n",
        "  # Reshape das dimensões de X_train, X_val e X_test para se adequar à CNN:\r\n",
        "  X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\r\n",
        "  X_val = X_val.reshape(X_val.shape[0],X_val.shape[1],1)\r\n",
        "  X_test = X_test.reshape(X_test.shape[0], X_test.shape[1],1)\r\n",
        " \r\n",
        "  return X_train, Y_train, X_val, Y_val, X_test, Y_test, n_cases\r\n",
        " \r\n",
        "# Caso queira testar a função:\r\n",
        "#X_train, Y_train, X_val, Y_val, X_test, Y_test, n_cases = subsetB(600)\r\n",
        "#print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape, n_cases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uel3kCnHG88v"
      },
      "source": [
        "## 3.2 Model function (create_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uZLBINdTTdw"
      },
      "source": [
        "* It was necessary to implement the strategy of save the initially created model and upload it again, each round. Otherwise, the network continues to train its weights, causing the accuracy to be maintained even with the reduction of cases.\n",
        "\n",
        "\n",
        "* Therefore, the model created here (with all its information) is stored in its specific folder in Google Drive and, subsequently, the optimizer loads this same standard model each round."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujhpgi3Nyr0K"
      },
      "source": [
        "# Parâmetros para o Callbacks:\r\n",
        "\r\n",
        "# Determinando o caminho onde os parâmetros calculados serão salvos:\r\n",
        "checkpoint_filepath = '/content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current'\r\n",
        "# Salvando o modelo após cada época:\r\n",
        "checkpoint = ModelCheckpoint(filepath = checkpoint_filepath,\r\n",
        "                             monitor = 'val_accuracy', verbose = 1,\r\n",
        "                             mode = 'max', save_best_only = True)\r\n",
        "\r\n",
        "# EarlyStopping (O modelo pára o treinamento caso não perceba melhoria):\r\n",
        "earlystopping = EarlyStopping(monitor=\"val_accuracy\", min_delta=0, patience=100,\r\n",
        "                              verbose=1, mode=\"auto\", baseline=None,\r\n",
        "                              restore_best_weights=True)\r\n",
        "\r\n",
        "# Reduce LR on Plateau (Taxa de aprendizado reduzirá se não houver melhorias):\r\n",
        "#reducplateau = ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.9, patience=10,\r\n",
        "#                                 verbose=1, mode=\"auto\", min_delta=0.0001,\r\n",
        "#                                 cooldown=0, min_lr=0)\r\n",
        "\r\n",
        "# TensorDash (acompanhamento das métricas do modelo pelo app Android):\r\n",
        "histories = Tensordash(ModelName = 'AutoML', email = 'viniciuswv@gmail.com',\r\n",
        "                       password = 'admin1')\r\n",
        "\r\n",
        "# Batch size (número de exemplos de treinamento usados em uma iteração/época):\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# Épocas (quantidade de ciclos de treinamento da rede neural):\r\n",
        "epochs = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsTiA-whzJQS"
      },
      "source": [
        "# FUNÇÃO QUE CRIA A CNN:\n",
        "def create_model():\n",
        "  'Retorna o objeto (modelo), que estará sujeito à fitness function.'\n",
        "  'CNN de arquitetura nº 3 (FIRMES, 2020).'\n",
        "\n",
        "  # Criação das camadas com apoio do recurso 'keras.sequential':\n",
        "  model = Sequential() # Empilha linearmente as camadas da rede, conforme abaixo:\n",
        "  # Camada de alimentação do dataset:\n",
        "  model.add(InputLayer(input_shape=(1666,1))) # O tensor de entrada tem o shape (1666, 1).\n",
        " \n",
        "  # 1ª camada convolucional:\n",
        "  model.add(Conv1D(32, kernel_size=4, strides=1, activation='relu', padding='same'))\n",
        "  # 1ª camada MaxPooling:\n",
        "  model.add(MaxPooling1D(pool_size=3, strides=None, padding='valid'))\n",
        "  # 1ª camada de normalização do batch:\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  # 2ª camada convolucional:\n",
        "  model.add(Conv1D(64, kernel_size=4, strides=1, activation='relu', padding='same'))\n",
        "  # 2ª camada MaxPooling:\n",
        "  model.add(MaxPooling1D(pool_size=3, strides=None, padding='valid'))\n",
        "  # 2ª camada de normalização do batch:\n",
        "  model.add(BatchNormalization())\n",
        " \n",
        "  # 3ª camada convolucional:\n",
        "  model.add(Conv1D(128, kernel_size=4, strides=1, activation='relu', padding='same'))\n",
        "  # 3ª camada de MaxPooling:\n",
        "  model.add(MaxPooling1D(pool_size=3, strides=None, padding='valid'))\n",
        "  # 3ª camada de normalização do batch:\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  # 4ª camada convolucional:\n",
        "  model.add(Conv1D(256, kernel_size=4, strides=1, activation='relu', padding='same'))\n",
        "  # 4ª camada de MaxPooling:\n",
        "  model.add(MaxPooling1D(pool_size=3, strides=None, padding='valid'))\n",
        "  # 4ª camada de normalização do batch:\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  # Camada de achatamento (flatten):\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # 1ª camada densa (fully connected):\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  # 2ª camada densa (fully connected):\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  # 3ª camada densa (fully connected):\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  # 4ª camada densa (fully connected):\n",
        "  model.add(Dense(16, activation='softmax'))\n",
        "\n",
        "  \n",
        "  # Programação manual da Taxa de Aprendizado (decaimento exponencial):\n",
        "  lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "  initial_learning_rate=1e-2,\n",
        "  decay_steps=50,\n",
        "  decay_rate=0.95)\n",
        "\n",
        "\n",
        "  # Otimizador da rede:\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate= lr_schedule, name=\"SGD\")\n",
        "\n",
        "\n",
        "  # Compilação do modelo neural: \n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer= optimizer,\n",
        "                metrics=['accuracy'])\n",
        " \n",
        "  return model\n",
        " \n",
        "# Criação do modelo e verificação de seu sumário:\n",
        "model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjhJVmYz0ohu"
      },
      "source": [
        "# (Lâmpadas) Determinando o caminho para salvamento do modelo:\n",
        "save_path = '/content/drive/My Drive/MESTRADO - UFES/Bancos de dados/Banco de dados A1_0 lampadas/standard_cnn/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQdbR40i0vdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098c5701-3022-43e8-eecb-0ae96ae4e980"
      },
      "source": [
        "# Salvando o modelo e os pesos não treinados como referência para o looping:\n",
        "model.save(save_path,\n",
        "           overwrite = True,\n",
        "           save_format = 'initial_model_h5.h5') # ou 'tf'."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/MESTRADO - UFES/Bancos de dados/Banco de dados A1_0 lampadas/standard_cnn/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj9cksoVO3pc"
      },
      "source": [
        "The summary is important to compare the structure and the quantity of parameters in the (FIRMES, 2020) architecture with the new optimized architecture:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVpt8LokOoXW",
        "outputId": "d26f533a-3a2e-418f-d6c1-b732d00242d1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1666, 32)          160       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 555, 32)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 555, 32)           128       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 555, 64)           8256      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 185, 64)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 185, 64)           256       \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 185, 128)          32896     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 61, 128)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 61, 128)           512       \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 61, 256)           131328    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 20, 256)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 20, 256)           1024      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5120)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               2621952   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                2064      \n",
            "=================================================================\n",
            "Total params: 2,962,800\n",
            "Trainable params: 2,961,840\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meKxSv8JIf6o"
      },
      "source": [
        "## 3.3 Training function (train / validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWhjJTXVuw2V"
      },
      "source": [
        "# FUNÇÃO QUE TREINA O MODELO (train/validation):\n",
        "def fit_model(model, X_train, Y_train, X_val, Y_val, batch_size, epochs):\n",
        "  '''\n",
        "  Recebe o modelo, o dataset reduzido, o tamanho de batch e qtd. de épocas.\n",
        "  Retorna o modelo (treinado/validado), history e valor máx. de 'val_accuracy'.\n",
        "  '''\n",
        "  \n",
        "  # Reinicia a sessão do Keras, evitando sobrecarregamento de memória:\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  start_time = time.time()         # Parâmetro para tempo de treinamento.\n",
        "  \n",
        "  # Método \".fit()\" do Keras:\n",
        "  history = model.fit(X_train,\n",
        "                      Y_train,\n",
        "                      batch_size = batch_size,\n",
        "                      epochs = epochs,\n",
        "                      verbose = 1,\n",
        "                      validation_data = (X_val, Y_val),\n",
        "                      callbacks = [histories,\n",
        "                                   earlystopping,\n",
        "                                   ])\n",
        "   \n",
        "  accuracy = history.history['val_accuracy']\n",
        "   \n",
        "  acc_max = max(accuracy)           # Armazena a maior val_accuracy da lista.\n",
        " \n",
        "  end_time = time.time()            # Parâmetro para tempo de treinamento.\n",
        " \n",
        "  # Visualização do tempo total de treinamento:\n",
        "  print(\"Training/validation time was: %g seconds\" % (end_time - start_time))\n",
        "\n",
        "  train_time = (end_time - start_time)\n",
        " \n",
        "  return model, history, acc_max, train_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N2JZ3-XIpkG"
      },
      "source": [
        "## 3.4 Testing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMZED4DBrx8x"
      },
      "source": [
        "# FUNÇÃO QUE TESTA O MODELO:\n",
        "def test_model(X_test, Y_test, model):\n",
        "  'Recebe as amostras de teste e labels (X, Y), assim como o novo modelo gerado.'\n",
        "  'Retorna a acurácia de teste (é o parâmetro para continuar iterando).'\n",
        "  \n",
        "  print('\\n',\n",
        "        '\\nEVALUATING THE MODEL:')\n",
        "  \n",
        "  start_time = time.time()\n",
        " \n",
        "  scores = model.evaluate(X_test, Y_test, verbose=1, return_dict=False)\n",
        " \n",
        "  end_time = time.time()\n",
        " \n",
        "  print(\"Evaluate time was %g seconds\" % (end_time - start_time))\n",
        " \n",
        "  test_accuracy = (scores[1])  # Armazena apenas a acurácia do teste.\n",
        "  \n",
        "  print(test_accuracy)\n",
        " \n",
        "  return test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_rDfUP5I7Ki"
      },
      "source": [
        "## 3.5 Optimization function (Hill Climbdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWt71G_dgWJW"
      },
      "source": [
        "**This function consists of the following sub-functions:**\n",
        "\n",
        "1. Function that makes the subset;\n",
        "2. Command to load the standard CNN, with it's saved weights;\n",
        "3. Function that trains / validates CNN;\n",
        "4. Function that tests CNN;\n",
        "5. Fitness function for the iterative process of the Hill Climbdown heuristic.\n",
        "\n",
        "* As suggested by Professor Helder, we establish as fitness (cost, which will be minimized) the test accuracy itself!\n",
        "\n",
        "* The optimizer logic is based on the analysis of the neighboring solution, that is, at each round of case reduction, if the test accuracy is less than fitness (which starts at 1), fitness takes on this value and starts a new one round of case reduction and network training. This process is repeated until fitness (target accuracy) reaches 0.95 (95%).\n",
        "* The target accuracy was established at 95% because, according to the literature, in statistical tests a 95% confidence level can be admitted. Therefore, the idea is to take advantage of this \"gap\" to investigate how much we can reduce of the total dataset (FIRMES, 2020) due to the admitted statistical reliability.\n",
        "* **Important:** It can happen that the optimizer finds accuracy above 95% even with very low cases in the database. Accuracy alone cannot guarantee the robustness of the network under any circumstances. Therefore, a limit on the search space will be established, which means that the first stage will be able to reduce the data to up to 60 cases (10% of the total)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_1UYNC9tQI7"
      },
      "source": [
        "# FUNÇÃO DO OTIMIZADOR (DESCIDA DE ENCOSTA):\n",
        "def hillclimb():\n",
        "  'Reduz casos até que a acurácia de teste atinja um valor pré determinado.'\n",
        "  'Retorna o melhor modelo, históricos de fitness e redução de casos.'\n",
        " \n",
        "  acc_target = 0.95  # Qual a acurácia de teste alvo?\n",
        "  cases = 610        # Preencher com (600 + decrease step value utilizado).\n",
        "  fitness = 1    # Fitness inicia em 1 e irá descer.\n",
        "  \n",
        "  # Armazenamento das listas contendo o histórico da otimização:\n",
        "  fitness_hist = []\n",
        "  n_cases_hist = []\n",
        "  acc_val_hist = []\n",
        "  acc_test_hist = []\n",
        "  time_hist = []\n",
        " \n",
        "  # Lógica para percorrer o espaço de busca:\n",
        "  while fitness > acc_target:\n",
        "    cases = cases - 10  # Decrease step value (passo da redução de casos).\n",
        "\n",
        "    # Restrinja o espaço de busca para até 60 casos - verificar (VIANNA, 2021)\n",
        "    if cases == 50:\n",
        "      break\n",
        "\n",
        "    # Faça o subset das amostras:\n",
        "    X_train_new, Y_train_new, X_val_new, Y_val_new, X_test_new, Y_test_new, n_cases = subsetB(cases)\n",
        " \n",
        "    # Carregue o modelo (CNN) padrão salvo:\n",
        "    model = load_model(save_path)\n",
        "\n",
        "    # Imprima algumas informações úteis durante o processo:\n",
        "    print('\\n---> ITERATING NOW WITH:',n_cases,'CASES !',\n",
        "          '(',\"%.2f\" % round((((n_cases)/600)*100),2),'% FROM TOTAL )',\n",
        "          '\\n----> AND THE HISTORY OF CASES DECREASE IS:',n_cases_hist,\n",
        "          '\\n',\n",
        "          '\\nTRAINING AND VALIDATING THE MODEL:',\n",
        "          '\\nIt will take a while ;D...')\n",
        "    \n",
        "    # Treine o modelo com as novas amostras:\n",
        "    model2, history, acc_max, train_time = fit_model(model, X_train_new, Y_train_new, X_val_new, Y_val_new, batch_size, epochs)\n",
        "\n",
        "    # Teste o modelo com as novas amostras:\n",
        "    test_accuracy = test_model(X_test_new, Y_test_new, model2)\n",
        "\n",
        "    # Imprima algumas informações úteis durante o processo:\n",
        "    print('\\nSUMMARY:',\n",
        "          '\\nWith',n_cases,'cases, the max val_accuracy was:',\n",
        "          \"%.4f\" % round((acc_max*100),4),'% and the test_accuracy was:',\n",
        "          \"%.4f\" % round((test_accuracy*100),4),'%.',\n",
        "          '\\nIt is a difference of',\n",
        "          \"%.4f\" % round(((acc_max*100)-(test_accuracy*100)),4),'%.')\n",
        "    \n",
        "    n_cases_hist.append(n_cases) # Armazene o histórico de redução de casos.\n",
        "    fitness_hist.append(fitness) # Armazene o histórico de fitness.\n",
        "    acc_val_hist.append(acc_max) # Armazene o histórico da acurácia de validação.\n",
        "    acc_test_hist.append(test_accuracy) # Armazene o histórico da acurácia de teste.\n",
        "    time_hist.append(train_time) # Armazene os tempos gastos nos treinamentos.\n",
        "\n",
        "    # Imprima o histórico parcial durante o processo:\n",
        "    # (Para caso houver algum problema, saber por onde começar)\n",
        "    print('Fitness history is:', fitness_hist,\n",
        "          '\\nCases history is:', n_cases_hist,\n",
        "          '\\nacc_val history is:', acc_val_hist,\n",
        "          '\\nacc_test history is:', acc_test_hist,\n",
        "          '\\nTimes history is:', time_hist)\n",
        " \n",
        "    # Calcule a Fitness Function:\n",
        "    if test_accuracy < fitness:\n",
        "      fitness = test_accuracy # Fitness assume o valor da nova acurácia de teste.\n",
        "       \n",
        "    # Apague os modelos (pois suas informações podem persistir no estado geral):\n",
        "    del model\n",
        "    del model2\n",
        "    # Reinicie a sessão do Keras, evitando sobrecarregamento de memória:\n",
        "    K.clear_session()\n",
        "    tf.keras.backend.clear_session()\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "    \n",
        "  # Imprime a conclusão do processo de otimização:    \n",
        "  print('\\nHILL CLIMBING: For the configured step, was possible to reduce the dataset to',\n",
        "        n_cases_hist[-1],'cases, with test_accuracy of',fitness_hist[-1])\n",
        " \n",
        "  return history, fitness_hist, n_cases_hist, acc_val_hist, acc_test_hist, time_hist, acc_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUl7jFBCybn9"
      },
      "source": [
        "# 4.First stage simulation (cases number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIOOS560BPMN"
      },
      "source": [
        "**When starting this cell, the \"Hill Climb function\" will automatically instantiate all the other functions, starting an iterative sequence in the form:**\n",
        "\n",
        "1. Subset a portion of the samples;\n",
        "2. Load the initial standard model (with respective weights);\n",
        "3. Train and validate;\n",
        "4. Test;\n",
        "5. Calculation of the fitness function (acc_test >= 95% ?);\n",
        "6. Restart the entire process, now with a smaller number of cases (and according to the adjusted step).\n",
        "\n",
        "*The results (graphs and insights) are presented in section 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lb9AU4ryYNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c426dcf-58b8-480f-c424-8aa16ce8516a"
      },
      "source": [
        "# Execução da fitness function:\n",
        "history, fitness_hist, n_cases_hist, acc_val_hist, acc_test_hist, time_hist, acc_target = hillclimb()\n",
        " \n",
        "print('\\nThe fitness history is:',fitness_hist,\n",
        "      '\\nThe cases decrease history is:',n_cases_hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9982\n",
            "Epoch 24/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.8351\n",
            "Epoch 25/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "Epoch 26/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
            "Epoch 27/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 0.9823\n",
            "Epoch 28/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9982\n",
            "Epoch 29/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9876\n",
            "Epoch 30/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9858\n",
            "Epoch 31/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
            "Epoch 32/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9894\n",
            "Epoch 33/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
            "Epoch 34/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
            "Epoch 35/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9929\n",
            "Epoch 36/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 37/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0061 - accuracy: 0.9996 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 38/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 39/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9929\n",
            "Epoch 40/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0087 - accuracy: 0.9996 - val_loss: 0.0223 - val_accuracy: 0.9965\n",
            "Epoch 41/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9929\n",
            "Epoch 42/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9947\n",
            "Epoch 43/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9982\n",
            "Epoch 44/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 45/500\n",
            "71/71 [==============================] - 1s 9ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9929\n",
            "Epoch 46/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 50/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 0.9996 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0069 - accuracy: 0.9996 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0061 - accuracy: 0.9996 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "71/71 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00119: early stopping\n",
            "Training/validation time was: 125.166 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Evaluate time was 0.315739 seconds\n",
            "1.0\n",
            "\n",
            "SUMMARY: \n",
            "With 220 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 100.0000 %. \n",
            "It is a difference of 0.0000 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693]\n",
            "\n",
            "---> ITERATING NOW WITH: 210 CASES ! ( 35.00 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "68/68 [==============================] - 2s 16ms/step - loss: 1.0765 - accuracy: 0.6209 - val_loss: 2.7953 - val_accuracy: 0.0706\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.5584 - accuracy: 0.7386 - val_loss: 2.9670 - val_accuracy: 0.0706\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.4854 - accuracy: 0.7786 - val_loss: 3.1393 - val_accuracy: 0.0706\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 0.4449 - accuracy: 0.7791 - val_loss: 3.3218 - val_accuracy: 0.1283\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.3714 - accuracy: 0.8349 - val_loss: 3.2700 - val_accuracy: 0.1840\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.3184 - accuracy: 0.8544 - val_loss: 2.8197 - val_accuracy: 0.2007\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 0.2807 - accuracy: 0.8828 - val_loss: 2.6783 - val_accuracy: 0.1654\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.1998 - accuracy: 0.9209 - val_loss: 1.8600 - val_accuracy: 0.3271\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.1688 - accuracy: 0.9414 - val_loss: 1.0979 - val_accuracy: 0.6673\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.1242 - accuracy: 0.9651 - val_loss: 2.0024 - val_accuracy: 0.4368\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.1178 - accuracy: 0.9665 - val_loss: 3.6383 - val_accuracy: 0.2825\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0764 - accuracy: 0.9805 - val_loss: 1.0861 - val_accuracy: 0.5855\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0513 - accuracy: 0.9949 - val_loss: 0.9826 - val_accuracy: 0.6227\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0345 - accuracy: 0.9967 - val_loss: 0.1980 - val_accuracy: 0.9312\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0284 - accuracy: 0.9986 - val_loss: 0.8852 - val_accuracy: 0.6134\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0329 - accuracy: 0.9967 - val_loss: 2.0044 - val_accuracy: 0.5335\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 0.0326 - accuracy: 0.9963 - val_loss: 0.9194 - val_accuracy: 0.6301\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0259 - accuracy: 0.9972 - val_loss: 0.4707 - val_accuracy: 0.8773\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - 1s 10ms/step - loss: 0.0183 - accuracy: 0.9995 - val_loss: 0.3075 - val_accuracy: 0.8996\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0173 - accuracy: 0.9995 - val_loss: 0.2848 - val_accuracy: 0.8866\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 0.0176 - accuracy: 0.9991 - val_loss: 1.2804 - val_accuracy: 0.6877\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9312\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9740\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9870\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9926\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0129 - accuracy: 0.9995 - val_loss: 0.4608 - val_accuracy: 0.8420\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0123 - accuracy: 0.9995 - val_loss: 1.1134 - val_accuracy: 0.6487\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9907\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0117 - accuracy: 0.9995 - val_loss: 0.4808 - val_accuracy: 0.8216\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9907\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9981\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 0.0211 - val_accuracy: 0.9963\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9981\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0092 - accuracy: 0.9995 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9981\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.0229 - val_accuracy: 0.9963\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9944\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0095 - accuracy: 0.9991 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 0.8338 - val_accuracy: 0.7602\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - 1s 10ms/step - loss: 0.0140 - accuracy: 0.9991 - val_loss: 1.9963 - val_accuracy: 0.5279\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0124 - accuracy: 0.9995 - val_loss: 0.1882 - val_accuracy: 0.9257\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9981\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9833\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9647\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9995 - val_loss: 0.0410 - val_accuracy: 0.9833\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.9991 - val_loss: 0.0455 - val_accuracy: 0.9796\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9888\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9926\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9926\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9981\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9963\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9981\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9981\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9981\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9963\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 0.9963\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9981\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - 1s 10ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9981\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9981\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9981\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9981\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9981\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9981\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9981\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9981\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9981\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9995 - val_loss: 0.0296 - val_accuracy: 0.9981\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9981\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9981\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9981\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 0.0164 - val_accuracy: 0.9981\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9963\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9981\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9963\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9981\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9981\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 0.0207 - val_accuracy: 0.9944\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9981\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9981\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9981\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - 1s 11ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9981\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 0.0092 - accuracy: 0.9991 - val_loss: 0.0181 - val_accuracy: 0.9981\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9981\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9981\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9981\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9981\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9981\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9981\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9981\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9981\n",
            "Epoch 95/500\n",
            "68/68 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9981\n",
            "Epoch 96/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9981\n",
            "Epoch 97/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9981\n",
            "Epoch 98/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 0.0203 - val_accuracy: 0.9963\n",
            "Epoch 99/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0087 - accuracy: 0.9995 - val_loss: 0.0197 - val_accuracy: 0.9981\n",
            "Epoch 100/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9981\n",
            "Epoch 101/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9981\n",
            "Epoch 102/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 0.0170 - val_accuracy: 0.9981\n",
            "Epoch 103/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9981\n",
            "Epoch 104/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9981\n",
            "Epoch 105/500\n",
            "68/68 [==============================] - 1s 10ms/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 0.0148 - val_accuracy: 0.9981\n",
            "Epoch 106/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9981\n",
            "Epoch 107/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9981\n",
            "Epoch 108/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9981\n",
            "Epoch 109/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9981\n",
            "Epoch 110/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9981\n",
            "Epoch 111/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9981\n",
            "Epoch 112/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9981\n",
            "Epoch 113/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9981\n",
            "Epoch 114/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9981\n",
            "Epoch 115/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9981\n",
            "Epoch 116/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9981\n",
            "Epoch 117/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9981\n",
            "Epoch 118/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9981\n",
            "Epoch 119/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9981\n",
            "Epoch 120/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9981\n",
            "Epoch 121/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9981\n",
            "Epoch 122/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9981\n",
            "Epoch 123/500\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9981\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00123: early stopping\n",
            "Training/validation time was: 132.936 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "21/21 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Evaluate time was 0.338005 seconds\n",
            "1.0\n",
            "\n",
            "SUMMARY: \n",
            "With 210 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 100.0000 %. \n",
            "It is a difference of 0.0000 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249]\n",
            "\n",
            "---> ITERATING NOW WITH: 200 CASES ! ( 33.33 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "64/64 [==============================] - 2s 10ms/step - loss: 1.0808 - accuracy: 0.6226 - val_loss: 2.7806 - val_accuracy: 0.0527\n",
            "Epoch 2/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.5316 - accuracy: 0.7529 - val_loss: 2.8513 - val_accuracy: 0.0527\n",
            "Epoch 3/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7900 - val_loss: 2.9256 - val_accuracy: 0.0527\n",
            "Epoch 4/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8081 - val_loss: 2.9637 - val_accuracy: 0.2109\n",
            "Epoch 5/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.2778 - accuracy: 0.8857 - val_loss: 2.9455 - val_accuracy: 0.2578\n",
            "Epoch 6/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.2153 - accuracy: 0.9028 - val_loss: 2.9193 - val_accuracy: 0.1543\n",
            "Epoch 7/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.1773 - accuracy: 0.9375 - val_loss: 2.7043 - val_accuracy: 0.2480\n",
            "Epoch 8/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.1339 - accuracy: 0.9526 - val_loss: 2.0285 - val_accuracy: 0.3184\n",
            "Epoch 9/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.9663 - val_loss: 1.0898 - val_accuracy: 0.5723\n",
            "Epoch 10/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.9780 - val_loss: 0.9851 - val_accuracy: 0.7148\n",
            "Epoch 11/500\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0747 - accuracy: 0.9858 - val_loss: 1.4110 - val_accuracy: 0.6152\n",
            "Epoch 12/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9937 - val_loss: 0.2673 - val_accuracy: 0.9316\n",
            "Epoch 13/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9976 - val_loss: 0.7210 - val_accuracy: 0.6836\n",
            "Epoch 14/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0271 - accuracy: 0.9976 - val_loss: 0.3703 - val_accuracy: 0.7949\n",
            "Epoch 15/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0183 - accuracy: 0.9995 - val_loss: 0.1981 - val_accuracy: 0.9180\n",
            "Epoch 16/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0185 - accuracy: 0.9985 - val_loss: 0.2287 - val_accuracy: 0.9043\n",
            "Epoch 17/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 0.9995 - val_loss: 0.2732 - val_accuracy: 0.8848\n",
            "Epoch 18/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 0.9995 - val_loss: 0.1625 - val_accuracy: 0.9395\n",
            "Epoch 19/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 0.9995 - val_loss: 0.0374 - val_accuracy: 0.9980\n",
            "Epoch 20/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9941\n",
            "Epoch 21/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9961\n",
            "Epoch 22/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 0.9990 - val_loss: 0.3810 - val_accuracy: 0.8477\n",
            "Epoch 23/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.8047\n",
            "Epoch 24/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9941\n",
            "Epoch 25/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9980\n",
            "Epoch 26/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 0.9995 - val_loss: 0.0144 - val_accuracy: 0.9980\n",
            "Epoch 27/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9883\n",
            "Epoch 28/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9980\n",
            "Epoch 29/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9980\n",
            "Epoch 30/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9961\n",
            "Epoch 31/500\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9980\n",
            "Epoch 32/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9961\n",
            "Epoch 33/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9980\n",
            "Epoch 34/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 0.0117 - val_accuracy: 0.9980\n",
            "Epoch 35/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.0177 - val_accuracy: 0.9941\n",
            "Epoch 36/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 0.9922\n",
            "Epoch 37/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9980\n",
            "Epoch 38/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9980\n",
            "Epoch 39/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9941\n",
            "Epoch 40/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9961\n",
            "Epoch 41/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9980\n",
            "Epoch 42/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9980\n",
            "Epoch 43/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9961\n",
            "Epoch 44/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9980\n",
            "Epoch 45/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9980\n",
            "Epoch 46/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9980\n",
            "Epoch 47/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9995 - val_loss: 0.0114 - val_accuracy: 0.9980\n",
            "Epoch 48/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9980\n",
            "Epoch 49/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9980\n",
            "Epoch 50/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9980\n",
            "Epoch 51/500\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
            "Epoch 52/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9980\n",
            "Epoch 53/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9980\n",
            "Epoch 55/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9980\n",
            "Epoch 57/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9980\n",
            "Epoch 58/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9980\n",
            "Epoch 60/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
            "Epoch 61/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9980\n",
            "Epoch 62/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
            "Epoch 63/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
            "Epoch 64/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 65/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 66/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 67/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 68/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
            "Epoch 69/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9980\n",
            "Epoch 70/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
            "Epoch 72/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
            "Epoch 73/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
            "Epoch 74/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 75/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 76/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 77/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9980\n",
            "Epoch 79/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
            "Epoch 80/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
            "Epoch 81/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 82/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9980\n",
            "Epoch 83/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 84/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 85/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 86/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 87/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
            "Epoch 88/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 89/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
            "Epoch 91/500\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
            "Epoch 92/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 93/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 94/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 95/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
            "Epoch 96/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
            "Epoch 97/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 98/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 99/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9980\n",
            "Epoch 100/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 101/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 102/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 103/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
            "Epoch 104/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9980\n",
            "Epoch 105/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9980\n",
            "Epoch 106/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 107/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
            "Epoch 108/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
            "Epoch 112/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
            "Epoch 113/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 114/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 115/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 116/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
            "Epoch 117/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 118/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 119/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9980\n",
            "Epoch 120/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 121/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
            "Epoch 122/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
            "Epoch 123/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 124/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
            "Epoch 125/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
            "Epoch 126/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
            "Epoch 127/500\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
            "Epoch 128/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
            "Epoch 129/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
            "Epoch 130/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
            "Epoch 131/500\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 132/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 133/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 134/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 135/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9980\n",
            "Epoch 136/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 137/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 138/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
            "Epoch 139/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
            "Epoch 140/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 141/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 142/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
            "Epoch 143/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 144/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 145/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
            "Epoch 146/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9980\n",
            "Epoch 147/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
            "Epoch 148/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
            "Epoch 149/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9980\n",
            "Epoch 150/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 151/500\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 152/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9980\n",
            "Epoch 153/500\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00153: early stopping\n",
            "Training/validation time was: 138.755 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9969\n",
            "Evaluate time was 0.0990257 seconds\n",
            "0.996874988079071\n",
            "\n",
            "SUMMARY: \n",
            "With 200 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 99.6875 %. \n",
            "It is a difference of 0.3125 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645]\n",
            "\n",
            "---> ITERATING NOW WITH: 190 CASES ! ( 31.67 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "61/61 [==============================] - 2s 13ms/step - loss: 1.1366 - accuracy: 0.6216 - val_loss: 2.7688 - val_accuracy: 0.0595\n",
            "Epoch 2/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.5399 - accuracy: 0.7445 - val_loss: 2.8170 - val_accuracy: 0.0595\n",
            "Epoch 3/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.4477 - accuracy: 0.7728 - val_loss: 2.8910 - val_accuracy: 0.1211\n",
            "Epoch 4/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8021 - val_loss: 2.9483 - val_accuracy: 0.1396\n",
            "Epoch 5/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.3471 - accuracy: 0.8324 - val_loss: 3.0408 - val_accuracy: 0.1417\n",
            "Epoch 6/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.3094 - accuracy: 0.8668 - val_loss: 3.1909 - val_accuracy: 0.1561\n",
            "Epoch 7/500\n",
            "61/61 [==============================] - 1s 13ms/step - loss: 0.3085 - accuracy: 0.8524 - val_loss: 2.8246 - val_accuracy: 0.2423\n",
            "Epoch 8/500\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.2300 - accuracy: 0.9111 - val_loss: 2.4445 - val_accuracy: 0.2341\n",
            "Epoch 9/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.1817 - accuracy: 0.9337 - val_loss: 1.4494 - val_accuracy: 0.5051\n",
            "Epoch 10/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.1204 - accuracy: 0.9650 - val_loss: 0.8047 - val_accuracy: 0.6879\n",
            "Epoch 11/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0922 - accuracy: 0.9753 - val_loss: 0.6599 - val_accuracy: 0.7310\n",
            "Epoch 12/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0666 - accuracy: 0.9887 - val_loss: 0.2775 - val_accuracy: 0.9405\n",
            "Epoch 13/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0488 - accuracy: 0.9964 - val_loss: 0.2584 - val_accuracy: 0.9179\n",
            "Epoch 14/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0432 - accuracy: 0.9928 - val_loss: 0.2870 - val_accuracy: 0.9055\n",
            "Epoch 15/500\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9969 - val_loss: 0.2566 - val_accuracy: 0.9199\n",
            "Epoch 16/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9985 - val_loss: 0.9839 - val_accuracy: 0.7454\n",
            "Epoch 17/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9985 - val_loss: 0.2114 - val_accuracy: 0.8809\n",
            "Epoch 18/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 0.9954 - val_loss: 0.4653 - val_accuracy: 0.7823\n",
            "Epoch 19/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9985 - val_loss: 0.2615 - val_accuracy: 0.8768\n",
            "Epoch 20/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 0.9990 - val_loss: 0.0343 - val_accuracy: 0.9979\n",
            "Epoch 21/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0150 - accuracy: 0.9995 - val_loss: 0.0265 - val_accuracy: 0.9979\n",
            "Epoch 22/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0139 - accuracy: 0.9990 - val_loss: 0.0309 - val_accuracy: 0.9959\n",
            "Epoch 23/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9774\n",
            "Epoch 24/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 25/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 26/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0117 - accuracy: 0.9990 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
            "Epoch 27/500\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
            "Epoch 28/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 29/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9979\n",
            "Epoch 30/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 31/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0100 - accuracy: 0.9995 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 32/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9959\n",
            "Epoch 33/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 34/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 35/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 36/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 37/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9979\n",
            "Epoch 38/500\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 39/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 40/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 41/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 42/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 43/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 44/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 45/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "61/61 [==============================] - 1s 11ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9548\n",
            "Epoch 48/500\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 50/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0095 - accuracy: 0.9990 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00124: early stopping\n",
            "Training/validation time was: 122.349 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9951\n",
            "Evaluate time was 0.31813 seconds\n",
            "0.9950658082962036\n",
            "\n",
            "SUMMARY: \n",
            "With 190 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 99.5066 %. \n",
            "It is a difference of 0.4934 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935]\n",
            "\n",
            "---> ITERATING NOW WITH: 180 CASES ! ( 30.00 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "58/58 [==============================] - 2s 14ms/step - loss: 1.0974 - accuracy: 0.6283 - val_loss: 2.7627 - val_accuracy: 0.0629\n",
            "Epoch 2/500\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.5361 - accuracy: 0.7542 - val_loss: 2.8233 - val_accuracy: 0.0629\n",
            "Epoch 3/500\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.4264 - accuracy: 0.7835 - val_loss: 2.9199 - val_accuracy: 0.0629\n",
            "Epoch 4/500\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.3858 - accuracy: 0.8079 - val_loss: 2.9935 - val_accuracy: 0.1692\n",
            "Epoch 5/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3195 - accuracy: 0.8492 - val_loss: 3.0352 - val_accuracy: 0.1714\n",
            "Epoch 6/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2791 - accuracy: 0.8709 - val_loss: 3.0186 - val_accuracy: 0.1779\n",
            "Epoch 7/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2268 - accuracy: 0.8996 - val_loss: 2.7342 - val_accuracy: 0.1735\n",
            "Epoch 8/500\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.1973 - accuracy: 0.9126 - val_loss: 2.5052 - val_accuracy: 0.2625\n",
            "Epoch 9/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.1501 - accuracy: 0.9365 - val_loss: 1.7317 - val_accuracy: 0.3948\n",
            "Epoch 10/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1419 - accuracy: 0.9419 - val_loss: 1.1226 - val_accuracy: 0.5987\n",
            "Epoch 11/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1086 - accuracy: 0.9685 - val_loss: 0.8168 - val_accuracy: 0.7614\n",
            "Epoch 12/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0935 - accuracy: 0.9696 - val_loss: 0.7744 - val_accuracy: 0.7874\n",
            "Epoch 13/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0817 - accuracy: 0.9826 - val_loss: 0.8736 - val_accuracy: 0.6833\n",
            "Epoch 14/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0589 - accuracy: 0.9946 - val_loss: 5.0824 - val_accuracy: 0.2863\n",
            "Epoch 15/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9989 - val_loss: 0.3241 - val_accuracy: 0.9132\n",
            "Epoch 16/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9995 - val_loss: 1.2115 - val_accuracy: 0.6681\n",
            "Epoch 17/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.7753 - val_accuracy: 0.7137\n",
            "Epoch 18/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0170 - accuracy: 0.9995 - val_loss: 0.2499 - val_accuracy: 0.8503\n",
            "Epoch 19/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9067\n",
            "Epoch 20/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.5894 - val_accuracy: 0.8286\n",
            "Epoch 21/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.8959\n",
            "Epoch 22/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.8894\n",
            "Epoch 23/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 24/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9631\n",
            "Epoch 25/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9479\n",
            "Epoch 26/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9892\n",
            "Epoch 27/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9892\n",
            "Epoch 28/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
            "Epoch 29/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
            "Epoch 30/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 0.9995 - val_loss: 0.0653 - val_accuracy: 0.9718\n",
            "Epoch 31/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9957\n",
            "Epoch 32/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9957\n",
            "Epoch 33/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 34/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9783\n",
            "Epoch 35/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 36/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
            "Epoch 37/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 38/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
            "Epoch 39/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 0.9995 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 40/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 41/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 42/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 43/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 44/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 45/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 50/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 0.9995 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00123: early stopping\n",
            "Training/validation time was: 123.116 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9965\n",
            "Evaluate time was 0.299307 seconds\n",
            "0.9965277910232544\n",
            "\n",
            "SUMMARY: \n",
            "With 180 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 99.6528 %. \n",
            "It is a difference of 0.3472 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965]\n",
            "\n",
            "---> ITERATING NOW WITH: 170 CASES ! ( 28.33 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "55/55 [==============================] - 2s 13ms/step - loss: 1.0660 - accuracy: 0.6437 - val_loss: 2.7637 - val_accuracy: 0.0665\n",
            "Epoch 2/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5028 - accuracy: 0.7816 - val_loss: 2.8286 - val_accuracy: 0.0665\n",
            "Epoch 3/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4206 - accuracy: 0.7954 - val_loss: 2.8749 - val_accuracy: 0.0665\n",
            "Epoch 4/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.3595 - accuracy: 0.8132 - val_loss: 2.8188 - val_accuracy: 0.1376\n",
            "Epoch 5/500\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.3288 - accuracy: 0.8563 - val_loss: 2.8994 - val_accuracy: 0.1422\n",
            "Epoch 6/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.2472 - accuracy: 0.8862 - val_loss: 2.8175 - val_accuracy: 0.1445\n",
            "Epoch 7/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.2146 - accuracy: 0.8931 - val_loss: 2.7557 - val_accuracy: 0.2202\n",
            "Epoch 8/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.1842 - accuracy: 0.9126 - val_loss: 2.8231 - val_accuracy: 0.2248\n",
            "Epoch 9/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.1712 - accuracy: 0.9247 - val_loss: 1.8448 - val_accuracy: 0.3303\n",
            "Epoch 10/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.9414 - val_loss: 2.2651 - val_accuracy: 0.2775\n",
            "Epoch 11/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.1085 - accuracy: 0.9649 - val_loss: 0.6053 - val_accuracy: 0.7959\n",
            "Epoch 12/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.1315 - accuracy: 0.9546 - val_loss: 4.0395 - val_accuracy: 0.2202\n",
            "Epoch 13/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.1078 - accuracy: 0.9598 - val_loss: 3.3692 - val_accuracy: 0.3394\n",
            "Epoch 14/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0989 - accuracy: 0.9603 - val_loss: 1.4351 - val_accuracy: 0.6147\n",
            "Epoch 15/500\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.0860 - accuracy: 0.9713 - val_loss: 1.2938 - val_accuracy: 0.6674\n",
            "Epoch 16/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0714 - accuracy: 0.9810 - val_loss: 1.6397 - val_accuracy: 0.5161\n",
            "Epoch 17/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0355 - accuracy: 0.9977 - val_loss: 0.6428 - val_accuracy: 0.7339\n",
            "Epoch 18/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0258 - accuracy: 0.9994 - val_loss: 0.6052 - val_accuracy: 0.7752\n",
            "Epoch 19/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9989 - val_loss: 2.9681 - val_accuracy: 0.4610\n",
            "Epoch 20/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9989 - val_loss: 0.7805 - val_accuracy: 0.7477\n",
            "Epoch 21/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.6210 - val_accuracy: 0.7821\n",
            "Epoch 22/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9381\n",
            "Epoch 23/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.7224 - val_accuracy: 0.4404\n",
            "Epoch 24/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.9691 - val_accuracy: 0.4106\n",
            "Epoch 25/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.6259 - val_accuracy: 0.8005\n",
            "Epoch 26/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9633\n",
            "Epoch 27/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9794\n",
            "Epoch 28/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.2177 - val_accuracy: 0.6858\n",
            "Epoch 29/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
            "Epoch 30/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.3141 - val_accuracy: 0.8899\n",
            "Epoch 31/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9977\n",
            "Epoch 32/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9381\n",
            "Epoch 33/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.8945\n",
            "Epoch 34/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 35/500\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 36/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
            "Epoch 37/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
            "Epoch 38/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 39/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9128\n",
            "Epoch 40/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 41/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8532\n",
            "Epoch 42/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9954\n",
            "Epoch 43/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.8876\n",
            "Epoch 44/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9954\n",
            "Epoch 45/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9931\n",
            "Epoch 49/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9885\n",
            "Epoch 50/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9954\n",
            "Epoch 57/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9977\n",
            "Epoch 60/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9977\n",
            "Epoch 61/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9312\n",
            "Epoch 62/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00129: early stopping\n",
            "Training/validation time was: 123.414 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Evaluate time was 0.28863 seconds\n",
            "1.0\n",
            "\n",
            "SUMMARY: \n",
            "With 170 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 100.0000 %. \n",
            "It is a difference of 0.0000 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287]\n",
            "\n",
            "---> ITERATING NOW WITH: 160 CASES ! ( 26.67 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "52/52 [==============================] - 2s 19ms/step - loss: 1.0599 - accuracy: 0.6398 - val_loss: 2.7595 - val_accuracy: 0.0683\n",
            "Epoch 2/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.4809 - accuracy: 0.8004 - val_loss: 2.7822 - val_accuracy: 0.0683\n",
            "Epoch 3/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.4113 - accuracy: 0.7949 - val_loss: 2.7878 - val_accuracy: 0.0683\n",
            "Epoch 4/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.3682 - accuracy: 0.8126 - val_loss: 2.7764 - val_accuracy: 0.1463\n",
            "Epoch 5/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.3182 - accuracy: 0.8559 - val_loss: 2.7897 - val_accuracy: 0.1244\n",
            "Epoch 6/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.2844 - accuracy: 0.8669 - val_loss: 2.8058 - val_accuracy: 0.1439\n",
            "Epoch 7/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.2402 - accuracy: 0.8907 - val_loss: 2.6487 - val_accuracy: 0.1683\n",
            "Epoch 8/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.3317 - accuracy: 0.8480 - val_loss: 2.5227 - val_accuracy: 0.2024\n",
            "Epoch 9/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.2189 - accuracy: 0.8907 - val_loss: 1.9184 - val_accuracy: 0.3073\n",
            "Epoch 10/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.1512 - accuracy: 0.9536 - val_loss: 1.3141 - val_accuracy: 0.3878\n",
            "Epoch 11/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.1270 - accuracy: 0.9567 - val_loss: 0.9203 - val_accuracy: 0.6415\n",
            "Epoch 12/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0882 - accuracy: 0.9811 - val_loss: 0.8809 - val_accuracy: 0.6610\n",
            "Epoch 13/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0751 - accuracy: 0.9853 - val_loss: 0.8710 - val_accuracy: 0.6902\n",
            "Epoch 14/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0506 - accuracy: 0.9933 - val_loss: 9.6620 - val_accuracy: 0.2390\n",
            "Epoch 15/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.1226 - accuracy: 0.9634 - val_loss: 2.3370 - val_accuracy: 0.3488\n",
            "Epoch 16/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0876 - accuracy: 0.9847 - val_loss: 0.8084 - val_accuracy: 0.7854\n",
            "Epoch 17/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 0.9957 - val_loss: 0.6727 - val_accuracy: 0.8366\n",
            "Epoch 18/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0440 - accuracy: 0.9951 - val_loss: 1.2844 - val_accuracy: 0.4854\n",
            "Epoch 19/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9976 - val_loss: 0.5640 - val_accuracy: 0.7610\n",
            "Epoch 20/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0180 - accuracy: 0.9994 - val_loss: 0.2461 - val_accuracy: 0.9244\n",
            "Epoch 21/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9982 - val_loss: 0.1974 - val_accuracy: 0.9463\n",
            "Epoch 22/500\n",
            "52/52 [==============================] - 1s 11ms/step - loss: 0.0157 - accuracy: 0.9994 - val_loss: 0.0693 - val_accuracy: 0.9927\n",
            "Epoch 23/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
            "Epoch 24/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 0.9988 - val_loss: 0.0565 - val_accuracy: 0.9854\n",
            "Epoch 25/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 0.1569 - val_accuracy: 0.9439\n",
            "Epoch 26/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0116 - accuracy: 0.9994 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
            "Epoch 27/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9488\n",
            "Epoch 28/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9951\n",
            "Epoch 29/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0148 - accuracy: 0.9976 - val_loss: 1.0455 - val_accuracy: 0.5659\n",
            "Epoch 30/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9659\n",
            "Epoch 31/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 0.9994 - val_loss: 0.1797 - val_accuracy: 0.9073\n",
            "Epoch 32/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
            "Epoch 33/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.8073\n",
            "Epoch 34/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
            "Epoch 35/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 0.9220\n",
            "Epoch 36/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 37/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9951\n",
            "Epoch 38/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 39/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 40/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.1766 - val_accuracy: 0.9122\n",
            "Epoch 41/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.2320 - val_accuracy: 0.9195\n",
            "Epoch 42/500\n",
            "52/52 [==============================] - 1s 11ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
            "Epoch 43/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.2402 - val_accuracy: 0.9683\n",
            "Epoch 44/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.8780\n",
            "Epoch 45/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9780\n",
            "Epoch 50/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "52/52 [==============================] - 1s 11ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "52/52 [==============================] - 1s 11ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "52/52 [==============================] - 1s 11ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00123: early stopping\n",
            "Training/validation time was: 112.386 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 1.0000\n",
            "Evaluate time was 0.292081 seconds\n",
            "1.0\n",
            "\n",
            "SUMMARY: \n",
            "With 160 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 100.0000 %. \n",
            "It is a difference of 0.0000 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0, 1.0] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287, 112.38595223426819]\n",
            "\n",
            "---> ITERATING NOW WITH: 150 CASES ! ( 25.00 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "48/48 [==============================] - 2s 12ms/step - loss: 1.0427 - accuracy: 0.6576 - val_loss: 2.7531 - val_accuracy: 0.0573\n",
            "Epoch 2/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.4961 - accuracy: 0.7878 - val_loss: 2.7691 - val_accuracy: 0.0573\n",
            "Epoch 3/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.3913 - accuracy: 0.8145 - val_loss: 2.7996 - val_accuracy: 0.0573\n",
            "Epoch 4/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.3395 - accuracy: 0.8294 - val_loss: 2.8114 - val_accuracy: 0.1120\n",
            "Epoch 5/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.2959 - accuracy: 0.8503 - val_loss: 2.7939 - val_accuracy: 0.1120\n",
            "Epoch 6/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.2809 - accuracy: 0.8516 - val_loss: 2.7174 - val_accuracy: 0.1120\n",
            "Epoch 7/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.2508 - accuracy: 0.8822 - val_loss: 2.6647 - val_accuracy: 0.1693\n",
            "Epoch 8/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.2219 - accuracy: 0.8997 - val_loss: 2.5896 - val_accuracy: 0.1120\n",
            "Epoch 9/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.1993 - accuracy: 0.9056 - val_loss: 2.4213 - val_accuracy: 0.1276\n",
            "Epoch 10/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.1700 - accuracy: 0.9238 - val_loss: 2.0417 - val_accuracy: 0.3542\n",
            "Epoch 11/500\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.1565 - accuracy: 0.9245 - val_loss: 3.3287 - val_accuracy: 0.1771\n",
            "Epoch 12/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.1447 - accuracy: 0.9421 - val_loss: 1.9218 - val_accuracy: 0.4948\n",
            "Epoch 13/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.1106 - accuracy: 0.9648 - val_loss: 0.8913 - val_accuracy: 0.7370\n",
            "Epoch 14/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0918 - accuracy: 0.9772 - val_loss: 0.6065 - val_accuracy: 0.9010\n",
            "Epoch 15/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0621 - accuracy: 0.9876 - val_loss: 1.4843 - val_accuracy: 0.6589\n",
            "Epoch 16/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0559 - accuracy: 0.9896 - val_loss: 1.5078 - val_accuracy: 0.5573\n",
            "Epoch 17/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9889 - val_loss: 0.3627 - val_accuracy: 0.8177\n",
            "Epoch 18/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0380 - accuracy: 0.9954 - val_loss: 0.2101 - val_accuracy: 0.9297\n",
            "Epoch 19/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.9961 - val_loss: 0.5777 - val_accuracy: 0.7943\n",
            "Epoch 20/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9531\n",
            "Epoch 21/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9980 - val_loss: 0.6861 - val_accuracy: 0.8307\n",
            "Epoch 22/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.5907 - val_accuracy: 0.8177\n",
            "Epoch 23/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9922\n",
            "Epoch 24/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0570 - val_accuracy: 0.9922\n",
            "Epoch 25/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
            "Epoch 26/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9844\n",
            "Epoch 27/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.8464\n",
            "Epoch 28/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
            "Epoch 29/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.8568\n",
            "Epoch 30/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0108 - accuracy: 0.9993 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
            "Epoch 31/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
            "Epoch 32/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 1.0000\n",
            "Epoch 33/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9974\n",
            "Epoch 34/500\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.0099 - accuracy: 0.9993 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
            "Epoch 35/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
            "Epoch 36/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.8724\n",
            "Epoch 37/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9844\n",
            "Epoch 38/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0101 - accuracy: 0.9993 - val_loss: 0.2002 - val_accuracy: 0.9141\n",
            "Epoch 39/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 40/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 41/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 42/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.1068 - val_accuracy: 0.9375\n",
            "Epoch 43/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 44/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 45/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 50/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9219\n",
            "Epoch 54/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9089\n",
            "Epoch 55/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9974\n",
            "Epoch 56/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9974\n",
            "Epoch 58/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.0516 - val_accuracy: 0.9922\n",
            "Epoch 69/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9974\n",
            "Epoch 79/500\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "48/48 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00125: early stopping\n",
            "Training/validation time was: 105.299 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9979\n",
            "Evaluate time was 0.0856166 seconds\n",
            "0.9979166388511658\n",
            "\n",
            "SUMMARY: \n",
            "With 150 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 99.7917 %. \n",
            "It is a difference of 0.2083 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0, 1.0, 0.9979166388511658] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287, 112.38595223426819, 105.29911494255066]\n",
            "\n",
            "---> ITERATING NOW WITH: 140 CASES ! ( 23.33 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "45/45 [==============================] - 2s 14ms/step - loss: 1.1194 - accuracy: 0.6274 - val_loss: 2.7656 - val_accuracy: 0.0641\n",
            "Epoch 2/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.4580 - accuracy: 0.7913 - val_loss: 2.7832 - val_accuracy: 0.0641\n",
            "Epoch 3/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.3902 - accuracy: 0.8165 - val_loss: 2.8268 - val_accuracy: 0.1170\n",
            "Epoch 4/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.3494 - accuracy: 0.8283 - val_loss: 2.8609 - val_accuracy: 0.1337\n",
            "Epoch 5/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.2961 - accuracy: 0.8569 - val_loss: 2.8956 - val_accuracy: 0.1393\n",
            "Epoch 6/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.2717 - accuracy: 0.8709 - val_loss: 2.9382 - val_accuracy: 0.1866\n",
            "Epoch 7/500\n",
            "45/45 [==============================] - 1s 15ms/step - loss: 0.2650 - accuracy: 0.8737 - val_loss: 2.8507 - val_accuracy: 0.1866\n",
            "Epoch 8/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.1868 - accuracy: 0.9184 - val_loss: 2.7401 - val_accuracy: 0.1894\n",
            "Epoch 9/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.1737 - accuracy: 0.9253 - val_loss: 2.5821 - val_accuracy: 0.1783\n",
            "Epoch 10/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.1372 - accuracy: 0.9567 - val_loss: 2.1735 - val_accuracy: 0.3064\n",
            "Epoch 11/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.1104 - accuracy: 0.9714 - val_loss: 1.9040 - val_accuracy: 0.3983\n",
            "Epoch 12/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.1030 - accuracy: 0.9644 - val_loss: 1.5341 - val_accuracy: 0.4540\n",
            "Epoch 13/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0759 - accuracy: 0.9826 - val_loss: 1.1419 - val_accuracy: 0.5794\n",
            "Epoch 14/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0567 - accuracy: 0.9902 - val_loss: 1.3306 - val_accuracy: 0.5850\n",
            "Epoch 15/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0301 - accuracy: 0.9993 - val_loss: 1.2800 - val_accuracy: 0.5599\n",
            "Epoch 16/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0306 - accuracy: 0.9979 - val_loss: 0.2779 - val_accuracy: 0.8607\n",
            "Epoch 17/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.8552\n",
            "Epoch 18/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9986 - val_loss: 0.5707 - val_accuracy: 0.8357\n",
            "Epoch 19/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.8691\n",
            "Epoch 20/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9081\n",
            "Epoch 21/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9331\n",
            "Epoch 22/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 0.9916\n",
            "Epoch 23/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9861\n",
            "Epoch 24/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 0.9986 - val_loss: 0.0977 - val_accuracy: 0.9777\n",
            "Epoch 25/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
            "Epoch 26/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9889\n",
            "Epoch 27/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9916\n",
            "Epoch 28/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
            "Epoch 29/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9443\n",
            "Epoch 30/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9833\n",
            "Epoch 31/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 32/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9666\n",
            "Epoch 33/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9972\n",
            "Epoch 34/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 35/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 36/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 37/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 38/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 0.9387\n",
            "Epoch 39/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 40/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 0.9993 - val_loss: 0.0163 - val_accuracy: 0.9972\n",
            "Epoch 41/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9944\n",
            "Epoch 42/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 43/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 44/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 45/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 50/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00125: early stopping\n",
            "Training/validation time was: 117.065 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 1.0000\n",
            "Evaluate time was 0.292975 seconds\n",
            "1.0\n",
            "\n",
            "SUMMARY: \n",
            "With 140 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 100.0000 %. \n",
            "It is a difference of 0.0000 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0, 1.0, 0.9979166388511658, 1.0] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287, 112.38595223426819, 105.29911494255066, 117.06488060951233]\n",
            "\n",
            "---> ITERATING NOW WITH: 130 CASES ! ( 21.67 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "42/42 [==============================] - 2s 14ms/step - loss: 1.0812 - accuracy: 0.6702 - val_loss: 2.7552 - val_accuracy: 0.1141\n",
            "Epoch 2/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.4610 - accuracy: 0.8054 - val_loss: 2.7811 - val_accuracy: 0.0601\n",
            "Epoch 3/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.3487 - accuracy: 0.8392 - val_loss: 2.8194 - val_accuracy: 0.0601\n",
            "Epoch 4/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.3186 - accuracy: 0.8467 - val_loss: 2.8438 - val_accuracy: 0.1141\n",
            "Epoch 5/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2792 - accuracy: 0.8595 - val_loss: 2.8767 - val_accuracy: 0.1141\n",
            "Epoch 6/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2563 - accuracy: 0.8753 - val_loss: 2.9280 - val_accuracy: 0.1141\n",
            "Epoch 7/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2608 - accuracy: 0.8768 - val_loss: 2.9611 - val_accuracy: 0.1381\n",
            "Epoch 8/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2228 - accuracy: 0.9001 - val_loss: 2.9734 - val_accuracy: 0.1141\n",
            "Epoch 9/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.1896 - accuracy: 0.9264 - val_loss: 2.8043 - val_accuracy: 0.1381\n",
            "Epoch 10/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.1607 - accuracy: 0.9271 - val_loss: 2.4819 - val_accuracy: 0.1832\n",
            "Epoch 11/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.1535 - accuracy: 0.9376 - val_loss: 2.4686 - val_accuracy: 0.2072\n",
            "Epoch 12/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.1131 - accuracy: 0.9624 - val_loss: 1.7370 - val_accuracy: 0.3303\n",
            "Epoch 13/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.1154 - accuracy: 0.9602 - val_loss: 1.6148 - val_accuracy: 0.5225\n",
            "Epoch 14/500\n",
            "42/42 [==============================] - 1s 12ms/step - loss: 0.0825 - accuracy: 0.9752 - val_loss: 1.2188 - val_accuracy: 0.6697\n",
            "Epoch 15/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0628 - accuracy: 0.9865 - val_loss: 0.8232 - val_accuracy: 0.6306\n",
            "Epoch 16/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0426 - accuracy: 0.9955 - val_loss: 0.7075 - val_accuracy: 0.8589\n",
            "Epoch 17/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 0.9962 - val_loss: 1.2160 - val_accuracy: 0.6727\n",
            "Epoch 18/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9992 - val_loss: 0.4018 - val_accuracy: 0.9099\n",
            "Epoch 19/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9985 - val_loss: 0.3532 - val_accuracy: 0.8919\n",
            "Epoch 20/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 0.9977 - val_loss: 0.1744 - val_accuracy: 0.9189\n",
            "Epoch 21/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0151 - accuracy: 0.9992 - val_loss: 0.1133 - val_accuracy: 0.9910\n",
            "Epoch 22/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9670\n",
            "Epoch 23/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0160 - accuracy: 0.9985 - val_loss: 0.1476 - val_accuracy: 0.9369\n",
            "Epoch 24/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9249\n",
            "Epoch 25/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 0.9985 - val_loss: 0.0610 - val_accuracy: 0.9880\n",
            "Epoch 26/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9940\n",
            "Epoch 27/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9940\n",
            "Epoch 28/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9820\n",
            "Epoch 29/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9640\n",
            "Epoch 30/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 0.7808\n",
            "Epoch 31/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9580\n",
            "Epoch 32/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9940\n",
            "Epoch 33/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9940\n",
            "Epoch 34/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9940\n",
            "Epoch 35/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9940\n",
            "Epoch 36/500\n",
            "42/42 [==============================] - 1s 13ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 2.4272 - val_accuracy: 0.5766\n",
            "Epoch 37/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.9436 - val_accuracy: 0.7538\n",
            "Epoch 38/500\n",
            "42/42 [==============================] - 0s 10ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 0.9820\n",
            "Epoch 39/500\n",
            "42/42 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9940\n",
            "Epoch 40/500\n",
            "42/42 [==============================] - 0s 10ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9489\n",
            "Epoch 41/500\n",
            "42/42 [==============================] - 0s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9940\n",
            "Epoch 42/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9910\n",
            "Epoch 43/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9940\n",
            "Epoch 44/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9940\n",
            "Epoch 45/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9940\n",
            "Epoch 46/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9940\n",
            "Epoch 47/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9940\n",
            "Epoch 48/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9940\n",
            "Epoch 49/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9940\n",
            "Epoch 50/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9940\n",
            "Epoch 51/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9940\n",
            "Epoch 52/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9940\n",
            "Epoch 53/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 0.9940\n",
            "Epoch 54/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9880\n",
            "Epoch 55/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9910\n",
            "Epoch 56/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0363 - val_accuracy: 0.9910\n",
            "Epoch 57/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9940\n",
            "Epoch 58/500\n",
            "42/42 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9820\n",
            "Epoch 59/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9940\n",
            "Epoch 60/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9940\n",
            "Epoch 61/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9940\n",
            "Epoch 62/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9910\n",
            "Epoch 63/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9940\n",
            "Epoch 64/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9940\n",
            "Epoch 65/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9910\n",
            "Epoch 66/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9940\n",
            "Epoch 67/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9940\n",
            "Epoch 68/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9940\n",
            "Epoch 69/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9940\n",
            "Epoch 70/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9640\n",
            "Epoch 71/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9399\n",
            "Epoch 72/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.0483 - val_accuracy: 0.9850\n",
            "Epoch 73/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9850\n",
            "Epoch 74/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9249\n",
            "Epoch 75/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9970\n",
            "Epoch 76/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9940\n",
            "Epoch 77/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9940\n",
            "Epoch 78/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9880\n",
            "Epoch 79/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9910\n",
            "Epoch 80/500\n",
            "42/42 [==============================] - 1s 12ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9940\n",
            "Epoch 81/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9940\n",
            "Epoch 82/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9940\n",
            "Epoch 83/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9940\n",
            "Epoch 84/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9940\n",
            "Epoch 85/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9940\n",
            "Epoch 86/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9940\n",
            "Epoch 87/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9940\n",
            "Epoch 88/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0196 - val_accuracy: 0.9940\n",
            "Epoch 89/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9940\n",
            "Epoch 90/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9940\n",
            "Epoch 91/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9940\n",
            "Epoch 92/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9940\n",
            "Epoch 93/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9940\n",
            "Epoch 94/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9940\n",
            "Epoch 95/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9940\n",
            "Epoch 96/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.0161 - val_accuracy: 0.9940\n",
            "Epoch 97/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9940\n",
            "Epoch 98/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9940\n",
            "Epoch 99/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9940\n",
            "Epoch 100/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9940\n",
            "Epoch 101/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9940\n",
            "Epoch 102/500\n",
            "42/42 [==============================] - 1s 12ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9940\n",
            "Epoch 103/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9940\n",
            "Epoch 104/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9940\n",
            "Epoch 105/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9940\n",
            "Epoch 106/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9880\n",
            "Epoch 107/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9910\n",
            "Epoch 108/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9940\n",
            "Epoch 109/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9940\n",
            "Epoch 110/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9880\n",
            "Epoch 111/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9940\n",
            "Epoch 112/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9940\n",
            "Epoch 113/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9940\n",
            "Epoch 114/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9940\n",
            "Epoch 115/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9940\n",
            "Epoch 116/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9940\n",
            "Epoch 117/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9940\n",
            "Epoch 118/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9940\n",
            "Epoch 119/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9940\n",
            "Epoch 120/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9940\n",
            "Epoch 121/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9910\n",
            "Epoch 122/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 0.9940\n",
            "Epoch 123/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9940\n",
            "Epoch 124/500\n",
            "42/42 [==============================] - 0s 11ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9940\n",
            "Epoch 125/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9940\n",
            "Epoch 126/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9940\n",
            "Epoch 127/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9910\n",
            "Epoch 128/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9940\n",
            "Epoch 129/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9940\n",
            "Epoch 130/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9940\n",
            "Epoch 131/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9940\n",
            "Epoch 132/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9940\n",
            "Epoch 133/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9940\n",
            "Epoch 134/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9940\n",
            "Epoch 135/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9940\n",
            "Epoch 136/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9940\n",
            "Epoch 137/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9940\n",
            "Epoch 138/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9940\n",
            "Epoch 139/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9940\n",
            "Epoch 140/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9940\n",
            "Epoch 141/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9940\n",
            "Epoch 142/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9940\n",
            "Epoch 143/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9940\n",
            "Epoch 144/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9940\n",
            "Epoch 145/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0154 - val_accuracy: 0.9940\n",
            "Epoch 146/500\n",
            "42/42 [==============================] - 1s 12ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9940\n",
            "Epoch 147/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9940\n",
            "Epoch 148/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9940\n",
            "Epoch 149/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9940\n",
            "Epoch 150/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9940\n",
            "Epoch 151/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9940\n",
            "Epoch 152/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9940\n",
            "Epoch 153/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9940\n",
            "Epoch 154/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9940\n",
            "Epoch 155/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9940\n",
            "Epoch 156/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9940\n",
            "Epoch 157/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9940\n",
            "Epoch 158/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9940\n",
            "Epoch 159/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9940\n",
            "Epoch 160/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9940\n",
            "Epoch 161/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9940\n",
            "Epoch 162/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9940\n",
            "Epoch 163/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9940\n",
            "Epoch 164/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9940\n",
            "Epoch 165/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9940\n",
            "Epoch 166/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9940\n",
            "Epoch 167/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9940\n",
            "Epoch 168/500\n",
            "42/42 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9940\n",
            "Epoch 169/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9940\n",
            "Epoch 170/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9940\n",
            "Epoch 171/500\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9940\n",
            "Epoch 172/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9940\n",
            "Epoch 173/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 0.9940\n",
            "Epoch 174/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9940\n",
            "Epoch 175/500\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9940\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00175: early stopping\n",
            "Training/validation time was: 150.655 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9952\n",
            "Evaluate time was 0.286802 seconds\n",
            "0.995192289352417\n",
            "\n",
            "SUMMARY: \n",
            "With 130 cases, the max val_accuracy was: 99.6997 % and the test_accuracy was: 99.5192 %. \n",
            "It is a difference of 0.1805 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9969969987869263] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0, 1.0, 0.9979166388511658, 1.0, 0.995192289352417] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287, 112.38595223426819, 105.29911494255066, 117.06488060951233, 150.65474224090576]\n",
            "\n",
            "---> ITERATING NOW WITH: 120 CASES ! ( 20.00 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "39/39 [==============================] - 2s 16ms/step - loss: 1.0599 - accuracy: 0.6653 - val_loss: 2.7575 - val_accuracy: 0.0584\n",
            "Epoch 2/500\n",
            "39/39 [==============================] - 1s 16ms/step - loss: 0.4035 - accuracy: 0.8192 - val_loss: 2.7676 - val_accuracy: 0.0584\n",
            "Epoch 3/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.3860 - accuracy: 0.8176 - val_loss: 2.7936 - val_accuracy: 0.0584\n",
            "Epoch 4/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.3103 - accuracy: 0.8436 - val_loss: 2.8134 - val_accuracy: 0.1169\n",
            "Epoch 5/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.2795 - accuracy: 0.8518 - val_loss: 2.8455 - val_accuracy: 0.0584\n",
            "Epoch 6/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.2670 - accuracy: 0.8705 - val_loss: 2.8317 - val_accuracy: 0.1916\n",
            "Epoch 7/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.2476 - accuracy: 0.8697 - val_loss: 2.8565 - val_accuracy: 0.1169\n",
            "Epoch 8/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.2299 - accuracy: 0.8852 - val_loss: 2.8328 - val_accuracy: 0.1169\n",
            "Epoch 9/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.2117 - accuracy: 0.8917 - val_loss: 2.8513 - val_accuracy: 0.1169\n",
            "Epoch 10/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.1927 - accuracy: 0.9161 - val_loss: 2.6708 - val_accuracy: 0.1299\n",
            "Epoch 11/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.1610 - accuracy: 0.9373 - val_loss: 2.5347 - val_accuracy: 0.1916\n",
            "Epoch 12/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.1738 - accuracy: 0.9283 - val_loss: 1.8849 - val_accuracy: 0.3442\n",
            "Epoch 13/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.1448 - accuracy: 0.9381 - val_loss: 1.8004 - val_accuracy: 0.3474\n",
            "Epoch 14/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.1127 - accuracy: 0.9650 - val_loss: 1.6094 - val_accuracy: 0.4253\n",
            "Epoch 15/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.1003 - accuracy: 0.9739 - val_loss: 1.1212 - val_accuracy: 0.5097\n",
            "Epoch 16/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0550 - accuracy: 0.9870 - val_loss: 0.5351 - val_accuracy: 0.8052\n",
            "Epoch 17/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9910 - val_loss: 0.3378 - val_accuracy: 0.8734\n",
            "Epoch 18/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0497 - accuracy: 0.9886 - val_loss: 0.2740 - val_accuracy: 0.9123\n",
            "Epoch 19/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0467 - accuracy: 0.9951 - val_loss: 0.3659 - val_accuracy: 0.8831\n",
            "Epoch 20/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0308 - accuracy: 0.9959 - val_loss: 0.4713 - val_accuracy: 0.8247\n",
            "Epoch 21/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 0.9992 - val_loss: 0.0835 - val_accuracy: 0.9935\n",
            "Epoch 22/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0182 - accuracy: 0.9992 - val_loss: 0.0403 - val_accuracy: 0.9903\n",
            "Epoch 23/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0193 - accuracy: 0.9992 - val_loss: 0.0302 - val_accuracy: 0.9968\n",
            "Epoch 24/500\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 0.0225 - accuracy: 0.9976 - val_loss: 0.0410 - val_accuracy: 0.9935\n",
            "Epoch 25/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
            "Epoch 26/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
            "Epoch 27/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9935\n",
            "Epoch 28/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9968\n",
            "Epoch 29/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 30/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 31/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 32/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
            "Epoch 33/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 1.2415 - val_accuracy: 0.4513\n",
            "Epoch 34/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 0.9992 - val_loss: 0.0373 - val_accuracy: 0.9903\n",
            "Epoch 35/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9935\n",
            "Epoch 36/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
            "Epoch 37/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 38/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 39/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 40/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 41/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9968\n",
            "Epoch 42/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 43/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 44/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 45/500\n",
            "39/39 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 50/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.0549 - val_accuracy: 0.9838\n",
            "Epoch 54/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "39/39 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00125: early stopping\n",
            "Training/validation time was: 105.858 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9922\n",
            "Evaluate time was 0.298177 seconds\n",
            "0.9921875\n",
            "\n",
            "SUMMARY: \n",
            "With 120 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 99.2188 %. \n",
            "It is a difference of 0.7812 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9969969987869263, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0, 1.0, 0.9979166388511658, 1.0, 0.995192289352417, 0.9921875] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287, 112.38595223426819, 105.29911494255066, 117.06488060951233, 150.65474224090576, 105.85787105560303]\n",
            "\n",
            "---> ITERATING NOW WITH: 110 CASES ! ( 18.33 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "36/36 [==============================] - 2s 17ms/step - loss: 1.0663 - accuracy: 0.6812 - val_loss: 2.7558 - val_accuracy: 0.1099\n",
            "Epoch 2/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4652 - accuracy: 0.8126 - val_loss: 2.7656 - val_accuracy: 0.0603\n",
            "Epoch 3/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.3409 - accuracy: 0.8410 - val_loss: 2.7926 - val_accuracy: 0.0603\n",
            "Epoch 4/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.3159 - accuracy: 0.8508 - val_loss: 2.8176 - val_accuracy: 0.1099\n",
            "Epoch 5/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2777 - accuracy: 0.8650 - val_loss: 2.8313 - val_accuracy: 0.1170\n",
            "Epoch 6/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2520 - accuracy: 0.8757 - val_loss: 2.8923 - val_accuracy: 0.1170\n",
            "Epoch 7/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.2563 - accuracy: 0.8730 - val_loss: 2.9253 - val_accuracy: 0.1099\n",
            "Epoch 8/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.2164 - accuracy: 0.9050 - val_loss: 2.8839 - val_accuracy: 0.1170\n",
            "Epoch 9/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.2090 - accuracy: 0.8863 - val_loss: 2.8403 - val_accuracy: 0.1596\n",
            "Epoch 10/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1864 - accuracy: 0.9218 - val_loss: 2.9017 - val_accuracy: 0.1170\n",
            "Epoch 11/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.1856 - accuracy: 0.9192 - val_loss: 2.4760 - val_accuracy: 0.2979\n",
            "Epoch 12/500\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.1795 - accuracy: 0.9298 - val_loss: 2.3539 - val_accuracy: 0.3440\n",
            "Epoch 13/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1265 - accuracy: 0.9538 - val_loss: 2.2539 - val_accuracy: 0.4007\n",
            "Epoch 14/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1025 - accuracy: 0.9609 - val_loss: 2.0603 - val_accuracy: 0.4220\n",
            "Epoch 15/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0904 - accuracy: 0.9627 - val_loss: 1.5948 - val_accuracy: 0.4716\n",
            "Epoch 16/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.1174 - accuracy: 0.9654 - val_loss: 1.1083 - val_accuracy: 0.6773\n",
            "Epoch 17/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0819 - accuracy: 0.9698 - val_loss: 0.5838 - val_accuracy: 0.8156\n",
            "Epoch 18/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0670 - accuracy: 0.9813 - val_loss: 0.4587 - val_accuracy: 0.8085\n",
            "Epoch 19/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0554 - accuracy: 0.9822 - val_loss: 0.4329 - val_accuracy: 0.7979\n",
            "Epoch 20/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0484 - accuracy: 0.9840 - val_loss: 0.2113 - val_accuracy: 0.9433\n",
            "Epoch 21/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 0.1247 - val_accuracy: 0.9610\n",
            "Epoch 22/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0419 - accuracy: 0.9885 - val_loss: 1.7119 - val_accuracy: 0.5035\n",
            "Epoch 23/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0540 - accuracy: 0.9805 - val_loss: 0.1976 - val_accuracy: 0.9113\n",
            "Epoch 24/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0323 - accuracy: 0.9885 - val_loss: 0.1906 - val_accuracy: 0.9043\n",
            "Epoch 25/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0403 - accuracy: 0.9867 - val_loss: 0.0568 - val_accuracy: 0.9894\n",
            "Epoch 26/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 0.6161 - val_accuracy: 0.7979\n",
            "Epoch 27/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0345 - accuracy: 0.9911 - val_loss: 0.4406 - val_accuracy: 0.9043\n",
            "Epoch 28/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9938 - val_loss: 0.3301 - val_accuracy: 0.9113\n",
            "Epoch 29/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 0.9956 - val_loss: 0.2512 - val_accuracy: 0.9220\n",
            "Epoch 30/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 0.5411 - val_accuracy: 0.8688\n",
            "Epoch 31/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0193 - accuracy: 0.9964 - val_loss: 0.7726 - val_accuracy: 0.7092\n",
            "Epoch 32/500\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0473 - accuracy: 0.9831 - val_loss: 7.5713 - val_accuracy: 0.2163\n",
            "Epoch 33/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0667 - accuracy: 0.9858 - val_loss: 3.7826 - val_accuracy: 0.4043\n",
            "Epoch 34/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0402 - accuracy: 0.9929 - val_loss: 2.1742 - val_accuracy: 0.5461\n",
            "Epoch 35/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.1186 - val_accuracy: 0.9858\n",
            "Epoch 36/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0174 - accuracy: 0.9991 - val_loss: 0.7645 - val_accuracy: 0.7766\n",
            "Epoch 37/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9964 - val_loss: 0.5490 - val_accuracy: 0.8262\n",
            "Epoch 38/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 0.9991 - val_loss: 0.4577 - val_accuracy: 0.9007\n",
            "Epoch 39/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0153 - accuracy: 0.9964 - val_loss: 0.5915 - val_accuracy: 0.8262\n",
            "Epoch 40/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 0.4254 - val_accuracy: 0.9043\n",
            "Epoch 41/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 1.0443 - val_accuracy: 0.7447\n",
            "Epoch 42/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.8936\n",
            "Epoch 43/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9965\n",
            "Epoch 44/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0130 - accuracy: 0.9982 - val_loss: 0.8168 - val_accuracy: 0.7908\n",
            "Epoch 45/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9610\n",
            "Epoch 46/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9973 - val_loss: 0.0274 - val_accuracy: 0.9858\n",
            "Epoch 47/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0418 - val_accuracy: 0.9823\n",
            "Epoch 48/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.0762 - val_accuracy: 0.5887\n",
            "Epoch 49/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9716\n",
            "Epoch 50/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.1230 - val_accuracy: 0.9574\n",
            "Epoch 51/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0112 - accuracy: 0.9991 - val_loss: 0.6004 - val_accuracy: 0.8475\n",
            "Epoch 52/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9113\n",
            "Epoch 53/500\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.9007\n",
            "Epoch 54/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9858\n",
            "Epoch 55/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9894\n",
            "Epoch 56/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.1730 - val_accuracy: 0.9184\n",
            "Epoch 58/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9823\n",
            "Epoch 59/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9894\n",
            "Epoch 60/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.1304 - val_accuracy: 0.6667\n",
            "Epoch 61/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0337 - accuracy: 0.9911 - val_loss: 0.4526 - val_accuracy: 0.8369\n",
            "Epoch 62/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 0.8262\n",
            "Epoch 63/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.8546\n",
            "Epoch 64/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9716\n",
            "Epoch 65/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9894\n",
            "Epoch 66/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9823\n",
            "Epoch 67/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9965\n",
            "Epoch 68/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9965\n",
            "Epoch 69/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9965\n",
            "Epoch 71/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9965\n",
            "Epoch 72/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9858\n",
            "Epoch 74/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9894\n",
            "Epoch 75/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.0571 - val_accuracy: 0.9787\n",
            "Epoch 76/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 0.9965\n",
            "Epoch 78/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9858\n",
            "Epoch 80/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9965\n",
            "Epoch 81/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9965\n",
            "Epoch 82/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9965\n",
            "Epoch 86/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.8440\n",
            "Epoch 87/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0275 - val_accuracy: 0.9858\n",
            "Epoch 88/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9894\n",
            "Epoch 89/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0074 - accuracy: 0.9991 - val_loss: 0.0181 - val_accuracy: 0.9894\n",
            "Epoch 90/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 0.9973 - val_loss: 0.0314 - val_accuracy: 0.9894\n",
            "Epoch 91/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.4970 - val_accuracy: 0.8333\n",
            "Epoch 92/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.2084 - val_accuracy: 0.9184\n",
            "Epoch 93/500\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9787\n",
            "Epoch 94/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.0162 - val_accuracy: 0.9965\n",
            "Epoch 95/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9858\n",
            "Epoch 97/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.0177 - val_accuracy: 0.9894\n",
            "Epoch 100/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0493 - val_accuracy: 0.9787\n",
            "Epoch 101/500\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.0290 - val_accuracy: 0.9858\n",
            "Epoch 102/500\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9858\n",
            "Epoch 103/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9858\n",
            "Epoch 112/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9965\n",
            "Epoch 113/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9965\n",
            "Epoch 124/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.0173 - val_accuracy: 0.9894\n",
            "Epoch 126/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9894\n",
            "Epoch 127/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 0.9894\n",
            "Epoch 128/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9894\n",
            "Epoch 129/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9894\n",
            "Epoch 130/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9894\n",
            "Epoch 131/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9965\n",
            "Epoch 132/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9965\n",
            "Epoch 133/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0151 - val_accuracy: 0.9929\n",
            "Epoch 134/500\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9973 - val_loss: 0.0161 - val_accuracy: 0.9894\n",
            "Epoch 138/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0587 - val_accuracy: 0.9787\n",
            "Epoch 139/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9858\n",
            "Epoch 140/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9858\n",
            "Epoch 141/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9894\n",
            "Epoch 142/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9894\n",
            "Epoch 143/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00156: early stopping\n",
            "Training/validation time was: 131.93 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9972\n",
            "Evaluate time was 0.272584 seconds\n",
            "0.9971590638160706\n",
            "\n",
            "SUMMARY: \n",
            "With 110 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 99.7159 %. \n",
            "It is a difference of 0.2841 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9969969987869263, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0, 1.0, 0.9979166388511658, 1.0, 0.995192289352417, 0.9921875, 0.9971590638160706] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287, 112.38595223426819, 105.29911494255066, 117.06488060951233, 150.65474224090576, 105.85787105560303, 131.93044590950012]\n",
            "\n",
            "---> ITERATING NOW WITH: 100 CASES ! ( 16.67 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "32/32 [==============================] - 1s 15ms/step - loss: 1.1573 - accuracy: 0.6533 - val_loss: 2.7524 - val_accuracy: 0.1133\n",
            "Epoch 2/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.4508 - accuracy: 0.8096 - val_loss: 2.7561 - val_accuracy: 0.1133\n",
            "Epoch 3/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.3452 - accuracy: 0.8281 - val_loss: 2.7643 - val_accuracy: 0.1133\n",
            "Epoch 4/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2969 - accuracy: 0.8555 - val_loss: 2.7740 - val_accuracy: 0.1133\n",
            "Epoch 5/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2678 - accuracy: 0.8721 - val_loss: 2.7819 - val_accuracy: 0.1133\n",
            "Epoch 6/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2568 - accuracy: 0.8691 - val_loss: 2.7744 - val_accuracy: 0.1133\n",
            "Epoch 7/500\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.2399 - accuracy: 0.8799 - val_loss: 2.7661 - val_accuracy: 0.1133\n",
            "Epoch 8/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2523 - accuracy: 0.8770 - val_loss: 2.7711 - val_accuracy: 0.1133\n",
            "Epoch 9/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2294 - accuracy: 0.8799 - val_loss: 2.7508 - val_accuracy: 0.1133\n",
            "Epoch 10/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2149 - accuracy: 0.8936 - val_loss: 2.7251 - val_accuracy: 0.1133\n",
            "Epoch 11/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1822 - accuracy: 0.9102 - val_loss: 2.6330 - val_accuracy: 0.1133\n",
            "Epoch 12/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1902 - accuracy: 0.9297 - val_loss: 2.5372 - val_accuracy: 0.1133\n",
            "Epoch 13/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1704 - accuracy: 0.9287 - val_loss: 2.3046 - val_accuracy: 0.2344\n",
            "Epoch 14/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1355 - accuracy: 0.9531 - val_loss: 2.2270 - val_accuracy: 0.3203\n",
            "Epoch 15/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1148 - accuracy: 0.9648 - val_loss: 2.2273 - val_accuracy: 0.3242\n",
            "Epoch 16/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0875 - accuracy: 0.9805 - val_loss: 1.5234 - val_accuracy: 0.4258\n",
            "Epoch 17/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0746 - accuracy: 0.9814 - val_loss: 1.4600 - val_accuracy: 0.4258\n",
            "Epoch 18/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0549 - accuracy: 0.9863 - val_loss: 1.0203 - val_accuracy: 0.5156\n",
            "Epoch 19/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0524 - accuracy: 0.9844 - val_loss: 0.6886 - val_accuracy: 0.6836\n",
            "Epoch 20/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9883 - val_loss: 0.5233 - val_accuracy: 0.7617\n",
            "Epoch 21/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9873 - val_loss: 0.3239 - val_accuracy: 0.9102\n",
            "Epoch 22/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0375 - accuracy: 0.9844 - val_loss: 0.2831 - val_accuracy: 0.9102\n",
            "Epoch 23/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 0.3755 - val_accuracy: 0.9141\n",
            "Epoch 24/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.9922 - val_loss: 0.1468 - val_accuracy: 0.9453\n",
            "Epoch 25/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 0.9854 - val_loss: 0.2340 - val_accuracy: 0.9336\n",
            "Epoch 26/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0299 - accuracy: 0.9951 - val_loss: 0.1978 - val_accuracy: 0.9375\n",
            "Epoch 27/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9951 - val_loss: 0.1331 - val_accuracy: 0.9414\n",
            "Epoch 28/500\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0336 - accuracy: 0.9932 - val_loss: 0.2848 - val_accuracy: 0.8750\n",
            "Epoch 29/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0204 - accuracy: 0.9990 - val_loss: 0.1157 - val_accuracy: 0.9492\n",
            "Epoch 30/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0188 - accuracy: 0.9980 - val_loss: 0.1123 - val_accuracy: 0.9453\n",
            "Epoch 31/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0722 - val_accuracy: 0.9922\n",
            "Epoch 32/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9336\n",
            "Epoch 33/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9805\n",
            "Epoch 34/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0178 - accuracy: 0.9971 - val_loss: 0.0497 - val_accuracy: 0.9805\n",
            "Epoch 35/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9961\n",
            "Epoch 36/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9727\n",
            "Epoch 37/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9844\n",
            "Epoch 38/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9961\n",
            "Epoch 39/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
            "Epoch 40/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 0.9990 - val_loss: 0.1729 - val_accuracy: 0.9375\n",
            "Epoch 41/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 0.9990 - val_loss: 0.0611 - val_accuracy: 0.9766\n",
            "Epoch 42/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9961\n",
            "Epoch 43/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
            "Epoch 44/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9805\n",
            "Epoch 45/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9922\n",
            "Epoch 46/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0112 - accuracy: 0.9990 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0175 - accuracy: 0.9971 - val_loss: 0.0298 - val_accuracy: 0.9961\n",
            "Epoch 50/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9922\n",
            "Epoch 51/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9805\n",
            "Epoch 52/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9844\n",
            "Epoch 53/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9922\n",
            "Epoch 54/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 0.9990 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9961\n",
            "Epoch 60/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9961\n",
            "Epoch 69/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9990 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0155 - val_accuracy: 0.9961\n",
            "Epoch 91/500\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 0.9990 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00139: early stopping\n",
            "Training/validation time was: 109.666 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9969\n",
            "Evaluate time was 0.0808821 seconds\n",
            "0.996874988079071\n",
            "\n",
            "SUMMARY: \n",
            "With 100 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 99.6875 %. \n",
            "It is a difference of 0.3125 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110, 100] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9969969987869263, 1.0, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0, 1.0, 0.9979166388511658, 1.0, 0.995192289352417, 0.9921875, 0.9971590638160706, 0.996874988079071] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287, 112.38595223426819, 105.29911494255066, 117.06488060951233, 150.65474224090576, 105.85787105560303, 131.93044590950012, 109.66640210151672]\n",
            "\n",
            "---> ITERATING NOW WITH: 90 CASES ! ( 15.00 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110, 100] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "29/29 [==============================] - 2s 19ms/step - loss: 1.0864 - accuracy: 0.6971 - val_loss: 2.7686 - val_accuracy: 0.0476\n",
            "Epoch 2/500\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 0.3751 - accuracy: 0.8578 - val_loss: 2.7770 - val_accuracy: 0.0476\n",
            "Epoch 3/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.3147 - accuracy: 0.8643 - val_loss: 2.7822 - val_accuracy: 0.1299\n",
            "Epoch 4/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.2594 - accuracy: 0.8849 - val_loss: 2.7904 - val_accuracy: 0.1082\n",
            "Epoch 5/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.2472 - accuracy: 0.8806 - val_loss: 2.7921 - val_accuracy: 0.0693\n",
            "Epoch 6/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.2264 - accuracy: 0.8860 - val_loss: 2.7897 - val_accuracy: 0.0693\n",
            "Epoch 7/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.2163 - accuracy: 0.8871 - val_loss: 2.7617 - val_accuracy: 0.1645\n",
            "Epoch 8/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.1916 - accuracy: 0.9164 - val_loss: 2.7116 - val_accuracy: 0.1602\n",
            "Epoch 9/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.1832 - accuracy: 0.9131 - val_loss: 2.6573 - val_accuracy: 0.1602\n",
            "Epoch 10/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.1670 - accuracy: 0.9207 - val_loss: 2.5982 - val_accuracy: 0.1645\n",
            "Epoch 11/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.1371 - accuracy: 0.9392 - val_loss: 2.5313 - val_accuracy: 0.1688\n",
            "Epoch 12/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.1364 - accuracy: 0.9305 - val_loss: 2.4919 - val_accuracy: 0.1948\n",
            "Epoch 13/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.1341 - accuracy: 0.9370 - val_loss: 2.3818 - val_accuracy: 0.3160\n",
            "Epoch 14/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.1153 - accuracy: 0.9490 - val_loss: 2.2945 - val_accuracy: 0.3247\n",
            "Epoch 15/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.1117 - accuracy: 0.9490 - val_loss: 2.2184 - val_accuracy: 0.3636\n",
            "Epoch 16/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.1007 - accuracy: 0.9631 - val_loss: 1.7956 - val_accuracy: 0.3939\n",
            "Epoch 17/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.1155 - accuracy: 0.9435 - val_loss: 1.4962 - val_accuracy: 0.4892\n",
            "Epoch 18/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.1125 - accuracy: 0.9468 - val_loss: 1.2833 - val_accuracy: 0.5281\n",
            "Epoch 19/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0946 - accuracy: 0.9609 - val_loss: 1.3274 - val_accuracy: 0.4978\n",
            "Epoch 20/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0779 - accuracy: 0.9837 - val_loss: 1.4165 - val_accuracy: 0.5455\n",
            "Epoch 21/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0860 - accuracy: 0.9620 - val_loss: 0.5220 - val_accuracy: 0.8182\n",
            "Epoch 22/500\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 0.0748 - accuracy: 0.9750 - val_loss: 0.5999 - val_accuracy: 0.7662\n",
            "Epoch 23/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0511 - accuracy: 0.9870 - val_loss: 0.6108 - val_accuracy: 0.8398\n",
            "Epoch 24/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0449 - accuracy: 0.9935 - val_loss: 0.7426 - val_accuracy: 0.8485\n",
            "Epoch 25/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0307 - accuracy: 0.9957 - val_loss: 0.5406 - val_accuracy: 0.9004\n",
            "Epoch 26/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0303 - accuracy: 0.9935 - val_loss: 0.6485 - val_accuracy: 0.8918\n",
            "Epoch 27/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0264 - accuracy: 0.9989 - val_loss: 0.7136 - val_accuracy: 0.8788\n",
            "Epoch 28/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 0.9957 - val_loss: 0.4309 - val_accuracy: 0.9004\n",
            "Epoch 29/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.8549 - val_accuracy: 0.8095\n",
            "Epoch 30/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9307\n",
            "Epoch 31/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0178 - accuracy: 0.9978 - val_loss: 0.5048 - val_accuracy: 0.9091\n",
            "Epoch 32/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0141 - accuracy: 0.9989 - val_loss: 0.6474 - val_accuracy: 0.8874\n",
            "Epoch 33/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0175 - accuracy: 0.9989 - val_loss: 0.5423 - val_accuracy: 0.8961\n",
            "Epoch 34/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9870\n",
            "Epoch 35/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9177\n",
            "Epoch 36/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9177\n",
            "Epoch 37/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9957\n",
            "Epoch 38/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0112 - accuracy: 0.9989 - val_loss: 0.3174 - val_accuracy: 0.9221\n",
            "Epoch 39/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9913\n",
            "Epoch 40/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9221\n",
            "Epoch 41/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9870\n",
            "Epoch 42/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9913\n",
            "Epoch 43/500\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
            "Epoch 44/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9957\n",
            "Epoch 45/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9957\n",
            "Epoch 46/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9091\n",
            "Epoch 47/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9307\n",
            "Epoch 48/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 0.2258 - val_accuracy: 0.9221\n",
            "Epoch 49/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 0.9957\n",
            "Epoch 50/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9957\n",
            "Epoch 51/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 0.0202 - val_accuracy: 0.9957\n",
            "Epoch 52/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9264\n",
            "Epoch 53/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9957\n",
            "Epoch 57/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9610\n",
            "Epoch 59/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.0535 - val_accuracy: 0.9827\n",
            "Epoch 65/500\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9957\n",
            "Epoch 66/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9913\n",
            "Epoch 72/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 0.9957\n",
            "Epoch 110/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00143: early stopping\n",
            "Training/validation time was: 114.893 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 1.0000\n",
            "Evaluate time was 0.27874 seconds\n",
            "1.0\n",
            "\n",
            "SUMMARY: \n",
            "With 90 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 100.0000 %. \n",
            "It is a difference of 0.0000 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110, 100, 90] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9969969987869263, 1.0, 1.0, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0, 1.0, 0.9979166388511658, 1.0, 0.995192289352417, 0.9921875, 0.9971590638160706, 0.996874988079071, 1.0] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287, 112.38595223426819, 105.29911494255066, 117.06488060951233, 150.65474224090576, 105.85787105560303, 131.93044590950012, 109.66640210151672, 114.89259839057922]\n",
            "\n",
            "---> ITERATING NOW WITH: 80 CASES ! ( 13.33 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110, 100, 90] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "26/26 [==============================] - 2s 20ms/step - loss: 1.2244 - accuracy: 0.6410 - val_loss: 2.7610 - val_accuracy: 0.0634\n",
            "Epoch 2/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3667 - accuracy: 0.8706 - val_loss: 2.7562 - val_accuracy: 0.0780\n",
            "Epoch 3/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3428 - accuracy: 0.8400 - val_loss: 2.7546 - val_accuracy: 0.0780\n",
            "Epoch 4/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2776 - accuracy: 0.8694 - val_loss: 2.7465 - val_accuracy: 0.1073\n",
            "Epoch 5/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2789 - accuracy: 0.8681 - val_loss: 2.7437 - val_accuracy: 0.1073\n",
            "Epoch 6/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2376 - accuracy: 0.8645 - val_loss: 2.7379 - val_accuracy: 0.1073\n",
            "Epoch 7/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2225 - accuracy: 0.8852 - val_loss: 2.7153 - val_accuracy: 0.1073\n",
            "Epoch 8/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2170 - accuracy: 0.8926 - val_loss: 2.6911 - val_accuracy: 0.1073\n",
            "Epoch 9/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2124 - accuracy: 0.8974 - val_loss: 2.6548 - val_accuracy: 0.1073\n",
            "Epoch 10/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1854 - accuracy: 0.9133 - val_loss: 2.6273 - val_accuracy: 0.1561\n",
            "Epoch 11/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1960 - accuracy: 0.8913 - val_loss: 2.5861 - val_accuracy: 0.2098\n",
            "Epoch 12/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1638 - accuracy: 0.9304 - val_loss: 2.5103 - val_accuracy: 0.1561\n",
            "Epoch 13/500\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.1495 - accuracy: 0.9512 - val_loss: 2.4719 - val_accuracy: 0.1902\n",
            "Epoch 14/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1837 - accuracy: 0.9255 - val_loss: 2.3520 - val_accuracy: 0.1902\n",
            "Epoch 15/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1381 - accuracy: 0.9426 - val_loss: 2.2689 - val_accuracy: 0.2195\n",
            "Epoch 16/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1216 - accuracy: 0.9487 - val_loss: 2.1327 - val_accuracy: 0.2927\n",
            "Epoch 17/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1041 - accuracy: 0.9634 - val_loss: 1.9266 - val_accuracy: 0.2976\n",
            "Epoch 18/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1384 - accuracy: 0.9353 - val_loss: 2.0136 - val_accuracy: 0.3171\n",
            "Epoch 19/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1405 - accuracy: 0.9377 - val_loss: 1.4241 - val_accuracy: 0.5122\n",
            "Epoch 20/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0981 - accuracy: 0.9670 - val_loss: 1.1369 - val_accuracy: 0.6293\n",
            "Epoch 21/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0735 - accuracy: 0.9817 - val_loss: 0.9456 - val_accuracy: 0.7073\n",
            "Epoch 22/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0563 - accuracy: 0.9829 - val_loss: 0.9518 - val_accuracy: 0.8390\n",
            "Epoch 23/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0626 - accuracy: 0.9866 - val_loss: 0.7279 - val_accuracy: 0.7659\n",
            "Epoch 24/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.9915 - val_loss: 0.5934 - val_accuracy: 0.7805\n",
            "Epoch 25/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0326 - accuracy: 0.9915 - val_loss: 0.5381 - val_accuracy: 0.8585\n",
            "Epoch 26/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0314 - accuracy: 0.9915 - val_loss: 0.3771 - val_accuracy: 0.9317\n",
            "Epoch 27/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9939 - val_loss: 0.2627 - val_accuracy: 0.9756\n",
            "Epoch 28/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0189 - accuracy: 0.9976 - val_loss: 0.2186 - val_accuracy: 0.9317\n",
            "Epoch 29/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0190 - accuracy: 0.9988 - val_loss: 0.1513 - val_accuracy: 0.9073\n",
            "Epoch 30/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9976 - val_loss: 0.1042 - val_accuracy: 0.9366\n",
            "Epoch 31/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9366\n",
            "Epoch 32/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
            "Epoch 33/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.8927\n",
            "Epoch 34/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9415\n",
            "Epoch 35/500\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.0222 - accuracy: 0.9963 - val_loss: 0.3292 - val_accuracy: 0.9220\n",
            "Epoch 36/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0153 - accuracy: 0.9988 - val_loss: 0.2164 - val_accuracy: 0.8780\n",
            "Epoch 37/500\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
            "Epoch 38/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 1.0000\n",
            "Epoch 39/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9805\n",
            "Epoch 40/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9951\n",
            "Epoch 41/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 42/500\n",
            "26/26 [==============================] - 0s 11ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
            "Epoch 43/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0168 - accuracy: 0.9988 - val_loss: 0.0517 - val_accuracy: 0.9756\n",
            "Epoch 44/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 45/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 50/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9951\n",
            "Epoch 67/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9951\n",
            "Epoch 69/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "26/26 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "26/26 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00132: early stopping\n",
            "Training/validation time was: 100.758 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9961\n",
            "Evaluate time was 0.270513 seconds\n",
            "0.99609375\n",
            "\n",
            "SUMMARY: \n",
            "With 80 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 99.6094 %. \n",
            "It is a difference of 0.3906 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110, 100, 90, 80] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9969969987869263, 1.0, 1.0, 1.0, 1.0, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0, 1.0, 0.9979166388511658, 1.0, 0.995192289352417, 0.9921875, 0.9971590638160706, 0.996874988079071, 1.0, 0.99609375] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287, 112.38595223426819, 105.29911494255066, 117.06488060951233, 150.65474224090576, 105.85787105560303, 131.93044590950012, 109.66640210151672, 114.89259839057922, 100.75834488868713]\n",
            "\n",
            "---> ITERATING NOW WITH: 70 CASES ! ( 11.67 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110, 100, 90, 80] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "23/23 [==============================] - 2s 21ms/step - loss: 1.2496 - accuracy: 0.6578 - val_loss: 2.7553 - val_accuracy: 0.1389\n",
            "Epoch 2/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.3874 - accuracy: 0.8631 - val_loss: 2.7526 - val_accuracy: 0.0556\n",
            "Epoch 3/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.3060 - accuracy: 0.8729 - val_loss: 2.7409 - val_accuracy: 0.0556\n",
            "Epoch 4/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.2559 - accuracy: 0.8841 - val_loss: 2.7382 - val_accuracy: 0.0556\n",
            "Epoch 5/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.2336 - accuracy: 0.8771 - val_loss: 2.7282 - val_accuracy: 0.1000\n",
            "Epoch 6/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.2233 - accuracy: 0.8953 - val_loss: 2.7175 - val_accuracy: 0.1222\n",
            "Epoch 7/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.2091 - accuracy: 0.9008 - val_loss: 2.6944 - val_accuracy: 0.1222\n",
            "Epoch 8/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.2215 - accuracy: 0.8813 - val_loss: 2.6767 - val_accuracy: 0.1222\n",
            "Epoch 9/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.2192 - accuracy: 0.8939 - val_loss: 2.6380 - val_accuracy: 0.1222\n",
            "Epoch 10/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1946 - accuracy: 0.9078 - val_loss: 2.6119 - val_accuracy: 0.1778\n",
            "Epoch 11/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1714 - accuracy: 0.8980 - val_loss: 2.5774 - val_accuracy: 0.1944\n",
            "Epoch 12/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1915 - accuracy: 0.8911 - val_loss: 2.5549 - val_accuracy: 0.1778\n",
            "Epoch 13/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1498 - accuracy: 0.9134 - val_loss: 2.5065 - val_accuracy: 0.1778\n",
            "Epoch 14/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1342 - accuracy: 0.9302 - val_loss: 2.4759 - val_accuracy: 0.1778\n",
            "Epoch 15/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1347 - accuracy: 0.9288 - val_loss: 2.4418 - val_accuracy: 0.1833\n",
            "Epoch 16/500\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.1304 - accuracy: 0.9372 - val_loss: 2.3303 - val_accuracy: 0.1778\n",
            "Epoch 17/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1138 - accuracy: 0.9441 - val_loss: 2.2451 - val_accuracy: 0.1833\n",
            "Epoch 18/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1127 - accuracy: 0.9553 - val_loss: 2.1216 - val_accuracy: 0.1611\n",
            "Epoch 19/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.1042 - accuracy: 0.9372 - val_loss: 2.0089 - val_accuracy: 0.2333\n",
            "Epoch 20/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.1165 - accuracy: 0.9274 - val_loss: 1.7694 - val_accuracy: 0.2833\n",
            "Epoch 21/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.1010 - accuracy: 0.9469 - val_loss: 1.7429 - val_accuracy: 0.3722\n",
            "Epoch 22/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0997 - accuracy: 0.9427 - val_loss: 1.5674 - val_accuracy: 0.3944\n",
            "Epoch 23/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0936 - accuracy: 0.9679 - val_loss: 1.0376 - val_accuracy: 0.6222\n",
            "Epoch 24/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.1004 - accuracy: 0.9665 - val_loss: 1.2966 - val_accuracy: 0.5944\n",
            "Epoch 25/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0973 - accuracy: 0.9539 - val_loss: 1.2334 - val_accuracy: 0.7389\n",
            "Epoch 26/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0704 - accuracy: 0.9749 - val_loss: 1.0855 - val_accuracy: 0.7722\n",
            "Epoch 27/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0806 - accuracy: 0.9707 - val_loss: 0.9310 - val_accuracy: 0.7444\n",
            "Epoch 28/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0753 - accuracy: 0.9832 - val_loss: 1.1995 - val_accuracy: 0.6444\n",
            "Epoch 29/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0599 - accuracy: 0.9860 - val_loss: 0.7547 - val_accuracy: 0.8667\n",
            "Epoch 30/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0472 - accuracy: 0.9944 - val_loss: 0.5414 - val_accuracy: 0.9278\n",
            "Epoch 31/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0392 - accuracy: 0.9986 - val_loss: 0.3863 - val_accuracy: 0.8778\n",
            "Epoch 32/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0323 - accuracy: 0.9958 - val_loss: 0.5140 - val_accuracy: 0.8000\n",
            "Epoch 33/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0655 - accuracy: 0.9763 - val_loss: 1.8275 - val_accuracy: 0.4722\n",
            "Epoch 34/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 0.9958 - val_loss: 1.3925 - val_accuracy: 0.6167\n",
            "Epoch 35/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.0394 - val_accuracy: 0.7000\n",
            "Epoch 36/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0173 - accuracy: 0.9972 - val_loss: 0.9301 - val_accuracy: 0.7333\n",
            "Epoch 37/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.8106 - val_accuracy: 0.7778\n",
            "Epoch 38/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0197 - accuracy: 0.9986 - val_loss: 0.1092 - val_accuracy: 0.9778\n",
            "Epoch 39/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0170 - accuracy: 0.9986 - val_loss: 0.2335 - val_accuracy: 0.9333\n",
            "Epoch 40/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.8722\n",
            "Epoch 41/500\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0112 - accuracy: 0.9986 - val_loss: 0.4623 - val_accuracy: 0.8778\n",
            "Epoch 42/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8778\n",
            "Epoch 43/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.8556\n",
            "Epoch 44/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.1647 - val_accuracy: 0.9111\n",
            "Epoch 45/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.8722\n",
            "Epoch 46/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.1394 - val_accuracy: 0.9333\n",
            "Epoch 47/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9778\n",
            "Epoch 48/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.0222 - val_accuracy: 0.9944\n",
            "Epoch 49/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9333\n",
            "Epoch 50/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9944\n",
            "Epoch 51/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9611\n",
            "Epoch 52/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9944\n",
            "Epoch 53/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9778\n",
            "Epoch 54/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9667\n",
            "Epoch 55/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9778\n",
            "Epoch 56/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9389\n",
            "Epoch 57/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9944\n",
            "Epoch 58/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.0524 - val_accuracy: 0.9944\n",
            "Epoch 59/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9778\n",
            "Epoch 60/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0097 - accuracy: 0.9986 - val_loss: 0.0127 - val_accuracy: 0.9944\n",
            "Epoch 61/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9778\n",
            "Epoch 62/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9944\n",
            "Epoch 63/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 0.9944\n",
            "Epoch 64/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9444\n",
            "Epoch 65/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9944\n",
            "Epoch 66/500\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9944\n",
            "Epoch 67/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9944\n",
            "Epoch 68/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9944\n",
            "Epoch 69/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9944\n",
            "Epoch 70/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9889\n",
            "Epoch 71/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9444\n",
            "Epoch 72/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9778\n",
            "Epoch 73/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9944\n",
            "Epoch 74/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0222 - val_accuracy: 0.9944\n",
            "Epoch 75/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 0.9833\n",
            "Epoch 76/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0115 - val_accuracy: 0.9944\n",
            "Epoch 77/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9944\n",
            "Epoch 78/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9944\n",
            "Epoch 79/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0427 - val_accuracy: 0.9944\n",
            "Epoch 80/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9944\n",
            "Epoch 81/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.8833\n",
            "Epoch 82/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9944\n",
            "Epoch 83/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9944\n",
            "Epoch 84/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0133 - val_accuracy: 0.9944\n",
            "Epoch 85/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9944\n",
            "Epoch 86/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9944\n",
            "Epoch 87/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 0.9944\n",
            "Epoch 88/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9944\n",
            "Epoch 89/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9944\n",
            "Epoch 90/500\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9944\n",
            "Epoch 91/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9944\n",
            "Epoch 92/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9944\n",
            "Epoch 93/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9944\n",
            "Epoch 94/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9944\n",
            "Epoch 95/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.2002 - val_accuracy: 0.9333\n",
            "Epoch 96/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9833\n",
            "Epoch 97/500\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9889\n",
            "Epoch 98/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.0283 - val_accuracy: 0.9944\n",
            "Epoch 99/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9944\n",
            "Epoch 100/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9944\n",
            "Epoch 101/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9889\n",
            "Epoch 102/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9444\n",
            "Epoch 103/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
            "Epoch 104/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9944\n",
            "Epoch 105/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0202 - val_accuracy: 0.9944\n",
            "Epoch 106/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9944\n",
            "Epoch 107/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9944\n",
            "Epoch 108/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 0.9944\n",
            "Epoch 109/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9944\n",
            "Epoch 110/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9944\n",
            "Epoch 111/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9944\n",
            "Epoch 112/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9944\n",
            "Epoch 113/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9944\n",
            "Epoch 114/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9944\n",
            "Epoch 115/500\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9944\n",
            "Epoch 116/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9944\n",
            "Epoch 117/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9944\n",
            "Epoch 118/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9944\n",
            "Epoch 119/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9944\n",
            "Epoch 120/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9944\n",
            "Epoch 121/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9944\n",
            "Epoch 122/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9944\n",
            "Epoch 123/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9944\n",
            "Epoch 124/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9944\n",
            "Epoch 125/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9944\n",
            "Epoch 126/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9944\n",
            "Epoch 127/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9944\n",
            "Epoch 128/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9944\n",
            "Epoch 129/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9944\n",
            "Epoch 130/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9944\n",
            "Epoch 131/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9944\n",
            "Epoch 132/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9944\n",
            "Epoch 133/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9944\n",
            "Epoch 134/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9944\n",
            "Epoch 135/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9944\n",
            "Epoch 136/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9944\n",
            "Epoch 137/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9944\n",
            "Epoch 138/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9944\n",
            "Epoch 139/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9944\n",
            "Epoch 140/500\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9944\n",
            "Epoch 141/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9944\n",
            "Epoch 142/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9944\n",
            "Epoch 143/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9944\n",
            "Epoch 144/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9944\n",
            "Epoch 145/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9944\n",
            "Epoch 146/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9944\n",
            "Epoch 147/500\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9944\n",
            "Epoch 148/500\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9944\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00148: early stopping\n",
            "Training/validation time was: 108.401 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Evaluate time was 0.254553 seconds\n",
            "1.0\n",
            "\n",
            "SUMMARY: \n",
            "With 70 cases, the max val_accuracy was: 99.4444 % and the test_accuracy was: 100.0000 %. \n",
            "It is a difference of -0.5556 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110, 100, 90, 80, 70] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9969969987869263, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9944444298744202] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0, 1.0, 0.9979166388511658, 1.0, 0.995192289352417, 0.9921875, 0.9971590638160706, 0.996874988079071, 1.0, 0.99609375, 1.0] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287, 112.38595223426819, 105.29911494255066, 117.06488060951233, 150.65474224090576, 105.85787105560303, 131.93044590950012, 109.66640210151672, 114.89259839057922, 100.75834488868713, 108.40132331848145]\n",
            "\n",
            "---> ITERATING NOW WITH: 60 CASES ! ( 10.00 % FROM TOTAL ) \n",
            "----> AND THE HISTORY OF CASES DECREASE IS: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110, 100, 90, 80, 70] \n",
            " \n",
            "TRAINING AND VALIDATING THE MODEL: \n",
            "It will take a while ;D...\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 2s 23ms/step - loss: 1.3754 - accuracy: 0.5993 - val_loss: 2.7611 - val_accuracy: 0.1364\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.3818 - accuracy: 0.8648 - val_loss: 2.7603 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.4047 - accuracy: 0.8599 - val_loss: 2.7583 - val_accuracy: 0.0909\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2356 - accuracy: 0.8811 - val_loss: 2.7660 - val_accuracy: 0.1169\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2454 - accuracy: 0.8844 - val_loss: 2.7746 - val_accuracy: 0.1104\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3133 - accuracy: 0.8811 - val_loss: 2.7848 - val_accuracy: 0.0909\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1938 - accuracy: 0.9039 - val_loss: 2.7804 - val_accuracy: 0.1169\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2067 - accuracy: 0.9039 - val_loss: 2.7812 - val_accuracy: 0.1169\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1806 - accuracy: 0.9007 - val_loss: 2.7907 - val_accuracy: 0.1818\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1562 - accuracy: 0.9332 - val_loss: 2.7854 - val_accuracy: 0.1818\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1688 - accuracy: 0.9072 - val_loss: 2.7690 - val_accuracy: 0.1818\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1589 - accuracy: 0.9153 - val_loss: 2.7535 - val_accuracy: 0.1818\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1374 - accuracy: 0.9365 - val_loss: 2.7240 - val_accuracy: 0.0909\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1335 - accuracy: 0.9365 - val_loss: 2.7358 - val_accuracy: 0.1818\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1214 - accuracy: 0.9316 - val_loss: 2.6903 - val_accuracy: 0.1818\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1543 - accuracy: 0.9137 - val_loss: 2.5662 - val_accuracy: 0.1818\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0995 - accuracy: 0.9625 - val_loss: 2.5356 - val_accuracy: 0.1818\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0925 - accuracy: 0.9609 - val_loss: 2.4242 - val_accuracy: 0.1883\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1000 - accuracy: 0.9495 - val_loss: 2.3481 - val_accuracy: 0.1818\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0754 - accuracy: 0.9772 - val_loss: 2.2840 - val_accuracy: 0.2208\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1122 - accuracy: 0.9397 - val_loss: 2.2343 - val_accuracy: 0.2338\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.1207 - accuracy: 0.9414 - val_loss: 1.8330 - val_accuracy: 0.3117\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0893 - accuracy: 0.9495 - val_loss: 1.5376 - val_accuracy: 0.4416\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0937 - accuracy: 0.9479 - val_loss: 1.5055 - val_accuracy: 0.4351\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1118 - accuracy: 0.9316 - val_loss: 1.4098 - val_accuracy: 0.4870\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0855 - accuracy: 0.9577 - val_loss: 1.7654 - val_accuracy: 0.3377\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0918 - accuracy: 0.9658 - val_loss: 1.1145 - val_accuracy: 0.6623\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0718 - accuracy: 0.9756 - val_loss: 1.8297 - val_accuracy: 0.4351\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0607 - accuracy: 0.9837 - val_loss: 2.0387 - val_accuracy: 0.5065\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0551 - accuracy: 0.9821 - val_loss: 0.6751 - val_accuracy: 0.8247\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0795 - accuracy: 0.9723 - val_loss: 1.6236 - val_accuracy: 0.5195\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0727 - accuracy: 0.9772 - val_loss: 0.5126 - val_accuracy: 0.7662\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0552 - accuracy: 0.9870 - val_loss: 0.3947 - val_accuracy: 0.8571\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0601 - accuracy: 0.9837 - val_loss: 1.4653 - val_accuracy: 0.6623\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0397 - accuracy: 0.9935 - val_loss: 0.6218 - val_accuracy: 0.7403\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.9886 - val_loss: 0.2747 - val_accuracy: 0.8961\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0382 - accuracy: 0.9870 - val_loss: 0.3357 - val_accuracy: 0.8961\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9740\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.5197 - val_accuracy: 0.8506\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9984 - val_loss: 0.2809 - val_accuracy: 0.9156\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9091\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9286\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8544 - val_accuracy: 0.7597\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9221\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.9156\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.7987\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9156\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 0.9984 - val_loss: 0.2566 - val_accuracy: 0.9156\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9156\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9286\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9286\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9221\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9286\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9091\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9091\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9286\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9545\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 9.5477 - val_accuracy: 0.2727\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0178 - accuracy: 0.9984 - val_loss: 4.8727 - val_accuracy: 0.4091\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.5566 - val_accuracy: 0.5065\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.8701\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.8766\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.8896\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9091\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9870\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9091\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9870\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9870\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7322 - val_accuracy: 0.8377\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0123 - accuracy: 0.9935 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9870\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9935\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8552 - val_accuracy: 0.8506\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6464 - val_accuracy: 0.8636\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5896 - val_accuracy: 0.8701\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.8961\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9740\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9805\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9935\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9870\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9286\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9935\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 0.9805\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9221\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00157: early stopping\n",
            "Training/validation time was: 110.443 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9844\n",
            "Evaluate time was 0.264258 seconds\n",
            "0.984375\n",
            "\n",
            "SUMMARY: \n",
            "With 60 cases, the max val_accuracy was: 100.0000 % and the test_accuracy was: 98.4375 %. \n",
            "It is a difference of 1.5625 %.\n",
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110, 100, 90, 80, 70, 60] \n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9969969987869263, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9944444298744202, 1.0] \n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0, 1.0, 0.9979166388511658, 1.0, 0.995192289352417, 0.9921875, 0.9971590638160706, 0.996874988079071, 1.0, 0.99609375, 1.0, 0.984375] \n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287, 112.38595223426819, 105.29911494255066, 117.06488060951233, 150.65474224090576, 105.85787105560303, 131.93044590950012, 109.66640210151672, 114.89259839057922, 100.75834488868713, 108.40132331848145, 110.4432852268219]\n",
            "\n",
            "HILL CLIMBING: For the configured step, was possible to reduce the dataset to 60 cases, with test_accuracy of 0.9721590876579285\n",
            "\n",
            "The fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285] \n",
            "The cases decrease history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110, 100, 90, 80, 70, 60]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3RSl536yrnr"
      },
      "source": [
        "## 4.1 First stage simulation results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqsp-KxojciJ"
      },
      "source": [
        "**Chart comparing the history of fitness values with the reduction of cases.**\n",
        "\n",
        "* Remembering that, due to the way the optimizer was implemented (aiming at the reduction of cases - climbdown), *only the iterations in which there was a reduction in the test accuracy will be recorded in this graph*. Note that a given round of iteration, with a smaller number of cases, does not always mean that it will deliver less accuracy than the previous round (stochastic characteristic of the tool).\n",
        "\n",
        "* In order to investigate the \"real\" variation of the test accuracy during optimization process, subsequent graphs should be analyzed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0NUO52BypuD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "0189086d-1d7d-402c-81eb-f8b415a46409"
      },
      "source": [
        "# Tamanho da figura:\n",
        "plt.figure(figsize=(10,10))\n",
        "# Configuração dos parâmetros da linha:\n",
        "plt.plot(n_cases_hist, fitness_hist, color = 'black')\n",
        "# Título do gráfico:\n",
        "plt.title('Fitness vs. cases', fontsize=20)\n",
        "# Título do eixo \"x\":\n",
        "plt.xlabel('Case quantity',fontsize=18)\n",
        "# Título do eixo \"y\":\n",
        "plt.ylabel('Fitness',fontsize=18)\n",
        "# Escala de plotagem (linear, log, symlog, etc):\n",
        "plt.yscale('linear')\n",
        "# Inversão do eixo x (n_cases_hist) para correta projeção da redução de casos:\n",
        "ax = plt.gca()\n",
        "ax.invert_xaxis()\n",
        "# Inserir grid ao gráfico:\n",
        "plt.grid()\n",
        "# Controle da resolução dos eixos (quantidade de 'thicks'):\n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(.005)) # Eixo 'y'.\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(25))   # Eixo 'x'.\n",
        "# Visualização do gráfico:\n",
        "plt.show()\n",
        "\n",
        "#Para salvar no Drive...\n",
        "#plt.savefig('/content/drive/My Drive/MESTRADO - UFES/Fitness.png', transparent=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zNwdrDSiOcp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2709f399-031d-4e78-8b06-4a772b6e5f1e"
      },
      "source": [
        "# Plotando as listas com os dados do histórico de otimização:\n",
        "# (Caso queira armazenar tabulado no Excel, para segurança)\n",
        "\n",
        "print('Fitness history is:', fitness_hist)\n",
        "print('Cases history is:', n_cases_hist)\n",
        "print('acc_val history is:', acc_val_hist)\n",
        "print('acc_test history is:', acc_test_hist)\n",
        "print('Times history is:', time_hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitness history is: [1, 0.9973958134651184, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9751059412956238, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285, 0.9721590876579285]\n",
            "Cases history is: [600, 590, 580, 570, 560, 550, 540, 530, 520, 510, 500, 490, 480, 470, 460, 450, 440, 430, 420, 410, 400, 390, 380, 370, 360, 350, 340, 330, 320, 310, 300, 290, 280, 270, 260, 250, 240, 230, 220, 210, 200, 190, 180, 170, 160, 150, 140, 130, 120, 110, 100, 90, 80, 70, 60]\n",
            "acc_val history is: [0.9973958134651184, 0.9768365025520325, 1.0, 1.0, 1.0, 0.9708806872367859, 1.0, 1.0, 0.9977477192878723, 0.9992343187332153, 0.999218761920929, 0.9992032051086426, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.9989989995956421, 0.9989722371101379, 1.0, 1.0, 1.0, 1.0, 0.997633159160614, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9969969987869263, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9944444298744202, 1.0]\n",
            "acc_test history is: [0.9973958134651184, 0.9751059412956238, 0.9994612336158752, 1.0, 0.9994419813156128, 0.9721590876579285, 0.9994212985038757, 0.9988207817077637, 0.995192289352417, 0.999387264251709, 0.9987499713897705, 0.9993622303009033, 0.9986979365348816, 0.9960106611251831, 0.998641312122345, 0.9965277910232544, 1.0, 0.9963662624359131, 0.9947916865348816, 0.9977133870124817, 0.9976562261581421, 0.9983974099159241, 0.9991776347160339, 1.0, 1.0, 0.9991071224212646, 1.0, 0.9943181872367859, 1.0, 0.9989919066429138, 0.9947916865348816, 0.9946120977401733, 0.9955357313156128, 0.9988425970077515, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.996874988079071, 0.9950658082962036, 0.9965277910232544, 1.0, 1.0, 0.9979166388511658, 1.0, 0.995192289352417, 0.9921875, 0.9971590638160706, 0.996874988079071, 1.0, 0.99609375, 1.0, 0.984375]\n",
            "Times history is: [203.83462858200073, 524.9487881660461, 237.94456267356873, 220.47466492652893, 245.26830530166626, 197.60819101333618, 240.1818287372589, 439.37347054481506, 239.39095902442932, 234.72545289993286, 179.53890419006348, 217.81174278259277, 234.00045156478882, 208.60470938682556, 218.41187000274658, 172.61667728424072, 196.76399993896484, 186.62631011009216, 216.51739931106567, 186.60415077209473, 192.93345165252686, 322.51677989959717, 172.5132372379303, 177.64870834350586, 181.64379954338074, 148.98605298995972, 168.82949090003967, 205.92917203903198, 172.16883325576782, 162.23333954811096, 146.44171977043152, 149.47154426574707, 156.7227897644043, 158.1405644416809, 161.09909319877625, 130.08673572540283, 154.9602508544922, 148.24799227714539, 125.165842294693, 132.93589043617249, 138.7548451423645, 122.34941148757935, 123.11575627326965, 123.41410732269287, 112.38595223426819, 105.29911494255066, 117.06488060951233, 150.65474224090576, 105.85787105560303, 131.93044590950012, 109.66640210151672, 114.89259839057922, 100.75834488868713, 108.40132331848145, 110.4432852268219]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDpIEZdUjy4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74436e9-3c5b-461a-92a5-33d098a8c0aa"
      },
      "source": [
        "print(sum(time_hist))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9944.911436796188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkytXx-tk0k8"
      },
      "source": [
        "**Referring to the last model that delivered test accuracy >= 95 %, the following graphs are available:**\n",
        "\n",
        "* Training accuracy vs. training validation;\n",
        "\n",
        "* Loss in training vs. loss in validation.\n",
        "\n",
        "**Referring to the optimization history, the following graphs are available:**\n",
        "\n",
        "* History of test accuracies vs. cases reduction;\n",
        "\n",
        "* History of the max. validation accuracy (found in each round) vs. test accuracy (for each round)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OOGjOZGy3NV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57ea7dbc-04bb-46e8-910e-e84238c6c0c4"
      },
      "source": [
        "# -> ACURÁCIA:\n",
        "# Tamanho da figura:\n",
        "plt.figure(figsize=(10,10))\n",
        "# Definição dos parâmetros que serão plotados:\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "# Título do gráfico:\n",
        "plt.title('Best model: train_acc vs. val_acc', fontsize=20)\n",
        "# Títulos dos labels:\n",
        "plt.xlabel('Epoch',fontsize=18)\n",
        "plt.ylabel('Accuracy',fontsize=18)\n",
        "# Título da legenda:\n",
        "plt.legend(['Train', 'Validation'], loc='best', fontsize=18)\n",
        "# Visualização do gráfico:\n",
        "plt.show()\n",
        "#Para salvar no Drive...\n",
        "#plt.savefig('/content/drive/My Drive/MESTRADO - UFES/acctrainvsval.png', transparent=True)\n",
        "\n",
        "# -> PERDA (LOSS):\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Best model: loss vs. epochs', fontsize=20)\n",
        "plt.ylabel('Loss',fontsize=18)\n",
        "plt.xlabel('Epoch',fontsize=18)\n",
        "plt.legend(['Train', 'Validation'], loc='best', fontsize=20)\n",
        "plt.show()\n",
        "#Para salvar no Drive...\n",
        "#plt.savefig('/content/drive/My Drive/MESTRADO - UFES/losstrainvsval.png', transparent=True)\n",
        "\n",
        "# -> TESTE vs. REDUÇÃO DE CASOS:\n",
        "plt.figure(figsize=(10,10))\n",
        "line, = plt.plot(n_cases_hist, acc_test_hist)\n",
        "plt.title('Optimization: evaluate_acc vs. cases', fontsize=20)\n",
        "plt.xlabel('Cases quantity',fontsize=18)\n",
        "plt.ylabel('evaluate_acc',fontsize=18)\n",
        "plt.yscale('linear')\n",
        "ax = plt.gca() # Inversão do eixo 'x'.\n",
        "ax.invert_xaxis() # Inversão do eixo 'x'.\n",
        "plt.show()\n",
        "#Para salvar no Drive...\n",
        "#plt.savefig('/content/drive/My Drive/MESTRADO - UFES/testvscasehist.png', transparent=True)\n",
        "\n",
        "# -> HIST MÁX ACC VAL vs. HIST TESTE:\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(n_cases_hist, acc_val_hist)\n",
        "plt.plot(n_cases_hist, acc_test_hist)\n",
        "plt.title('Optimization: val_acc vs. evaluate_acc', fontsize=20)\n",
        "plt.xlabel('Cases quantity',fontsize=18)\n",
        "plt.ylabel('Accuracy',fontsize=18)\n",
        "plt.legend(['max_val_acc', 'max_evaluate_acc'], loc='best', fontsize=20)\n",
        "plt.yscale('linear')\n",
        "ax = plt.gca()\n",
        "ax.invert_xaxis()\n",
        "plt.show()\n",
        "#Para salvar no Drive...\n",
        "#plt.savefig('/content/drive/My Drive/MESTRADO - UFES/maxaccvalvstest.png', transparent=True)\n",
        "\n",
        "# SUMÁRIO DOS RESULTADOS DO 1º ESTÁGIO:\n",
        "print('OPTIMIZATION SUMMARY:')\n",
        "# Acurácia configurada:\n",
        "print('-> The target accuracy configurated was:',\n",
        "      \"%.2f\" % round((acc_target*100),2),'%')\n",
        "\n",
        "# Minimização de casos:\n",
        "print('-> The minimum number of cases computed above target accuracy was:',\n",
        "      n_cases_hist[-1],'cases')\n",
        "\n",
        "# Porcentagem de redução do dataset:\n",
        "print('-> (It represents',\"%.2f\" % round((((n_cases_hist[-1])/600)*100),2),\n",
        "      '% from total dataset)')\n",
        "\n",
        "print('\\nBEST MODEL SUMMARY:')\n",
        "\n",
        "# Melhor acurácia de validação encontrada no melhor modelo:\n",
        "print('-> BEST MODEL: Best validation accuracy found was:',\n",
        "      \"%.4f\" % round((acc_val_hist[-1]*100),4),'%')\n",
        "\n",
        "# Melhor acurácia de teste encontrada no melhor modelo:\n",
        "print('-> BEST MODEL: Test accuracy found was:',\n",
        "      \"%.4f\" % round((acc_test_hist[-1])*100,4),'%')\n",
        "\n",
        "# Diferença entre val_accuracy e test_accuracy:\n",
        "print('-> BEST MODEL: It is a difference of',\n",
        "      \"%.4f\" % round(((acc_val_hist[-1]*100)-(acc_test_hist[-1]*100)),4),'%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAJqCAYAAACmQA0ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3gc1bn/P2eLitWsblmyLcsV2xQXbLoFAUIJIUBIICSBlEvqvTe9/JLckEKSmwbJTa9OQkij14RAMB3igrHB3bKMi3ovVtnd8/vjnZHWq+272l3L5/M8etaeOTNzdnd25jtvVVprDAaDwWAwGAzHP450T8BgMBgMBoPBkByMsDMYDAaDwWCYIhhhZzAYDAaDwTBFMMLOYDAYDAaDYYpghJ3BYDAYDAbDFMEIO4PBYDAYDIYpghF2hhMGpdR6pdSk1vdRSq1TSmmlVO1kHidalFI3WfO5Kd1zyQSUUrdYn0d9uudiSD2Z9vs0GCYDI+wMk45SapVS6rdKqQal1FGlVK9SaptS6jtKqeokHueEu2grpeqt93xLuudiMBhCY/1O16d7HoapjxF2hklDCf8LbADeCewEfgj8GhgEPgXsVkq9NUVTejdw0iQf4/PWMQ5P8nGi5V5kPvemeyIGg8FgmHxc6Z6AYUrzJeAzQCPwJq31a/4rlVLXAHcAf1ZKXaS1fnIyJ6O1fn0y928dowlomuzjRIvWugfoSfc8DAaDwZAajMXOMClY7tAvAaPAmwNFHYDW+m7g44AT+KlSyuG3/VhsmFLqcqXU80qpAaVUl1LqLqXUgoDjaeBG67/7rW21UqrRb8yEGDt/V6blMv67UqrHOs7dSqlZ1rg6pdSflVJtljv5SaXUqUHe9wR3sFKq0W8+wf7W+Y1dqJT6llJqo3WsYaXUAaXUL5RSNYHHAmwx/OWAfdYHfo5B5rrSeo+tfsf5iVKqKtz7Ukp9wHKlDymlWqy5FQVuEytKqZ1KqRGlVFmI9Z+15vBRv2XnW8ffbrn4jyqlXlVKfVkplZPonILMIebjKaWcSqkPKqWes86to0qpvUqpXwU5j6MeG+Q4Z1ifT0jrrFJqh/Vdl1j/V0qpG63fV5v1nR5USv1DKfX2eD6jIMd8o1LqEaVUu3XsfUrCMKb7jclRSnVb52JQg4NS6qfW+3uT37K3KKXuUErtVnJ9GFBKbVJK/Zfyu55EmF/YcAbr99sYsKxIKfVppdS/lFKHrPO2TSn1gFLqzICxN6nx687agN/pLQFj1yi5vjVb+zyolPq5UmpmNO8lxPyjvqYEbHexUupBNX59OKiUul8pdWEiYw2Tj7HYGSaL9yDn11+11tvCjPsV8D/AImAt40LF5mrgUsSVuB44DbgGOF8pdZbWepc17ivAW4BTgR8A3dbybqLjdOCzwFPAL4GTrWMvU0pdCTyLuJJ/D8yx1v1TKVWnte6PsO/bgelBll8BrEDc0v7v94PI5/A8MAIsBd4PXKGUWqW1tt2891mvN1rzXu+3n8ZwE7JujncDCrgLOACsBD4EXKmUOkdrvT/Ipt8G3gg8CDwGnA/8BzAfuCDgGDcBvwV+p7W+Kdx8LH4HfAO4Hvi/IOtvRD6PO/2WfRZYjHxWDwM5wNnALUC9UupCrbU3imNHS0zHU0plAQ8BFwEHrbn3ArXAVch5tSfWscHQWr+olNoFXKaUKtVad/ivV0qttuZ+t9a601p8KxI+sB/4K2LdrUJ+D9cCf4nt4zkWpdSXkc+m03pvrcApSBjGZUqpM7XWvVrrIaXUX4Cbkd/7gwH7yQbeDrQAf/db9S3AB7yEhD8UIefhD6z38K5E5h+Gk5DP7mnkPOgCZgNvBi5VSl2htbbnuQW5Pn0Z+Z2t89vPevsfSqn3Ar8AhoEHkHNgAeO//TPi9DrEck2x5/IV5Lrcj1xnDgIzgbOQsJrH4xlrSBFaa/Nn/pL+BzwBaOA/ohj7R2vsF/2W3WQt04gb13/8f1vLnwhYvs5aXhviOOvllD9mWb3fcW4IWPdra3kn8IWAdV+y1v13LHPwG3cRYs3cA5T5La8GsoOMvxjwAj8NMf9bQhzH/hxv8luWD3RY+zs3YPxnrfGPhXhfrwOz/Za7kJubBlaHOPa6KM+ZGmtOG4OsO93a190By+sAFWT816zxbw9Yfou1vD7O8zrW433DWv5A4PcKZAPl8YwNM7/PW/v4aJB1P7bWXeG3rAM4BEwLMr4s0vEizOV863jPA9NDnBu3+S0701p2V5B9XWut+17A8nlBxjqQhwQNrAlxHtf6LYv0G2oEGgOWFQX7fKxz+AiwI8g6DawPcYyFiODaC1QHrHuD9bu4N87vIdZrysXWXBsC52K/x3jGmr/U/aV9AuZvav4B260f/CVRjP2WNfYnfsvsC/8TQcY7rQugBub4LZ9w0Q7Ybj2hhd0zQcafZ63bDzgD1s2x1v02YHnYOVhjliGWkXZgQQyf6VagIcT8bwmxjf053uS37AZr2Z1Bxrus96s5VsDZ7+v9QbZ5D0HEhHXzWwxUxfAeH7P2tTRg+Y+s5W+Ocj8l1vjfBCy/hQSEXSzHs87TbsQiOzPC9lGPjbAfWxxvCFiehYi4FsDlt7zD+r4n3PiT8JncG+y79Fv/MtAasGwXYrEqCVj+kLWvU6I89gpr/P8ELJ/w+4ziN9RIgLCLcOwfBv5+rOXhhN1t1vrLw3yWHqAgyd9RsGvKg9Zcropi+6jHmr/U/RlXrCHTeSpwgdbaq5R6FpgHLEfcG4myMciyI9brFj3RnWe7LkLGqARDSfzaw4gF5nKt9Z6A9QoRXjchbuVi5KZvMxLL8UKwwnr9V+AKrbVHKfU04v5bjljo/An2OR20XosD9hVP4sY6xJp5I5J4Y7sor0fceI/4D1ZK5SEW3KsQq0cB4l62SVo5nTiOtxgRty9prY8QnljGhkRrfUgp9QRwkVJqidZ6u7XqCkR83qa19vht8kfgP4HtSqm/Ir+3F6zvLlHORKzS1yqlrg2yPgsoD3Ab/w5xcV4H/ARAKVWJuP9f1lpv9d+BUqoU+DRwGWJNzQs4RlK//4Bjn42cC2cCFcj7CTx2tK5TOy5vrVLq9CDrK5DrwEJgU4zzjPWacgYi1v5OZGIZa0gRRtgZJotmJA5lVhRj7THBbmgtYfYPcjNMBsFuZJ5Q6ywBBOCO9gCWKHgIeb83aK2fDTLs+8DHkMzafyAC8qi17ibEUpgo9mcWKnvXXh4sLjBYzKL9OTmDrIuVe5G4sncqpT5vCeo3IaLkdn9RopRyI+J0NfAqEg/WhogJkJim7CTMKd7j2Z9fNKVvYhkbiXWMi+PPWstutF5/FzD244gb7T3A56w/j1LqEeCTWuu9CcyjFLnHfDnCODs0ACSG9WvWfH9iLbvB2s8xc7eSLzYAc4F/W9t2IufjdER0Je37Dzj2VUhs6hDwT2AfMIDE+9Uj8cKxHLvUev10hHH5MU1UiPWaMh3o0lofJTKxjDWkCCPsDJPFs0iMzYVIMkJQlFJO5EII8FyQIZUhNp1hvR4XpTys9/lnxFr2Ba31n4KMqQD+CxENZ2mt+wLWX5+k6dif2YwQ66sCxqUMrfVRy3L0fkSc/J3QouRKRGSt01q/x3+FZRmNJChiJdbj2SI4GqtRLGMj4S+O/x8iGi4FXtFav+I/0BLOtwO3W+ffOYi17FpgqVJqqdZ6OM559AAOrXVJtBtYFsd/ARcqpRZrrXci3/8oxybNgJwjc4GvaK1v8V9hZab+d5SH9Vmvoe6H05n4QPM1xNK1Smu9I+DYP0eEXSzYv7UirXVvjNuGJM5rSjdQqpTKjUKwxTLWkCJMuRPDZLEOifW5Sim1NMy49yIZVLsI4nYlyAXSEknnWP992W+V7S5NhuUo2dyOWJ5+o7X+Rogxdchv8rEgF+Aaa30g8bxn+zOrD1yhpNTEudZ/N8ewz2Syznq9USlVjoiSrVrrLQHj5luv9wTZR6w31miI9Xg7kRvfKVGUq4hlbFisG+xfkd/VhcA7CGLxCrJdq9b6Hq312xDL5DwkHjReXgSKI/z+g7HOer1RKXUakkX7qNa6LWCc/X3cHWQfsXz/XdbrBO+CUmo+wb0C84HtQUSdg/FrUyA+Qv9OX7Rezw2xPl7iuaa8iIQXXBLF/mMZa0gRRtgZJgWtdQOS5ecGHlBKLQkco5R6C1KWwAt8SGvtCxwDXKD86lZZfBS56TyptfaPr7PdObMTnX8yUUp9DJnz40jZgVA0Wq/nWOLV3j4fsXoGsyjE857vQ1xW1yulzghY9zHECvK4TrCgs5JaX4tVkLp44dBaP4dkC1+JfF5uji0RYdNovdYHHLcO+N8YpxsNMR3Psob9BMgFfmaV7PDfLssSrjGNjZJ11uu7rT8PEk/nv89sK06MgOVuxPUNfqV4lFJV1vcZbfjDbdbrL4OJVaVUXpDzD0Q49yKlMm4KeD/+NFqv9QH7XY5kB0fLTut4V1oWLns/uUgiRDAagQX+78uKZbsFmHCts+ggdGjKjxCr5G1KqYWBK63vPx7R12i9xnJNsUsNfU8FafkYsCyWsYYUYVyxhsnkFiSY+RPAK0qpfwCvITfqs4A1SKzH9Tp014kHgXuVFF3di9SxuxQRJh8OGPsEEqPyS6XU3UAf0K21/lEy31QsKKVmAN9DAoxfBb5gxeb5s0VrfZ/Wulkp9WfEFbZFKfUYYi24CInl2YK8f392ITEz1ymlRpFEEg38IUD0jqG17rdqZv0NeEop9TckyHslUr6gGfhAYu8ckASD3yKWopti3NaOtfoSQUSJxYPIOfEJpdTJiCVyNmIZfZjkC/x4jvcV5Dy/Ammf9xByXs5CPutPMy5aYhkbFq31c0qpvYhL1Q08qLVuDRiWCzxrjduEnDs5yPl2EvBAgEXqm4hb9D3RzENr/YRS6nPWdnusuL39SJzYHMSq9iwB1h7LHf834H3Ib7wD+XwD+T3ymdyulDofeRhYgHwf9yB17yKitR5VSv0AOddetq41LuRzOELw2N/bgJ9Z4+9GRNnZiKh7EPkOA3kC+Z0+iFjDR4GntdZPa613Wr/J3wCvKaX+DuxGvrvZiCWvDUmyiZp4rila68eUUl8HvgjsUErZtekqEWvki1i/51jGGlJIutNyzd/U/0Pikn6HXNSPIoUsXwW+S4g6R/iV6UAu1C8gwcndiOtlYYjtPgHsQEomaPzKFBC+3MktQfZVS5g6bAQpX0BAOQW/fYT7W+e3/TQkK3AvcuE9iNQfKw02f2ub05GbRg/i7hkr50GQcicB292L3DBGEHH3U4KU2wh8X9F8hsRYxy5g29mIJVcjoiTUuFmI6LMDwl9DsmldIb6fW/w/nzjmFdPxrG1ciMX238i5P4CIkF8A8+MdG8Vcv+h3jl0TZL3bmvuj1nc/ZJ0LLyKW0qwQ58CEcynCPM5BXMNHrPOsDREU30di1EJtY8/9/8LsewlS96/V+qw2IbF3tcHOvVDnMeJO/BySBGH/Fr6N/B4bCVLuxDq/t1jHbUd+SyeHOseQzNY7kYQw+9wO/M2cbM3xAHIN60SulT8HLojznI35mmJtdxkS49ppzeWg9R4nzCOWseZv8v+U9aUYDBmFGu9a8B6t9br0zsZgMBgMhuMDE2NnMBgMBoPBMEUwws5gMBgMBoNhimCSJwwGwwmLUuqWKIfepyeWWzEYUo4VplIbxdAtWuv7Jnc2hkzExNgZDIYTFqVUtBdAE+tpyAiUUuuJrk7f77TWN03ubAyZiBF2BoPBYDAYDFME44oFysrKdG1tbbqnYTAYDAaDwRCRTZs2tWutgxYtN8IOqK2tZePGjemehsFgMBgMBkNElFJBC9CDyYo1GAwGg8FgmDIYYWcwGAwGg8EwRTDCzmAwGAwGg2GKYISdwWAwGAwGwxTBCDuDwWAwGAyGKYIRdgaDwWAwGAxTBCPsDAaDwWAwGKYIRtgZDAaDwWAwTBGMsDMYDAaDwWCYIhhhZzAYDAaDwTBFMMLOYDAYDAaDYYpghJ3BYDAYDAbDFMEIO4PBYDAYDIYpghF2BoPBYDAYDFMEI+wMBoPBYDAYpghG2BkMBoPBYDBMEYywMxgMBoPBYJgiGGFnMBgMBoPBMEUwws5gMBgMBoNhipBWYaeU+o1SqlUp9WqI9Uop9UOl1F6l1Fal1Aq/dTcqpfZYfzf6LV+plNpmbfNDpZRKxXsxGAwGg8FgSDfpttitAy4Js/5SYIH1dzPwUwClVAnwZWANsBr4slKq2Nrmp8B/+G0Xbv8Gg8FgMBgMU4a0Cjut9dNAZ5ghVwK/18KLwHSlVBXwRuCfWutOrXUX8E/gEmtdodb6Ra21Bn4PvGWS34bBYDAYDAZDRuBK9wQiUA0c9Pv/IWtZuOWHgiyfMvzwiT3cv+Vw2DFnel7iqpGHuS3nQzQ5qkKOcyjFFy4/ifpFFQnNqXtwhPes20Dv0dGIY69fPZv3n1uX0PFSjdaa/7n/NZ7f157uqRxDqa+Dzwz9kG/lfJwux/SUHNPlcPD1q5Zxem1JSo4XDdsev4P857+NA2/YcSO4+VH2zbzqWpLQ8eZ7G/jQ6O+o/fDdTC8uS2hfmx7/M30v/oFbcz6BTzkT2lcmMt3XzdeO3koeg+meSlyMkMVXcz/DkTDX0VTzxtEnePvIPRHHjZDFLbmfo9lRmdDxlnp28G4e4NRP3I/bnZXQvu548QC/fW5/QvuIhVM8r3Ll6CN8PedTaBXajuV2Orj1qpNZOac45Bg2/gb6W6H+cyGHbGjs5LN3b+WH1y1nWXVRIlNPiEwXdpOGUupmxL3L7Nmz0zyb6HliRwu9Qx5Wzw1+Y13R9yQ3NX0LJz5+OPw/3F5zGx1ZM4OOfWRbEy/t70xY2O1vH+Dl17tZXVtCeWF2yHFbD3Xz+xcOHHfC7o6XXucPLx7g3AVlFOa60z2dMVb3vsCqgS1cWriXzQUXpOSY63e28pcNBzNG2A11HGDus5+mQxXTnrcg7Ni6oVf5ouf/uLX6N4w6Qp+n4XBoL5868CPmjO7j+Zef46wLroxrPzb9rzxAvedZjkxbzXPTr0hoX5nIlW1/YvHAXrbkn4vm+Ap3duLltP5neFPedp6evijd0xnjikPPUaL62Z17WsgxCs2K/qe4JnczT5S8PaHjXf3646waep69DbuYv+jkhPZ19+ZD9A97WJWi68fVLS9x7tHneKL8o3S6ZwQfpOHhbU08v7c9vLDbcicM9YQVdoe7jtLQNkCOO70PaZku7A4Ds/z+X2MtOwzUByxfby2vCTJ+AlrrXwC/AFi1apVO1oQnmxGvZvms6fz4HSsmrnzlL3Df12H2GfCGL1Hyp+v5atfn4KaHoXjOhOGLv/QoHq8v4Tl5fPLxffSC+Zy3sDzkuF8/u5+vPbSdpp6jVBXlJnzcVNDQ1s+tD2/nvIXl/O49p5NRuTiPPwDN8L5FXt5XH+R8mAQ+cudmntrdhtY6/Z+F1rTdcTMl2kvnVX9k5anLw49veAp+/2Zun/kEXPDF+I75wo9hzz4ADh88EN8+LHw+je5rAeAdg3/kHe/7JGTnJ7TPjOJoF9z2ECy7ihVv/U26ZxM7WsP/zuHts/p4+xWp+X1FxfeaYOkbWXn1L8KP+/Eari7cw9XB7hXRojWj35XcxiMH9iYk7Lw+za7mPt62aha3vHlp/HOKhV+3Qg987dxpUBf6c3j+q4/R2jccfl+dDeDOCzuktW8IgMowBo5UkO7kiUg8ALzbyo49A+jRWjcB/wAuVkoVW0kTFwP/sNb1KqXOsLJh3w3cn7bZTwIjHi9uV5CvbfMf4N4PQO058M67YM5Z8O77YbgP1r0Jul+fsInb4WDUm7imHbXEocsZ/ka/xrIyvtQQLqwyc/B4fXz8r6+Q7XLynbeekn4hE0j7Hnnt2JOyQ9YvLKetb5jtTb0pO2YoBl/4NbO6XuTu0g+wPJKoA6hbC6e8HZ69Hdp2xX7AnkPwr1th1hkAdLZM/E3FQkN7P9N9nQzmVEJ/C7zwo4T2l3G89AsY6YdzPpHumcSHUlC5DFq3p3sm4wz3Qd8RKFsYeWxdPRx4HjwRBEs42vfgHmgGoKupIf79AAc6Bhgc8bKkqjCh/USN1uPfXWf4uVcU5NDSOxR6wNFuGOwAz9Gw+2npHSbX7SQ/O702s3SXO/kT8AKwSCl1SCn1PqXUB5VSH7SGPAI0AHuBXwIfBtBadwJfAzZYf1+1lmGN+ZW1zT7g0VS9n1Qw6tVkOQO+tg2/hgc+CvMugHf8FbKsp4qZp8G774PhHlh3OXQfPGYzl1Ph9SUu7Ox9uAPnFcBJVYUU5Lh4aX9HwsdMBT9+ch+vHOzmG1edTGVhTrqnMxFbnLSnTtittSyyT+1uS9kxg9J1AOfjX+JZ3zJWX/up6Le7+FbImgYPfUIu/LHw6GdB++Dqn+NRbnRvM31DkeNKQ7GhsYsK1Y23di0suRKe+yFYFrzjnuF+eOmnsPBSmLEs3bOJn4ol0LI99nNlsmjfLa/lUbiG6+pFiBz8d/zHa1g/9s+hjsQeZHY09QFyH0gJPQdh2HoA7dgXdmhFYXZ4i50tDEfDiD+gtW+YysLstBsB0p0Ve73Wukpr7dZa12itf621/pnW+mfWeq21/ojWep7W+mSt9Ua/bX+jtZ5v/f3Wb/lGrfUya5uPWtmxU4ZRrw+3v2XsxZ/Bw5+AhZfAdXeCO8DFOXM5vOs+OGqJu57x3BKX04HHlwRXrGX1cznCn8xOh2J1bclxYbF75WA3P/zXHq5aXs3lp2RO4PQYnhHrYqOgY2/KbjwVhTksqSpk/a40Cjufj+G7P8SoV7N+4f+wuCqGIOX8crjwK3DgWXjlT9Fvt+tR2PkQrP0MFNfiyS2nXHXz8uvdsc/fYuP+dipUD/ml1fCGL4N3GNZ/M+79ZRSb1okr9txPpnsmiVG5BEb6gno80kKbJezKohB2c84G5TxGnMVMw3qYPod+ZxHOvsMkcjvd0dSL06FYUJmicIMWy1qnnNAZPmGjoiCH1nAWO1vYRbTYDVFRkH4jQKa7Yg0BiLCzvrbnfgB//yycdAW87Q/gDnFCVa+Ad98rF9p1l0OPhB26HSqprthIFjuANXUlNLQPhP8RpZmjI14+/pctVBRkpy4WJFY6G0B7oWaVuLv6mlN26LWLytl8oIveBKxVCbHx12Qfeo5v+t7Fe950Xuzbr7gRZq2Bx74Ig1E8ZIwMwCOfhvKT4Kz/BMA9vYoK1c3GxvgfUnY3vo4LL6pgBpTOg1Xvg82/j89NnEmMDsHz/wdzz4NZp6d7NolRaVkbM8Ud274LHC4omRt5bE6hXB/iFXZeDzQ+A3X1DE2bSYmnLXIcWhh2NPVSV5aXusSC1tfkdc5ZEV2xlYXZtPUP4wvlwbKFoc8jn0sI2vqGqUhzfB0YYXfcMeKxhN1T34F//g8suwbe+ltwRUhDr14J77pXbmTrLofeIzidKqnJE84IFjuA1XNLAXhpf+Za7b756A4a2gf43rWnUpRBWbDH0G7d/BdfLq8pjrPz+DTP701D+ZeOffge+xLrfaeSu/omqqfHkYTjcMCbbpMMt39+KfL49d8St84Vt4NTzgdnwQxmuXvZeKAr9uMDrb1DjHY3yX8KrHIUaz8jYRSP3xLXPjOGV+6E/ubj31oHUHGSvLYEbY6Uetp2Q0nd2HkYkbp6OLJZYsRi5cjL4sqsq8cxvYaZqiOh2NodTb0smZkiNyxAy2swfTZUnQpd+yGMd6qiIJtRr6ZrcCT4gE4/V24Yq52x2BniYtTr48LmX8GTX4dTroOrfxn9j7xmFbzzHhhoh3VvooouRpMQYzdusYss7JbNLCQvy5mxcXbrd7Xy+xcO8L5z5nLW/MRqlE0qdqzNosus/6dO2K2YU0xBtiv17lifD+7/CEM+B19XH+QjF4QvbxKWyqVw5kfg5TskwDwUza9KJuyKd0u2uU1BJRWIK3Y0joejjQe6qFCWKMy3yjDklcE5H4Ndj0DjczHvMyPweiQ5pXoVzF2b7tkkTnaBiIOWTLHY7Y4uccKmrl7iQhufjf1YtqVv7lryyueIsDsSn7DrHhzhSM9Q6uLrQL6ziqUihD1DknQSAjuGOqRF0t/iFyLOrn/Yw+CIN+0ZsWCE3XHHe/T9nHPkN7D8XfCWn4AjRrP2rNPhXfdAfwvfH/oi04YTt7pIjJ3G5Yh8OrmcDlZmaJxd18AIn7lrKwsq8vn0GzOnblVQ2nZDYQ2ULgD3NImzSxFup4Oz55eNlT1JGS/9FF5/gS8NvYur6ldTnJdYsVTWfhaKZsNDH5eYxUB8PnjoY5A7XeLy/MmfwTRvD57R4bhudhsaO6l29ch/CvwKyJ7xYSisFjfx8Rge/Ord0H1ArHWZlkUeL5mSGWvH1UaTOGFTvUpKdMTjjm1YDzNOgbxSsktnU6gG2X+oKfb9wJilL2XCzjMsXoxKS9hBWHes7T4NmRnb2QBO63oTwmJnb5sJiXZG2B1H+Hyaix3/pqlgGVzxw9hFnc2s1fDOe6jxHeHsnocSnpd7sImN2R+icPddUY1fM7eEPa39dPQnkIa/+x/JyyDUGq01X7zvVboGR7jt7aelvcBkRNp3QflCcSuWzkupxQ6gflE5TT1D7G7pT80B2/egn/gqG7NW88y0C3nv2VHEGEUiKw8u+w607YQX/m/i+s2/g0MbJJN2WkBBVUuMldPNhjji7DY2dnFqkXX+5/sVTnXnwvlfEPfZa5G7C2QUPh88+32xkiycQi26K5bI7yuRsiHJwI6rjSZxwsaVBbVnxy7sRgbg4Eti8QN52AA6m+LrGjGeEVsQ1/Yx075b4uEql0Qn7ArCWOyGemGgbVxQh7DYtfYOW/syFjtDDIz6fLjxMJRVKjf0RJi9hhHcuL3hs3yiIWugiTLVS/E/Py7ZgxE4o05ukvHcEAGp5XTn2+H3b44vdsSfXX+H7y3ipUf/wMPbmvj4RQvT2gomKnw+udHYF/jSBSmNsQNJoAB4anfr5B/M54X7PoRHZfOh3hv5+MWLyM1KkvBedIkkHz317WMz5/pb4fEvQ+25cOp1E7ezxNjJRUNsbIwtzq5/2MNrR3pYlDcA2YVSfsWfU68TK9HjXyy2sPEAACAASURBVEm/mIiFXQ+LSD73E4lfnzKJyiUiqNKd1GLH1ZbH4IoFEWcde46piBCRAy+AbxTmnS//L5I+Ab7uQwyNhm/dF4wdTb2U5WelLv7Mdp1XLIWiGrG2hRF25ZYYC5rUZ29XYSXShbDY2cWJK4zFzhALIx4RdjramLoIeJULh048s1FbWUI6uwD+dlPE+KCTq6eT43bwYrzu2K4DgJabyF/eGdyNFg2vvwR/uxE90MYp//4U18zs4gPnzYtvX6mk9xCMDkKZFWNWtkDKMaRQBFQV5bKosiA1cXbP/x8c2sB3XO+noLyGa1fWRN4mFi75X8k0fORT4+7Pf3wBRgbh8u8HdylaFrs15SNsPNAZk0t6y+vd+DTUuHshP0gfT4cTLvqKuDQ3/Dqed5R6tIanvwvFc2HJW9I9m+SSKZmxdqmT0hhjS+vq5bXhqei3aXgSnNkw+0z5f5FY7KpUO7ua+2I7PiLsUhpf1/qaiLnS+fJ7Kq4NW8sux+1k+jR3cIudLewqrR7TkSx2GRBjl+ktxQx+jHq1CDtHgrFFFh5cKF/o1O1o8VnC6uglt5P37DfgT9dJG7OqU4KOz3I5WDmnOO7MWG/HfpzAPVlXcHXjg6z/7tv5WfGnyXK7yHY5yHI5yHZar9b/s1wOspxOst0OspwOyof2c/FLNzKaXcktuZ/lk21f4n9HbsU5eDHkJ9Y7d9JpCyhSWrpAAqQ7G8az+FLA2kXl/Pa5/QwMe8ibrErrrTvhyVs5VPkGfnFgBT9752JcUZTViYmianF//uPzsP0+yC2GbX+F8z4T2jpiWeyWFQ7RvneExo5B5paFbzdks6GxE4eCYt0FBSH6V86/EOrOh6e/Dae9Q+L8Mpl9/4KmLRIi4pxit5WSeSJy0p0Z275L4mpjbTtXsQTyysUdu/yG6LZpeApmrxmvi5o/A62cVKkOdjT1cuqs6M/HUa+PPS39vOfs2tjmnQgtr8n10T4XS+qiqGWXHTzGbsxiZwm7MDF2uW4nBWnuOgHGYndcMer14VbepF04vcqFIwnCDq8IO2dhpZRUyS6EO64O+4S0Zm4pO5t76RmM3WLYsEcusI+Wvpt7p99E/dC/uKb3DnoGRzjYOciOpl7+3djJEztbuW/LEe548XV+9lQDtz2+m289upNfPvQMK595Hz0jDi7p/Dh3HZrOtvN+hmu4G/58Q8Tq4mmnPaBIadl8a3mK4+wWljPq1Ty/b5IynL2jcN8H0VkF/EfnDSyfXcwblwaxcCWD1TdLoPijn5OuFMVzw5fryCsHFPNyxXoRS1jBxgOdLJ5RiGugJbjFzuair0qowbPfj3rfaeOZ70HBzOBu6+Mdp0sEfrozY9t3x+6GBbE419WLsIvGstzfBi3bxi19IJ9BQRVznJ0xlzzZ19bPiNeXnoxYm5I6K0Yx9PuvLMwJbbErqBqPsw1lsbNq2KW76wQYi91xxYjHRxYeRpzJsdglzxUr+3C43BLP8K574TdvhD+8Bd77GBRO7NywZm4JWsO/Gzu5aElsN+sj+3cyg2n8+L1vIMt1Edw/yrVb/si1F50j1o0QeH2akb4Osn5/GapvlNZr7uF3JUvIdjmoKZ4GVT+Hv74LHvwvuOrnmZvV175LrEp5VjmWUkvYpTjOblVtCdOynDy1uzXm7zAq1n8TjrzMY0u/w45NOfz5+sWTd9F0uuBNt8Ov3gBoOYdDFfy2x+eVU+LrYvo0N5sau3jbqlkRD+Px+nj59W6uXVENr7aEttiBWLxPvU66y5z+fim7kYkceAEOPAeXfAtc6XdDTQqVyxLr4JAodlztirPi276uHrb9DVp3jLsUQ7H/qfFt/FBFNdQd7eGOGIXdjlRnxA52SmmTygBh5zkKfU1QODPoZuUF2TS0DUxc0dkg27ss6+XoYNDtW3qHqMyAGnZgLHbHFaNeibEjScLOp5w4dOIWO1vYuewiyeUL4Z13yQ/sjqul40UAp86aTpbLwUsNsVl7egZH0V0H6M+tIcvtFPF1xQ/kIvTAf4a9+Do9R8m96wac3ftxXP8nZixazbzyfBF1AEveDOd/Ebb+BZ69LaZ5pZS23WKts0VOdoE8UbanruQJiEv9rHllrN81CWVPGp+DZ77P8Mnv4FOvzeGCxRWcUVea3GMEUrMS3ngrrP2c9F2OREElqr+FVXOK2XAgOovdjqY+Bke8nFGTJTeacBY7gAu+KK//ujWq/aeFZ78P00ql1t9UpWKJiIJoOpVMBnZcbTwWOxivKRiNOG14EnKKoOq0Y5cXVTNTtbOzqS+m3/uOpj6ynA7qyqMLVUgYOxbSX8BGkRkrFruhie+ts0E6fdgPep7gFru2vmHKMyC+DoywO66QGDsvKpnJE0lwxY5b7PxO6uqVcN0fpb7anW+X9Hk/ctxOls+aHnOc3QNbj1BDC9Mq/ZIcnG542+8l1uwv7wruMvF64K73Sgr/1b+EuecGP8B5n4Jlb4Unvgo7Ei8FMynYpU78KZ2fcosdSNmTQ11H2RfsSTcMO5t7ueT2p7n8h8/wtp+9wE2//TcfuXMzn7nrFb51z4v03vleenKq+Uz/DfQPe/jMJSmqK3jmR+D8z0c3Nn8G9DezqraEhraBqMr32C7blaXW2HAWOxAL+BkfkoeN5gzpfuBP0yuw5zGpv5eVoht3OrCtPy2vpef4sfSIDcb0WXKNiCTstIZ966UdXGA5raIapnva6B8e4VBX9NUUdjT1snBGflQtJ5OCf0asTVQlT+zuE35erOF+6G8JsNiFjrEzFjtDzIx6xRUbsX1YlPiUOykWOyxhN6EDRl09XPNrqQX213dPyF5dU1fKa0d6Yuo5es/G15ntaKOwav6xK3KK4Ia/SbHeO992bO9UraXQ7O5HpW7Z0jBZe0rBlT+CmcvhnpuheVvUc0sJAx0w2DGx+nzZAnHVpLio7dqFdtmT6LNjtdZ86b5XaeoZoqooB4cDOgdG2NHUy9O72zn5la8xbbiVG3tu5v4dPbxt5SwWz0hhfE60FFRCXwun1xYDRNVebOOBTmqKc6nAKtMTyWIHIuzQ8XUPmGye+b7E1J7+/nTPZHKxhV26MmPtUiexdJ0IpK5eziFvmOttZ4NYB+vqJ64rrMHpG6GUvqjj7LTWbD/Sy0mp/P22vAq5Jcc+NBXNAoc7osUOxsuWAOPjS+aFtdj1D3sYGPFmREYsGGF3XDFiuWIdSXPFunAmQ9j5rAuFI0jI5pI3S+zS3sfhvg8d069vzdwSfBo2RVkHbG9rP0cONZLFKKqkduKA6bPgHX8Rd8mdb5OnLYAnb4WX/yBZjqv/I/KB3Llw/Z9ELN55ndQ0yxQCEydsShfAULeIvhQyq2Qa88rzWL8r+s/owa1NbGjs4nOXLuZXN57On28+kwc+eg7/+mQ9L76pg8vVszgv+Dx//upH2fTFC/nm1SdP4jtIgPwZMNDGsqp8slwONkZIoNBas6Gxi9NrS8bPqUgWOxDx586DrsbE55xM2nbD9vtF1GV61m6i5FeKWEhXZmz77mPjauOhrh5GB+DQxtBjGp60xp4/cV2RlBma6Yi+tVhb3zAdAyMpLnWyXYS4fzyu0wXFc8Im9NmFhVt6/SzvY8IuvMWudazrhBF2hhgZGRnFoTTKlRxXrM+RHGGnQlnsbFbeCBfeAq/eJeUbLFbMLsbtVLwYZd/YuzcfYo7TsgwV1wYfNPM0uHadWNruei+8+FN4+juw4kY4//9FdRxAbrjX/0mEUiZlyoYqUmrXtEtxZizA2oUVvLS/k6MjkQuXHh3x8s1HdrB0ZuHEZIOuA/DwJ2HWGahzP0mO20lpfjYOR4YmsRTMAO0le6SbU2uK2BDhAeX1zkHa+oZZOad43KIcjcVOKTnfM03Ybf6dxPue8eF0z2TyUUrEQroyYwPjauOh9hxQjvDu2Ib1Yt2yXZf+WLXslhf2jyVERCLlrcR8PkkQqQiSIBKh5MmYxa43mMVurpUYpIJa7Oxs2pQVYI6AEXbHEd5ROXkcSco88ykXTpIQY2fH6TnCCM6zPwZzzobdfx9blJvl5JSa6VH1jfX6NPduPsxFM6ynpeIwLaUWXgyXfRf2/AP+/jlYdHnoQrPhmHkaXP1zOPRvyZTNhN6dbbvlybEoIEMyTZmxIHF2Ix4fL0aRCPPTp/bR1DPELW9eitNfsHk94voGuPoX8bfLSyW2KOuTOLtXD/eEFbe28BOLXTO4csQqHA3FtVKwOJNo3iZiJ7883TNJDZVLRTT4eR1SRrC42ljJLZYQk1DCzueF/U9D3drg18pCsdgty+9jR3N0ws5uJbYkVcKu+wCM9B+bEWsToeTJWPeJvgCLXV6FJKgpJd6cIBa7FmOxM8SLxxJ2KkkxdjpVFjuQH0XFEsnc9PthrZlbwrbDPQwMh5/H8/vaae4dYm35AKDG3AIhOf19klG45Ep466/jr/235EopXrv1L/DSz+PbRzJp3yV16wJbNk2fLUVU02CxWz23hBy3I2Kc3aGuQX7+1D6uOHWmiBt/nr0NDr4Il39PXCbHA7YbtV/i7Dw+zZaDoVvcbWzspDDHxYKKfOlznF8Z/cOGbbHLhIcLm7adKS2InXYqlogrs7sxtccdi6tNQgJRXb3EPA8FEWZNW2CoJ7gbFqSOmyuXBTndHOw8Sl8UsdE7mnqpnp5L0bTkeJkiMpYRG0zYzZPvL0RoTY7bSVGue6LFrtQvUc+VE9Ri12aJwXJjsTPEimdUkg8cSRJ2Xocbp469798EfFEIOxB34UifZBlZrKkrxevTbH49vBvr7k2HKMxxMc/dLg2po7FanvdpyZa1q6fHy3mflizfbX9NbD9g9T39cPg4l3C07Q4eQO1wyhNpR2pLnoBcEM+sK40YZ/eNR3agFHz+0sXHrji0SWrWLXsrnPK2SZxpkvGz2K2cLUJ1U5iyJxsPdLGqtkRcy/3N0blhbYrnSLmLgRS0cIuGwU75HZcvjjx2qmC3Fku1OzYZiRM2dfXS9/bA8xPX2Za8uecF31YpKKqmSsk5vjOK1mLSSqwgrqnGhf3dBDsvxzJjw8fZTYix83dLu3ODhuW09A6R43ZQmJMZpYGNsDuO8FkWO6c7SRY75U6KK1aNJU9EEHalEzskrJxTjNOhwrpj+4ZG+ftrzVxx6kyc3QdCx9dNFkpJz8TmbfH3pbVp3QFb/ggbfxv7tiOD0PN66Cf3svlpsdgB1C+qoLFjkMb24GVPXtjXwSPbmvlw/XxmTvcT2sP9cPf7pGjo5d9L0WyThC3M+pspmuZmUWVByDi7zoER9rb2s8rKoKWvZazfbFTY53ymxNm17ZTXE0nYVSwGVOpLnrSFiKuNh5rVEsoRzB3bsF7Ea7iWikU1FI/Kg3mkBIqhUS/72vpT3HHiVQnTCdZ2rcQK34milh0gJbr6msa3A8tiFyR5om+YioKcjOg6AUbYHVeMx9glzxXrToor1tpHRIuddWHyiwPLz3axrLqIl8IkUDyyrYmhUR9vXVkjMRSpFnYA1SukdVqi5Q6ObJbXaNv7+GN/bqEu8KULoGt/+HIGk0S4sicer4+vPPgaNcW53HxeQFD23z8r3+nVvzj+MivdVoxcn9zoVtUWs/lAF17fxO910wG/+DqwLHZRZMTajAm7DImzs4VdxQkk7LLy5HtoTbGwa98TPK42Htw5MOfMicJuZBBefzF4mRN/CmtwDzQxfZo7YgLF7pY+fDqFiRMwnhEbjOlzpHJDhFp2YxY7O9EiSotdpsTXgRF2xxVey1rkTFLyhHa4ceFJuGuA0qN4cUSOFyqslgtUQIeEM+aW8MrBHoZGg7uF7950mLryPE6bkS1PUOkQdjNXyKstzOLl8CZ57T0U9gITlEhFSssWgM+Tlpt/bVketaXTgrpj/7ThIDub+/jCZSeR4/ZLith+P7x8B5zzcZgTZ6ukdGMVKQYRbX3DHnYFcVFtbOwky+ng5OoiCb4e6onNYme3E8sUi13rTsjKlwzKE4l0ZMaGiquNl7p6aNtxbK3Pgy/Kg2tdffhti2pQfc0sq8yNKOxS3kpsdEhCUYJlxILEWU+fHV7YFebQ1jcs90T/GnY2ESx2mYIRdscRPkvYOdxJejJwuHDhxRPEwhALyufBQxTBsQ5H0A4Ja+pKGPH6gsbZHegY4N+NnVyzogbVc1AWpiO4vrhWssoOJ0HY2cI01t6T7bukXIF/MK8/pVbJkzRkxoJY7V5o6DhGoHcPjvC9x3ZxRl0Jlyzzs1D1HIYH/kuy9Oqj7PSQiVhFikHCCkCKEAeyobGTk2uKRNjaMaaxWOzcuTI+U4Rd2w4oT7D8xvFI5VKJ0QrRfWBSsEudJIu6enlteGp8WcN6CaWZfWb4bYuqAc3qshF2tfQFtU7b7GjqY1qWkzkl0xKccJS07QTtC22xAysOOXyM3YjXR/fg6LGlTmxCWOxae4czpjgxGGF3XOGzkidcyYqxc7pxKS8ebxKEnYqyPEWQOLBVtSU4FEHj7O7efBil4OoV1eM3tXRY7JQSEXJkS/z7GBmUp/1l14j1cv9Tkbfxp22XvPdQFtuyiTGMqaR+UQVDoz7+7dcm7rZ/7qb36ChfvmLpePyJ1yNxdd5RuPpXkV34mYyfxa6mOJcZhTkT4uyGRr1sO9xzbHwdRFec2J9MqmXXuhPKT6CMWJuKJSIebFf0ZDMyYMXVJiG+zqbyZCm27P9g2bAeZq0OHpvmj1WN4JSCfoZGfewPEVMLUsNu8YyC1NWhDJcRa2PXsgvhpRrvPjEswm5a2bEliYJY7AaGPfQPe4zFzhAfXo/4/l1Js9i5ceNlNMG6TA7fKF6izAYqXSAxVZ7xzKPCHDdLZhZOiLPz+TT3bD7EOfPLqCrKTa+wA3HHtm4XgRYPzVslI616lTTl3v9MbDWx2iM8uecWy4UoTRa7M+pKyXKNlz3Z1dzHHS+9zg1r5hzrjln/DXj9Bbji9nExerxiW+y0RinFqtpiNuzvPCa84ZWD3Yx6NafP8Yuvg9iyYiFzatkNdsJA64kVX2eT6szY9ghxtfHgcEitOjvOd6ADmrZGdsPCWC27+dny8BLKHau1tjJiU5k48ZoIr2DFlW1K5kllhoH2oKttq1tL79DEjFiQGMUAa61d987E2BniQnuSbLFzuHDhSdhi59AevCpKYVe2QJ54AyqAr5lbysuvdzPsGXfjvbS/k0NdR7lmhVWzruuA9ILNS1NB1OoVIszi7R9rx9dVr5AL69FOaIlyX16PuBAiXeDLFkyIYUwVuVlO1swtYf2uVrTWfPWh18jPdvGJi/zmvPcJ6S+6/F3HV2mTUOTPAO+wtHND4uyae4c43D1+8bd7yNqu2vgtdnOg51DimdmJ0rpDXk+kjFibkrkSJ5yqzFhb2CXTFQsi4vqOyP4bnwZ0dMLO6j4xgw5cDhWyZ+yhrqP0DXlSL+zKF4Uvbh6h5EllQYDFLjDsxTWxQLFd985Y7AxxMRZjl6SsWJxisfN4E7PYKZ8Hb7Su2BAdElbPLWHY4+OVgz1jy+7efIj8bBdvXGrdALsaxWqRrriemcvlNd4EisObxAVbMEMsdnBsnEs4uhqlXmCkC3yQGMZUUr+ogn1tA/zmuUae29vBJy9eSHGedb72Nkl3iYqT4NJvh9/R8YItzvwyY2E8CxYkcWJBRf7459DfDMop1tVYKK4FNNixpumi7QQWdg6niIdUZcZGiquNl7p6eW1YL39ZBeMJYuHIyoPcYlx9h5lfkR/SYpfyxAmwMmKXhR8zJuyCJ1DYFrv2rm7oPRzcYhdQoLjFWOwMiaCtMhYqSVmx4or1MJpg8oRDj+JVUcZJBallB7DaKgPxktWWanDEw6Pbmrj85CpysyzR2NUoKevponCmWGiOvBzf9oc3ibUOoLBK4maijbMb6xEbQdiVLZAitkdDd0CYTOyyJ19/eDuLKgt4x2orm9PrgbvfL0V2r10HWSkKqJ5s/GrZASyeUUh+tosNjRJn6PPpscLEY/S1SK2wWLMcx0qehO53mRLadokQiNT9ZapSuSx1rti2XVKXLVnXfJviWvmzhd3cc6PvzlNUA72HOamqMIyw60MpWDwjRcWJB9olKSlURqzN9NnyUBVC2OW4nRTmuPB12IkTAcLONTF5wljsDAlhu2KTFmzuzJKs2AQtdk7twRetKzanUMRRgLArzsti8YwCXrIC7//+ajMDI16uWWndPLQet9ilk+oV8WXGDnbK/KtXji+bu1YqwEfjWrOLlJYtCD9uLDM2Pe7YeeV51BTnojV8+YoluJzWJeap/4UDz0rP3kji9HgiwGLndChWzClmo5VAsbu1j74hD6fbiRMQe9cJm0ypZdd6gmbE2lQukRjD/hR0AWnfPXm/l7p62Pu4XJfq6qPfrrAGeg6xpKqQlt5hOgcmXr92NPVSW5pHXnaKOjHYrvHKCMLOlQXTZ0UseeKwH578M2LBsthNjLHLdjkozM2MrhNghN3xhdcWdslxxSqnC5fyJSzsHLEIOxBxEsRduGZuCZsOdDHq9XHXpkPMLpk2fkMcaJc+f+kWdjOXy9yHeiKP9ccWg/7Crm6tWLAOR9FerH23COJITeNt4ZemzFilFB+qn8cH187jrPmWq3Hfk/D0d+C0G+C069Myr0kjwGIHcPqcYna19NEzODqWIXt6oMUu1vg6kO/fmZ3+zNi2nSdm4oSNbRWabHesHVcb6WEuXurqJT7U/ne0FImws92swax2O5pT3EpsLCM2gisWIpY8qSzMJrf/wPhYf9zT5D7sG48Fb+kdoqIwO2O6ToARdscXSRd2sh+7B228xGSxA3HHtu+ZkHK+pq6Uo6Ne/vFaMy80dEjtOvvHYmcDpl3YWa7Upldi2+7wJkBB1Wnjy2rPkfiZaOLs2ndHlxlXXCvV1dMYZ3fDmjl8zu4H29cicXXli+Cy76RtTpNGdoFc7PvG+x+vrC1Ga9j8ehcbGzupKMimptivjVq8FjuHQ1xJ6RR2Ax3i6j8RS53YpCoztmt/dHG18VJ7HqCgoCq2cipF1TDUzUmlcm0ObC3WNzTKgY5BTpqR4lZi08rCt0OziVDypKIgh6KjB6UkTG7xsStdlrvVL86utXd4LOkiUzDC7jjCjrHDkSSTrxVTYbcqi3s32oMvljmVLZAswsFjy5usnitWja89tB2trdp1NukudWJjJ1DE6o49vEnETY7fxS63GKpOjRxnp3X0RUqdbvmM0mSxOwafF+55Pwz3WXF1eemeUfJRSkSan8XutFnTcTkUGxo72djYxem1JcfW8Btoj89iB+mvZWcnTpzIFrv8csnMn+zM2Har08xkuWLzSmHhJZKdHou1ySp5Uuptp6Ige4LFzu68ktqM2O2R3bA2JfNguEfCY4JQUZhN5ehhdLCyKW7rAc0vzq6lbyijihODEXbHF7awS5LFzuGSWD2vJ7HeouKKjSHurzS4u7AsP5v5Ffm09A5zRl0Js/wrltsxD9OT0C8xEfJKJYEjlsxYra3EiZUT181dC4c2wHB/6O37mqT2UrQX+NIFaYuxO4anvwv7n4bLvyuZsFOVghnQP95KbVqWi6XVRTy8rYnD3UfHCxODWLvQ8VnsIP217E7kUif+VC6dfFdstHG1ifCOP8NFX41tGztppucgJ1UVTih5MpYROzNFws7nlfCAaNywEDkztiCHWaqF0aLaiSvHLHbjcXZtvZnVTgyMsDu+SLIr1t5P4hY7b4wWu+AlT0Di7IDx2nU2XY1yM8yEbMqZy+FwDJmx3a/DYPt4Rqw/dWulv+vrL4TefuwCH6W7pGy+xJD4gvfeTQifL6QL4xj2PwNPfQtOuU5i66Yy+ZXH9t1E4uwOdEgh62Pi62zLXtwWuzkS33l0Yvu9lNC2C7ILpWzPiUzFUum+MRm/MZv23eImjRRXm2qsWnb0HGbJzEL2tfUz4hmP097e1EdRrpuZRSkSO12NEqscKSPWJkItu6o8mEkHvdOCGBECLHaDIx76hj0ZZ7HLnDQOQ0TUmMUuOVmxDmdyLHZOPOhYhN30OSIqg7gLr1pezb62fi47uerYFV0H0u+GtaleAdvvE5daXhS1yMYKEwex2M06Qz6LhvWw4KLg29sumWiFXekCCYruOZjcz2y4D35wmlxEC6qsvxlSuqXA7y8rT1qGlc6Hy7839bMnC2bAvn8ds2hVbQm/enY/eVnOY0s+9MXRJ9afsczYxonxP6mgbeeJnRFrU7lErDad+yeve0rbrsm11sVLQZXEBvcc4qSqixj1ava29rNk5ngyxUlVBalLJog2I9ameI7MP4TFroZWHErTnlXNhKt7gMWutdeqYZdhFjsj7I4nfJOTPOFNsJK9K9bkCYfTykya6C5cVVvCn28O0oi66wDMidCgOlXYCRRHXg4txvw5slm+s4ogPQyzpsGsNeHj7Np3i5UkWivPWGbs3uQKu6atYnlccqXUguprlozenc0TinbiyoF33Ru59+RUIL8Shnul1ZxlUbbdryvmFI+XfAE/i10CrliQ34Md75lKWnfAoktTf9xMw+5H2vra5Ag7reXB99Trkr/vRHG65cGk9zBLlslDy/amXpbMLMTr0+xs7uX61SkMmWndDqjoE3pc2eJODiHsZngOA3DEMZMJAQcBFrsWu4adsdgZ4kX5kmyxs2LsfAlmxbrwoB0xzql0/riLMRKeEeg9lDkWu6pTASUJFNEIu8ObYcYpUkMpGHPXwpNfl4zDvNKJ69t2ibUu2ifgsVp2e2DBhdFtEw12K7VLv32syNRaXIN9zRIP2Nck8S7hmnFPJezPor95zM1Tlp/NDWtmc878gGd+22KXF0X2XjDsAt3pSKAYaBdhP5XjJaOlfLFYfVq2y4NOsok1rjbVFNVAz0FqS/PIdjnG4uoaOwYYGvWlOHHiVfndxRKmU1IXUtgVDx0CYL8O8vAVaLEb6zqRWRY7E2N3HKF8ERQHlAAAIABJREFUHnw4wvfCiwHbFevzJuaKdWlv7MKubIEkRERz7J6D0l82nV0n/MkplPlH04HC65FxwdywNnVWe7HGp4Ovj7VIaV6ZxOUkOzO2easIkkDLoVIwrURcIfPfAMvfCTNPC76PqYidCOFX8gTg1qtO5tLAkIL+ZimjEG9bwJxC2T4dws4kTozjzhVx0PLq5Ow/1rjaVFNUDT2HcTkdLJpRMCbs7NclmZoRaxOmlp27p5Ee8jh4NIhYC2WxK8gsi50RdscRDt8InlhcnpH255abiy8BV6zXpy2LXYzzKlsoSQPRVNHPlFIn/sxcIS7WSIkE7bskJi2csJu5Qlo0Batnd7RbWuXEcoFXysqMnQRhN+Pk5O5zKhCkSHFI4i1O7E+6Sp607ZRXI+yEyqXjhXGTzWSXOkkUq60YWrPEai2mtWZHUy8uh2J+RYpCMEYGxfIWbUasTck8q+RWkJInnftocsyktW9o4jrbYjcqiVFtfcNkuRwU5SapG1SSMMIuBWy47yf8+weJZwYq3yhekncCOSyrQSIWu1GvD5fyxu4e9ncXRiJTihP7U71CBFfvkfDjwiVO2DhdUHt28Di7WBMnbMoWSIxdsvCMSBZg1SnJ2+dUIaCtWFjiLU7sT7pKnrTusDJiZ6b+2JlIxVJJnhgZSP6+7ezjRM+VyaKwRuJqBzs4qaqQrsFRWnqH2dHUx7zyfHLcyfEqRaRtB6Cjz4i1GcuMDdJ3ubOBjuxqWnqDVIuwLXaecYtdRUFmdZ0AI+xSgrfpFZZ0PpHwfpy+UTzJKk4MOJyJW+w8Po07LoudFXAcjbuwq1GSDwqqIg5NGXbgeiR37OFN4hYNVuzSn7lr5cmz++Cxy22XTKxP7qXzoe9I+Pp4sdC2U6rgG4vdRHJLpGh4yix2c6SEzmSW2ghG2y4rtiyzbmJpo3IJoOWBJ9m0744trjbVjNWyO7a1mJ0RmzLs7h+xxvOGKnniGYaeQ/RNmxPBYjceY5dp8XVghF1K0M4s3HgS3o/DNxpbIeBI+7OSJ3Qiws7rw40XYo2xyy2WFjDRWOy6GiW+zpFBp+uMk+VmHqlQ8eFN4mqNNHc7zi7Qate+W0RtrPGFdmZssgoVN2+V1xmnJmd/UwmHw6plF8Fip7VYeZNhsfN5xBWWStp2nNgdJwLxz4xNNm27MtcNC3617A6x2BJyz+1tp6lnKMWJE69JS79YvTnFtYCamEDRdQC0j9GiWlp6h9GBoTYhLHaZRgbdKacuyplFthrF5/VFHhwGh/bgTWKMnTMprliNizhcsRC9u7CrUawUmYQ7V7IDw7UWGxmUJ8pwblibiiXSpigwzq59t1jfnDF+76XJFnbbwJ0X2fJ4ohLQViwog51i9UxGjB2kNs6uv01aAJ7IPWIDmV4rv4lktxY72gUDrZmbOAFQNEteew9TmOOmpjiX+1+RsJSUCrvW18SKHGtCoTsneMkT6/+6ZC4jHh+9RwMMMsZiZxjDKYp+JMGyIjH3ZI20vywRdjqBAsUeX5wWOxDBEq3FLpPi62xmrhBXbKgEiuZtoL3BO04EohTMPU8sdv77s0udxEpJHaCSlxnbtBVmLMssq2kmUTAjssXOFn7JsNhBdIlHycL0iJ2IwyGfR7KFnf2bzWSL3bRSETk9EjqypKqQNqv0R8LCbmQAHv/KeHxyKLSWzz7WjFibkrkhhV12hTwYtwS6Y8fKnQxxdMRL35CHcmOxO0GxLGMjI0cjDAyPQyfXFeu0Yux0AhY7j1eyYuO22A20SeZnKI52SQuljBR2yyWzqitIAC5Elzjhz9y14qqz4+pGhyRIPh5h586RvrrJyIz1+USkmvi60ERjsbPbjiVqsSuskQLRqbTY2XFkxmJ3LJVLRVxE02YvWjK91AnIg2ihlDyBcTFXXpCduNBpWA/Pfh9+eQH86frx+pmB9LeKFTnWjFibYCVPOhsgu4jppfIbbQ1MoHA4RNyNHh2LwTMWuxMUZYkez3BiPVld2oMvHstYCJzuJAg7jwen0mPvMSaicRd2ZWBGrI1tiQvljj28SS5+0d7I6+rl1Y6z69gr9fvifXIvW5Aci113oxRLnWEyYkNSMENuMuHiVfvtdmIJWuycLnEjpVLYte2A7KLERelUo2IpHO0c/26TQfuu+OJqU01RNfRIMV9b2CXFDWtXGjjrP+HAc/Czc+CvN05MUrFjG2PNiLUpmSffnX/f5c59UDKXyiKJpbPr1B2DKwc8Q2NZsybG7gRFueWLHx1NVNiN4nMkp50YgMttiTFvAnXs7PcUr8UOwosP++aViRe5iiXyIw+VGXt4U3RuWJviOSJg7Ti7eEud2JQukCfSRK0J9hOzsdiFxhZrA62hxyTLYgepr2XXulPcjpmapZkubDdgMt2xbXHG1aaawpqxBJ4lY8IuCRmxPYcktOfCr8J/b4XzPgN7H4efnAH33DxuZYs3I9YmWMmTzgYoqRtrEWZ3ljgGd66x2BnAYcXYjQ4HUf9R4vVpXDqOsiJhcLlkXglZ7EZl27gsdsW1klkazl04Vpw4A4Wd0y1iJ5iwG+wUF220blibuWuh8RnpWNG+G1DxNwIvmw+jA5Fr7UWiaau4/uJ9Mj4RiKaWXX+LFKLOykv8eKmsZae1WOxMYeKJ2P2fk1mo2C51kukU1UjrM6+HWSW5/L/LFnPD6iRcp3uPQGGVuD1zp8MFXxCBd/Z/wfYH4Eenw/0fEc9GfqV02omHMWFnxdl5RqSMUEkd07JcFGS7jMXOEBq7w4NnJH5hZxcCjrl1VxjscidRtfUKgdd2PTnjsCQ63XKDimSxyy2RWnCZyMzlcGTLxJpitns2VmFXt1YayjdtkVib6bPHU+xjJZYi0OFo3ibuYHfmPZlmDNF0n+hrhoIkFZwtniPxqcmqUxiOgTZxV5kesRPJK4X8GdCcpNZidlxtJidO2BRVS6hIXxNKKW4+bx6zS2Po1xqK3sNiDfQnrxQu+ip8bCus+QBs/RvseSyxh007vMcWdnbrytJ5AJQXZo8lhByDn8Uuy+lg+rTM6joBRtilBIftih2J3xU76vWRhQcdj2UsFHbyhC+RGDsRdsoV57xKI8SBdR/IzPg6m5krxCpmu01tDm8CFFTF2DN1rlXPrmF97D1iA4nG1R0NzVtNfF0kbItduFir/lYRAcnA/k2kwmpnesSGZ/YasR75EitnBYzH1R4vFjsYi7NLGr2HQ3c3ya+AS74J//UynP3fcNZH4z9O1jSJgbaFne3itSx5lQU5YS12rb3DlGdg1wkwwi4lOCyXpyeBGLsRj0+KHCcxxm4sLs4bf/Fkn/WeHPEKzrL58sMKVUU/U0ud2IRKoDiyWURZTozBxHllkuXVsF4EWSIX+IIqyMpPrJZdf5u4W0x8XXjyKgAVwRWbTItdrbymIs7O7hFrLHbBWXSZ/EaatiS+r/bjICPWxraqJbNQts8nrli7AHIoiqrFgjf/wsSOV1I3LuzsV0vYVRRmh4mxG6K1b4jKwsxzw4IRdinBZblivQkIu1Gv1bormRY7K15PJZA84bNq4MUt7EoXgHdYYhsm7NwryzMxvs6mdIGIJ/84O62txIkY3bA2Y3F2w4ld4JUSt0IiFju744TpERsep0tEeVhXbEsSLXZz5TUVtexad0goRKb2LU03Cy6WGNRdjyS+r7YE42pTyVj3iYPhx8XCYIck8xVGEHbJwr+WXWeDXMvzygFJimjpHZrYfcKVA56jtPQOU1GQmeEpRtilAKcVm5SYsLMsdvHEsoXCFmO++C12Xis+T7ninFe41le9h2VumWyxczjE3erfWqznoMQl2f1kY8VuLwaJx9qULkgsxs7OiI23VtSJRH6YIsXDfeKyT5bFLrdYEjFSZbErP8lkxIZiWgnMPhN2PZr4vtoTjKtNJdkFIvh7kmix67XcuikTdvPkWj3Ua5U6qRs7zysKshn2+OgdCrg/2jF2vcZid0JjJ094E4ixG/H6cKs4OzyEwtqXSiDGzmd103DEK+xKw8SBjWXE1sa371RRvVwEkJ1IEmth4kDmnDVmTU3YJVO2ALoPjrXAiZnmrVA0W25ehvAUhClSbAu+ZFnslEpNyROtxWJnOk6EZ9Gl0PJq4hbU9j3HR+KETdGs5MbY2Rn8oWLsko1/ZqxV6sSmwipj0hoYZ+fKwTd6lN4hz9iYTMMIuxTgspInfJ5kWOySKeyc+FCJWexsV2y8yRN5ZfLUF8yqlMnFif2ZuULcB3bJg8ObxLIar5Uru0BEYV554oKqdD6gJ7bOiRbTcSJ6wlnsxtqJVSTveMVzJj95or9VuquYjhPhWXSpvCZitfOMJB5Xm2oKq8etbMnAtv4V1YQflyxsIde+e6zUiY1dxmRCnJ07B5/VRSoTS52AEXYpwZUlqt4Xrip9BEY9EmMXt8szGErhwZmQxU577eSJOOelVOjM2K5GiV0JTH3PNGyXq+2OPbxZskgT+a4u/jq86bbE55ZIZuzIgGxn4uuiI79CChQHy45MZnFiG9til8x2VoGYHrHRUToPyhYlFme3+1GJq607P3nzmmyKapJssTssnqRpcdami5USK1Z1/1Ni4PATdnbh4QmZsa7cMQ+IsdidwNgWO+9o/HXsRrw+3HhRyYyxA7y4cCTiik3UYgciPoLF2HU1yoUj0yuwF9dKrb3DmyXh48iW+N2wNrNWw0lXJD630vnyGk+cXct2QBuLXbQUzJCbw2DHxHXJaifmT3EteIaS284qENMjNnoWXyYtsML1vg7Hy3+UTPZ5x5Owq5YahyMDydmfXerEkSJpkpUnn/mex+X/Vg07CG+xUx6764Sx2J2wuLOTYLGz6tgl1WIHeJQTlYAr1hZ2TlcCJ3jZAikXMNx37PJML3Vio5RVqPhlKSo8OpC4sEsWWXkSB9O0NfZtm1+RV1PDLjrCFSnuawZntiQ9JItUlDxp2yFzTqYLeaqy6DIR9nsfj33bvmbY+0849TpwOJM/t8miaJa8JiuBovdI6hInbErqxn+zfha7vGwX+cG6T7hycfqGAW2yYk9k3JYrVicQY2fXsUvIMhYEL66EXLF21wqnO4F5lYbIjM304sT+VK+QIPPGZ63/Z4iwAynHsOefsXcpaN4GOdNTF+9yvBOurVh/iwi/ZGaWjgm7SYyza90phYlNRmxk7LjYeNyxr/xZChOf9s7kz2sysUVYsuLseg5FrmGXbGx3rDtvgkW9oiBILTsrYznf6aE4A7tOgBF2KcGdZfVkTcRiNzqKQ+lJsNi5cOgELHbeJLliAdr9hN1wv6ShHy/CbuZy0F7YtE6SQfye/NLOydeC52jsN5ymrRJfZ27q0RHJYpesUic2trVksix2pkdsbDicsPAScevFcq3XGrb8EWatkYLtxxNj3SeSYLHzSXuylGXE2tjXar9SJzYVhdkTs2ItYVeTrzKy6wQYYZcSsixXrE6gELDXsvY5EnF5BsGnXAm5Yu335EpEcJbUgXIcGwfWfZxkxNrMtDpQtL4mIi9VMSLRMGuNiIBtf4t+G69HsnyNGzZ6xix2QYSdbbFLJu4cKJg5ecKurxmGekzHiVhYdBkM90isXbQc2ihZmafdMHnzmiwKZwIqOQkUg+1WceIUewhKrLg623LnR0VBzkSLnUvu59X5kz2x+Mmgu8/UxWU3T0/AYucZtXuyTkLyRAIWO+wYO3cC83JlS1FO/8zNsRp2Gdx1wp/CKgnChcxyw4KIzGXXwN4nYKA9um069khgvhF20ePOheyi4MkMfc3JzYi1mcxadnYrMWOxi566+v/P3r1HSX7e9Z1/f3+X6hlpRrasy4xjKZbBwkJIQgbZEC7rC3Ei2zn4ErPYEEISArnYOZvsOsFeE4cIvA4su5yTs4YTBwx4ARsiCJggYxNfAjlcIrHWxbKQkG2wNbqNjeXRtft3+e4fz/Orru6p7q6qrqrf012f1zl9uqequudp3Ex/9fk+3+cJU5PTHHty6y+Gz/ma1yxqVYuTl+E/WObRiu2uJuszsdvmxHlrZ98+ERO7Z567jMXNRoXdMnSTrPtJ7OLhxvsaUhj3da0g389UbBsTu3Kf69p+Q8KwsDv7v6KS1aV2qRV2ENqx3sCnfmOy13c3TmgidjrHT5yd2FVPhbPg5nU48ajzL1vcWXa6I3Z6g3PCVOvdH5zsGJqNJ+CTvw5Xvmr6e6VTMa8jT4Zn2C15j92Fl4cuy1e+9KynLj5+hKeqlkfXR8KPmNidPGdZC5yeCrtlyDIq8n0Vdt3hxtl+krFxX9fy/SV2TfjcmW+e6Fx4OXzx05tngH3pL2DtvPlOES7aJdeFlnKKhd2JrwlHVtxx42Svf+C2MMV5kA5LTcGxE2cndt2f573HDkKifeb+UDzO28N3hWN84t2ZMqHnvRy+/LlwE8Ve/vS/wPoZeP4BbMN2nvas+eyxG946seTCrjwKP/DxrVc5RhfH40xG99ltWHjsxNEFnh+5TyrslqSm2F9hV3WJ3ZxbsVm5z8IupH3FfqZiIZy3Vj0Bj8b/5/7Sn4dfWoluTh3rG/4xfN/vLqbltl9mcPXr4HN/GE5Y38uDd8CJK9M/QzA1x0+endg9NufrxEadfxng872IvXNaE7Ez+arrAZusHfuJXwzbUJ79LQtf1sJ014rt96DsM/eF7tayDieeQHecycNnNvfZPVKF42guPDLmIPJEqLBbkooC20dhV9eh+NrXXrYx2n1OxXbDE/s+OHn7DQkH5Qy7UYNzQmqXqqtfF95/8td2f517uCNW++um1yV2o7/khrdOLCKxuyy8n/c+O/dw1IlunJjesYvDvwN7TaE/8jn47O+FoYmUhq2mdd6zwtT9k1/a39c5c3/Yp5zQ/y26A4gfenQzsfvieljfBWsq7FZebSXW7OeGh/BfDPvey7b961pB7s3Mnz+cqM32meyMnmXXtmHf0NMPyODEQXH+ZXDJC/dux545Ff6R1v666R0/GYZO1s9sPrbwxI75F3aPPhCmO3XjxGye94pwYHnXXhzntvcDHg4lPsiGR57sMzX+8qnkzszsrgwbTey+EAu7Zwxm/725aCrslqSmwNr97LELn5vPu7DLCgrf/wHF7DexO34SBsdCYvfYQ+GX40FL7A6Cq78j7P156FM7v6a7peKZX7ucNR0mx8YcUvzYQ2Hv5bkLaDEdOxE2c8+7sHtYd8Tuy/NeEd7v1I5t23B23WXfevD/neuGHfa7z667Tiwhx9YKzh3kPDRS2D38ZNia8PRShd3Kq63c152s3a0V856KdSvJ2ccPaPc95fvcY2cW9tl98c9GzrA7QBOxB8XXvBosh0/ukto9eAdgcPGVS1vWoXF8zCHFjz4I5168mKuizEKyPe/C7vTd4b0Su9lc9Lzw79dOhd3n/iD8b/b8A3bTxDjDa8X2MRnbtv1cJzaBi887wsMjrdiHYmF3braPQGTBVNgtSSjs9p/YzXsze5uV5PvYY7fZip3D1SoXXh5unxgedXLZ/r+mbHXs4nDW1h3/aefNzg/eHorstYRP4EzVTondIvbXdc6/bP7Xip2+C865AI5pInYmZnDFK+Gz/238VX6f+CUYHIev/vblr23ezrkwdGz2c5bd46dDSJBiYXd8bUsr9oHHw3urFzCJPicq7Jak2XdiN6eW5/avmxXk7G8qtiGbz4bXCy4PxwQ8/CnA4OmX7v9rytmu/o6wcfu+m8c//+Dt2l83q50Su0Xsr+t0Z9ntdypx1MN/qrRuv5738nASwqc/svXx9UfDeZJXvSYMXB10WRYKsv0kdmd6OsNuAtsTu66wo3qynwVNQIXdkjTZPgu7bqJ2AYVdsa/hiYqaObWYunsS7/1o2Gsx57azRFe8MuzLGnfF2JNfCkXfMzURO5O188ItAqNHniw8sXt2GNbY71Ri58kvwUN3an/dfl36jeEczu3t2Dt/IxztdO0haMN2nnbJ/vbY9XXrxAROHF/joTPrw9sn7ns0TsMqsZPWSvJ9DSl0hd0cWp4jPCsp9pHYWVuHM/rmoZuMfegOtWEX6ch54aytT/768IDpoQfjoapK7GZjFoq4bhK2bUKbad73xI4aTsZ+dj5f76M/Go6v+Lrvnc/XW1V5AZf/TbjnQ1v//+zWXwr/1l36wv7WNm/7vX1ieDhxWlOxEA4pfrJqeCzePvHgYzW1lUrsJOxl28/06UITu30Udllb0di8Cruv3PxYhd1iXf0d4dLtz3586+MPxolYnWE3u2Mj14o9fhq8XVJhN4d9dg/cBre8B17wD5XazsPzXg5P/iV8/o/Dn7/46XBI+LXfdbgOfj7vWeGInO3/oTipL3eHE18w33XNwYl45MlDZ9Z5qmp45ImKJltTYifQZIN9DSnM7ViRbUJi19C2s+3PMa/n14odnLv5X2wq7Bbr8peFC+u3n2n34B1hP9ixi/tZ12Eweq3Y8HDiBe6x68573O9kbNvCb785XCP2krfte1kCPPfbwr/Z3WHFt/5SOPrmoJ9dt93TnhXuon7swb1fO86Z+0MbNqHDiTsXHY/Xij36FKcfDUMUbXFEiZ3EAspnn4r1bip2vwcBb5eXlDRU7WynaGdtRTuvxA4299mpsFusYg2u/Ha467e2/gP1wO1Kavbr+MnNqdhFHk7cWTsWJhP3W9jd9stw3/+Al90AR58+l6WtvLXj4ay6u28Kbflb3xcum09wL9m+DI88mXGf3ZlTSU7EwmZi9/CZ9c0hiuKIEjsBz0uKfR0rspjEjpjY1c3sid3cWrGweem8bp1YvKu/AzYeg3t+J/y5egq+cLf21+3XsRPh1obqycVeJzbq/Mv2V9g9+SX43X8Dl34DfO0b5rUqAbjiFfCXn4H/8e5wF/a13933iuavK8pmvX0i4cLu4pHErjv2xAbnKLHbiZldb2Z3m9m9ZvaWMc8/28w+Yma3m9nHzeySked+zMw+Gd++c+Txnzezz5rZrfHt2mV9P7tps8G+CrtFtWJDYlfPXNhl8xyegHDbQT4I56jJYl32LSFJ6tqxp++Cttb+uv3q2q6PPjiS2C2hsHtkH3vsPvqOsBfsFT+RZDvsQPuql4f3//WH4cjTN2+lOEy6q8Bm+RlsWzjzQLIp5rG1gnPi7RMPnQkpXTE4qsRuHDPLgXcBLweuBN5gZtuPuv8J4L3ufg1wA/DO+LmvBL4OuBb4BuDNZnbeyOf9S3e/Nr7duuBvZTL5gJLZhydsQVOxZAWlNVTNbEeeZF7PtxX7tW+AN90M56a3ifbQyXK46rXwZx8Oic2Dd4THldjtT9d2feyhUNwdPX/xR/ec/2x45POzbV5/4Da45Wc1MLEoT3tW+A/W+qmQkpdH+l7R/B05L7Rjd7uqcCfd4cSJ3RPbMbNwSPGj6zz86DpFZuRK7Hb0QuBed/+Mu28A7wdete01VwIfjR9/bOT5K4Hfc/fa3R8HbgeuX8KaZ+Z5OFbEZzxEdGGt2Pj16mq2ojNr59yKzXLtr1umq18XjtK567fC/rrBcV3ltl9d27VL7Ba5v65z/mVh8/q0p/9rYGI5rvhb4f3zD2EbtnPiqnAP9bS6n9lEEzsIhxQ/dOYpHjqzzsXH17BSe+x28ixgtCF/X3xs1G3Aa+PHrwGOm9kF8fHrzewcM7sQeAkwek3BO2L79ifNLI1TbvM1BtRsNLMPKYSvM9/EzuLXq6v1PV45XuY17bwHOmR5/srXwTO+IhxW/OAdcPIqteL2a3tit+j9dTBy5MmfT/d5t71PAxPL8NfeCN/zG/BXnt/3Shbn5FXwhXumT7KGZ9iluccOwj6704+G4YmLzjsC5dGwJzlRqf8L/mbgRWb2CeBFwCmgcfcPAzcBfwC8D/hDGN5k/1bgCuAFwDOAHxz3hc3sB8zsFjO75fTp04v9LgDykgEVG/VshZ21NS3Z/C8Sj3fP1vVsiV3hc56KleUyC+2hz/4+PHCr9tfNwzkXhOn1ZSd2MN1Zdk8+Ar/7drjkhRqYWLTBufCVL+l7FYt14qpwZuPDd033ed0kbcKF3YmY2D18Zp0Tx9fCVGz1RN/L2lGfhd0ptqZsl8THhtz9fnd/rbs/H3hbfOyR+P4dcQ/dywAD7omPP+DBOvBzhJbvWdz93e5+nbtfd9FFi7/o2vIBJfXshZ1X1AsooCy2Ytt61sSuobE57/uT5brqdYCH1oL21+1flsG5F28WdstI7M57Vigmp0nsPhYHJl6pgQmZg+7fjmnbsWdOhS1B5144/zXNycXH13hio+Ev/vJxLj5vLSR2asWOdTNwuZk9x8wGwOuBD4y+wMwuNLNujW8F3hMfz2NLFjO7BrgG+HD88zPjewNeDczQ9F+AYo3cnGrGvWx5Wy2kgOpasU012xl7OTWuVuzBdtFXhc3doM3z83L8RDg6ptlYTmKX5WHz+gO3wvpje7/+gdvh5p+B675v8397kf04/zkwOLZ5LeGkzpwK++sSvomjO8vuqarlxPEjMbHT8MRZ3L0G3gR8CLgL+FV3v9PMbjCzb48vezFwt5ndA5wA3hEfL4HfN7NPAe8G/k78egC/ZGZ3AHcAFwI/upRvaA9WhGSsWp+typ/r1V0jusSumbXgnPdUrPTjBd8fbv24SBe/z8Wxk/DQneHjZSR2AJdcB5/+KPyfXwnv/2647VfgqS+f/bq2hZviwMRLNTAhc5JlcPGVMyR29yd5R+yo7iw74EAkdr3+Rnb3mwh75UYfe/vIxzcCN475vKcIk7HjvuZL57zMuci6wm7GDZeZV7TzPuoEsCImds2MiZ3XNErsDr6v+57wJvNx/MTmP/zLSOwAXvMf4Ov/HnzqA2HK+U//C2QlfMWLwy0jz3tlOEbo9veHu0tf9a5wFIvIvJy8Cu74NXCfPIH78in4q9+42HXt08XnHdn68ZmY2E3zfS6RfiMvicVzrDZmTOzydjHJWDZsxc44PEHNeqY9diJbjBZzi7z1hT/LAAAgAElEQVQndlSWh0OnL/sWuP7fwak/gbt+Ez71m/CBfwb2z+Gybw5njV3yAvja71rOumR1nLgKbnkPPPK5cLbiXto23MbxtHQHJyCmdN3Hx2Nih4etFos+o3IGKuyWJI//49cbsw4pVLQLKKC6PXazDk8U3ui4E5HtRtuvi751Ypwsg0tfEN5e9iPhEOK7PhDSvPVHdcOELMboAMUkhd3jD4fbbhKeiAU4vlZwtMx5smrCfrvyaHiielKF3SrLyljYzXheXOE17QKGJ7KuFTvjcSdheEKJncgWXWI3OAZrx/pdixn8lWvD20v/dWgRd7+YRObp4isBCwMUV7xy79efSf+oE4i3T5y3xqkvPckzzhmE4QlIdp+dCrslycpuSGH6H4SmdQrqhSR23d4/n3GPXUETjlkQkU1dYtdHWrcbMxV1sjhrx8KB5w/dMdnrh2fYpXvrROfE8SNs1C1ZZlsTuwTpN/KS7KcVWzUtgwUlY11h186Q2LmHglOJncg2xxIt7EQW7eRV4TidSXS3TiR6T+yoF19xEfc/Egs5JXYCkMeLn2c5L26jaSmp8Xz+vfx8H4Vd3TolTZi8E5FN514c3i/rqBORVJy4OgzsrD8Ka8d3f+2Z+yBfC7e1JO6fvvi5m39IPLHT7tklyQezt2KruqWwZjGJXRm+5iyt2LrxWHCqsBPZohiEX3DPvLbvlYgs18mrwvvuHMfdnLk/+cOJx1JiJwBFHJ5o69kSu8GCCqh8eKXY9Ouq2pZzlNiJjPdP/nvfKxBZvhOxsHvwjr3Pp/vyqeQHJ8ZSYicAxSBU+O0MU7FVHZIxssG8lzUc6vBZWrF1S2Et5PrvAxERIeyXO/K0yW6gOJP+GXZjJZ7YqbBbknKY2E1f2HV77MjnX9gV3VRsO0thF78XtWJFRARCW/XkNXvfGds24XDiAzARexYldgJQrM3eiq2Ghd0CWrH7SOyajfC9mFqxIiLSOXEVPPypULzt5PHTB+Jw4rG6xE6F3WorB6HC91lasU1Lac1CCztmSezihK8psRMRkc7Jq6B6Av7yszu/5ssH43DisbrETq3Y1VaUsx8E3CV2tshW7CyJXUwfrZj/ukRE5IDqBih2O6i4u3XiIO+xU2K32iweUOyzTMXG4YlFFFBdwckMBefwTD4ldiIi0rnoCrA8TMbu5IBcJzaWEjsBNgcfZk7smoUWdt7WU39uXasVKyIi25RH4MKv2n2A4sypA3M48VnyMhSuSuxW3D4Ku406nGO3iFbs8Gs207diu0GQTIWdiIiMOnn17keefPnUwTycuFOeo8Ru5cVW7OyJXU1WLKCAikWZzTA80bVitcdORES2OHlVSOWe+Mvxz5+5/0DcEbuj8ogSu5WX5TRk2EyJXUVmTraIAiqLhwvPUNi1MeVTYiciIlsMByh2SO3OnDqYZ9h1iqNK7ARqiplanl0ylnWp3zyZUZHPlNi1cZJ2IQWniIgcXCevDu/H7bNrG3j0gYM5ONFRYicAlZVYO31i111D1l3/NW+h4Jx+eGLzuBMldiIiMuLYxXDuxeMnYx97OB5OfJATuyNK7AQaCrJZjhWJV3ctKhmrZ0zsuqNbciV2IiKy3cmrxp9ld+b+8P5A77E7qsROoLZytiGFeHVXXi6gFUsoOG2G406GU7FK7EREZLuTV8Ppu8/egnTmvvBeid1CqLBbotpK8llasXEvW7GoxM5ysv0MTyixExGR7U5cHU6C+MI9Wx/vErvzlNgtggq7JWqykmymZCy0YlNL7LpryNSKFRGRs5yMk7HbByi+fF9IvM55xvLXNC+FhicEaK0g830cBLywxG62dXmjwk5ERHZwweXhdont++zO3H+wDyeGkNipFStNNqDwWVqxIbFjATdPADQ2Y2LXdHv/VNiJiMg2eQEXX3H2ZOyZUwf7qBNQYidBm5Xk+xhSWFRhF5LEWQq7mNiVGp4QEZExTlwdWrHum4+duf/gF3ZK7ARiYTdDy3N4DVlezHdB3Ze3gnwfhV1RHJn3kkRE5DA4eTU88QV47KHw57bZbMUeZErsBKDNBhQz7bGLn5NYYteNsBdK7EREZJztAxSPPQzewNMOQWLnzUy3SS2aCrsl8qykYJYCarGt2MaKmaZ1GbZitcdORETGOPE14X03QHHmVHh/GFqxkGRqp8JuiTwPiZ2P7jWY5POGhd1ikrF25lZsWFehwk5ERMY5ej487dLNxO6wFHbdFqQE99mpsFumfMCAmqqZrrAbRr2LbMXOkCR2k7Q67kRERHZ04qrNydgvx8LuIF8nBkrsJPCspLSajaad7hMXPRWblRT72GO3qHWJiMghcPIq+OKfhSLozKmQdh09v+9V7Y8SOwGgWGNAxUY9ZWHX7X/LFjMV6zO2YmkrWjfI8vkvSkREDoeTV4O38PBdm2fYHeTDiUGJnUR5GVux0xZ2i0/s8hlbsbWpqBMRkV2ciJOxD33ycBx1AkrsJLB8QEkzdWJnC255elaQezP9JzYVNYtJEUVE5JA4/zkwOBYGKL586uDvrwMldhLFVuz6lIVd1i52KnbWY1israhRYiciIrvIMrj4SnjgNnj0ASV2C6bCbomyYkBhLRsb0x1ouIzEbpbhCfNaiZ2IiOzt5FVw383hUN+DftQJKLGTIIvHglTV+nSf191WsbDErqBg+lZs2GOnwk5ERPZw4qpQ1MHhKOy6xE6F3Wqz+INQb0wX3Vpb05ItbPrU88FMrdisrWjUihURkb2cvGbz44N+nRhsJna1CruVlsUbGqqNKRO7tqJZZDIWE7tpb8Swtl7sukRE5HA4cSUQjzg5VImd9tittK4VW0/5gxAKu8W0YcNfUFLS0LTTFXaZL7jgFBGRw2FwLjzjK6A4evAPJwYldhJk5RoAzZSJXe4VTbbAwi4vyMyp6+nasZkSOxERmdSl3wAXXn7wDyeGOMxoSSZ2+q28REUs7Oophydyr2kXnNgBVBtPcWRt8snbzGtaFXYiIjKJV/w41NP9/kuWGZTnJHnciX4rL1FehMKu7e5+nYC7hwJqQdeJAcNjVOpqumNYMq9p9CMkIiKTWDse3g6L8oimYlddMQibLadpxTatU1LTLrAVa3kozuop/0tq4QWniIhIqoqjSSZ2KuyWKB90id3kPwhVEwo7X+geu5DYNVMmdoVasSIisqqU2EmX2LVT7LHbaNqlJXZNNXmLGGIrdpF7/0RERFKlxE7Kcvo9dlXTMlhwYmddYjdlKzb3GlcrVkREVpESOykGoYCaprDbqENixyILuyJ87aaerhWbqxUrIiKrqjiixG7VdVeK+RTJWNW0FNbgC7onFkYTu+lasTmNEjsREVlN5VEldisvFlA+Qyu2+9xFyGJi1065x67warFDHSIiIqlSYifE1M2baVqxi5+KzbrEbop1ARQ0Cx3qEBERSVZ5FKon+l7FWVTYLVMehidsigKqilOxViwusbMZE7scDU+IiMiKKo4keaWYCrtl6vbJTdmKLRfdio3raqccnii8UStWRERWU6njTqQrztopWrFNS2kNtsDhiay76qyZsrCjASV2IiKyigoddyLFLK1YX3hil5dx79+Uid2ij2ERERFJVnkU2grapu+VbKHCbpm6dGuKZKyK59hlC9xj1w1PtFMUnG1MEhd5DIuIiEiyyqPhfWKpnQq7ZTKjopwqsQtXijULHZ4ohondFEli91oVdiIisoqKWNglts9Ohd2S1VaSTbHHrjvHbqGJXfzaPkWSWHcTtGrFiojIKirDpQNK7FZcbQXWTl5AdVeKLXJ4Ii+nH56oq/jaXMMTIiKygpTYCUBjJfkUhV1d12Tmw+JrEWYZnmji2T2LLDhFRESSpcROAJqsJPNpCqhwr+wiW7F597WnKDibrghc4LSuiIhIspTYCUyf2DX14gu7soxfe4rhiborOJXYiYjIKlJiJwBNNiD3yQuoJg4pLLYVO0NiN9xjp8JORERWkBI7AfCsJPd64te3Syjsivi1vZl8XU1M97p7ZkVERFaKEjsBaLPpWrFtLKAW2fIsu6JxiqnYZgnrEhERSVahwk6ANhtQUuHuk71+eBDwAocn8ozas6lasV2SaMXikkQREZFkdTdP1CrsVppnJSU1dTtpYReGFBa9l60mn+p8vaZRYiciIitsmNhpj91K8zwUdht1O9nrl5DYAdQUU7Vi23jcSaY9diIisoqU2AmA52sMpinsmuUUdpUVWDvFUEc3PKFz7EREZBUpsRMAusSumbSwW87VXTU5NsXByV1ilyuxExGRVWQWijsldisuHzCw9BK7hukSu25d2QKPYREREUlaeVSJ3aqzYhBasRMmdixpj11j+ZSt2LjHTsMTIiKyqoqjSuxWXj6YanhiONCw8KnYgmyq8/XCa4tSe+xERGRFlUeU2K06K9YYUCXXiq2nHJ7o9v5pKlZERFZWcVRXio0ys+vN7G4zu9fM3jLm+Web2UfM7HYz+7iZXTLy3I+Z2Sfj23eOPP4cM/vj+DV/xcySipSsGEw1PGHDxG6x30ZLQTbF8ASx4MyLpP7PKyIisjzlEd080TGzHHgX8HLgSuANZnbltpf9BPBed78GuAF4Z/zcVwJfB1wLfAPwZjM7L37OjwE/6e7PBb4EfN+iv5dpZPmAgTVsVM1kn9C1R7PFTsU2VpDNkNjlAw1PiIjIilJit8ULgXvd/TPuvgG8H3jVttdcCXw0fvyxkeevBH7P3Wt3fxy4HbjezAx4KXBjfN0vAK9e4PcwNYtTpNXGZD8Iy0rsGivIfMJik83CrlArVkREVpUSuy2eBXx+5M/3xcdG3Qa8Nn78GuC4mV0QH7/ezM4xswuBlwCXAhcAj7h7vcvX7FVWdIXd+kSvt3Y5e+xaK8inaMUOCzsddyIiIquqOKLEbkpvBl5kZp8AXgScAhp3/zBwE/AHwPuAPwQmj5sAM/sBM7vFzG45ffr0nJe9szxOkdbVZIXdsD264KnYJivIfPJWbDetm5dK7EREZEWVR6F6ou9VbNFnYXeKkLJ1LomPDbn7/e7+Wnd/PvC2+Ngj8f073P1ad38ZYMA9wBeBp5tZsdPXHPna73b369z9uosuumie39eu8jJcQdJOWNgtK7Fzm62wKwsldiIisqIKHXcy6mbg8jjFOgBeD3xg9AVmdqGZdWt8K/Ce+HgeW7KY2TXANcCH3d0Je/FeFz/ne4HfXPh3MoUusWsmLuyWk9iFVuz0hV2hxE5ERFZVqQOKh+I+uDcBHwLuAn7V3e80sxvM7Nvjy14M3G1m9wAngHfEx0vg983sU8C7gb8zsq/uB4H/1czuJey5+9mlfEMTyuOetEkLu7ytaMkgyxe5LNqsnK6ways2PKfIU+/mi4iILEiCid1iz9DYg7vfRNgrN/rY20c+vpHNCdfR1zxFmIwd9zU/Q5i4TVIRW7GTFnaZV2H/2yIXRUjsiikKO2sragoGZgtclYiISMLKo9CsQ9tClkbQkcYqVkgRz31ruztg95C1FW22+HZnm5XkTJPY1dQsNkUUERFJWhHCmpQmY1XYLVkxbMXu/UPg7uRe09gS9rFlBfkU59hZU6mwExGR1VaeE96rsFtdFqdIfYLErm6dknpJiV1BMUViZ15RW6+dfBERkX7F7VUpHVKswm7Z4rElk7Riq6altAZf8HViAJ6V5FMcBWhtTd3vFk0REZF+FUfDeyV2KyweW+IT/BBU9fISO7KCcprErq1plNiJiMgqU2InTNGK3WhaSmp8CYWdZ4MZpmK1x05ERFaYEjsZ3iDR7H0vazUs7BZ76wQAeUFuHka2J5B5TavETkREVpkSO+kKO2smSOzqlgE1vuBbJ4DNVLDdu+CEcAyL9tiJiMhKU2InXWE3SSu2aloKmqW0Yol/x+Tn62mPnYiIrDgldjJsxbYT7rGzeuH3xAJYHoq0upqwsFMrVkREVl2X2KmwW2HF5K3YqnEG1JvF4CLF4rGe+KozJXYiIrLiusSuVmG3uqbYY9cNTyynsAt/R11NuMfOa9olnK8nIiKSrGFipz12qyvuZcsmaMVWdVfYLaMVG/6OZsLELlcrVkREVp0SOyHLqCmwCaZPu3PsbImt2GaCY1iA5d1hKyIikioldgLQWEE20Tl2TmnNME1bpKwbntiYPLFbxlVnIiIiycqysJVJid1qa6wk98kPKLZi8YmdTXGHLagVKyIiAkB5VIndqquzAdkkrdi4xy5bRmEX/46mnrAVS6PETkREpDiqxG7VtVlBNkFiF/bYNUtJ7LJiugOKC1/OHbYiIiJJK48osVt1rZUUk0zFNuFKsaUkdnlX2E2a2NW0KuxERGTVKbGTNhuQe73n66q6pVhSYZcPW7ETJnY0oFasiIisOiV20mYlBTV10+76urquyc3JirWFr2nqVixqxYqIiITEToXdSmvzAWtUbOxV2MXDgvNyecMTExV27hQanhAREYmJnVqxK82zASUNG/XuhV1XZC2zFdtOckBx25DhS7kRQ0REJGlK7IS8pLR6gsIuJHbLbMX6JMMT8agWtWJFRGTlKbETzwcMJmjFDtuiS0jGusTOJ0jsvAnrMhV2IiKy6oqjKuxWXj6gZILEropF1hIKqG4fX1e07abp1qVWrIiIrLryiI47WXn5gAH1nold06wPX7/wJcV27yTn2NXDJFHDEyIisuIKHXciXWG3R2Ln1fJasUUZ/44JWrFNXJctoeAUERFJWhkPKHbveyWACrteWDGYaHiCri26hAIqm2KPXROPYVlGi1hERCRpxZHwPg489k2FXQ+siMMTeyV2XVt0CYVdUU5e2NVxj50VKuxERGTFleeE94nss1Nh1wMr1ihpWN9jj91wkGEJe9mK7qy8SYYnuqlYDU+IiMiqK2Nil8g+OxV2PciKCffYLbEVW5QljRu0e99hu7nHToWdiIisuOJoeK/EbnVlxYA1q9ioml1fZ83yWrFlbtQUw8OHd9PtsbMl3IghIiKStIOa2JnZD5nZMxe5mFWRxR+Cqtq97bmZ2C1hKjbLqMg3i8lddEeiZNpjJyIiq+4AJ3Y3AJ8zs98ys1ebWb6oRR123QTqcLp0J+2yE7scn6QVW+u4ExEREeDgJnbANwA/C3wr8GvAfWb278zsqxayskMsH4Qfgr0KO6uXt8fOLBR22QTDE21M9XIldiIisuoOamLn7je7+z8Gngn8feAe4F8Bd5nZ75nZ95jZ0QWt81Dpru/as7Dr0rNsOTc8VBQTDU90rVgNT4iIyMo7wIkdAO7+pLu/191fBDwP+HHgK4GfBx4ws58ys2vnu8zDpYjXd+1d2C0vsQOoKTaLyV20cd1ZubboJYmIiKRtmNgd0MJum88CfwLcBRhwDPh+4E/M7Lc1bDHepK3YrCuyllTYNZZjE0zFdocY50rsRERk1Q0Tuyf6XUc0U2FnZl9jZv83cD/wK8AVwI8CXwFcCrwDeAnwnjmt81Dphifaevf9bJuJ3XIKqIYC88lbsZmOOxERkVXXJXaJtGIn3rxlZseANwDfB7wAaIHfAd4N/La7j562+3Yzewz4N3Nc6+ERE7h2r8TOlzcVC1BbQTZBYjccniiV2ImIyIrrErtEhiem2ZX/EHAEuI9w9MnPuvt9u7z+LwANU4yTh71p7R4XBmdNHTLVJSZ22QR77Lrz9XIldiIisuoOamIH/C7wH4EPbkvnxnL3XyG0aWW7WKj5Hq3YzCtaMrJsOUcGNlaQT9CKJSZ2hYYnRERk1eVFOL3ioCV27v7qRS5kpXSt1V0SO3cn95o2K5d271szYSu2G57QzRMiIiJAeU4yid00V4p9m5m9c5fn32lmL5nPsg65bnhil8OAq8YpqWlsOWfYQZiKzSZI7LxWYiciIjJUHEkmsZsmDPpB4Lm7PP+c+BrZS5fY7XIva9W0lITEblnaCVux3mp4QkREZKg8cvASO+BrgT/a5fk/jq+RvUzQiu2jsGusnCixG+6xK5TYiYiIUBw9kInd04DHd3n+SeD8/S1nRQwTu51bsRtNS2kNbssr7DybdHhig8pzymJZu/9EREQSdkATu1PA1+/y/NcDD+5vOStiolZs2GPnS7zdobVissSurajJKXIVdiIiIgc1sftt4HvN7K9vf8LMvg34XuCmeS3sUIstzOHNEmNUdWjF+jL32E2c2NVU5BSZLX5RIiIiqUsosZtm5PIdwN8GPmRmHwRujY9fC7yckNb9yHyXd0jFFM72asVS49nyDgF2KygmKOysranJOVeJnYiISEjsnvhi36sApjvH7iEz+ybgpwmF3Cu6p4APAm9y9wfmv8RDKLZis10Su426ZbDsVmxWkjNpK7ZAgZ2IiAgHNrHD3f8CeIWZnc/m0Sf3uvuX5r6yw2xY2O1+3ElBA/nybmVrs5Lcmz1fZ21FRYGZKjsRERGKo1ClscduptNvYyF385zXsjqynIYc27Wwc0qrl3ZPLISp2GKCxM6aMDwhIiIihMQukeGJmQo7MzsGPJ0xwxfu/rn9LmoVNFaQ7zY80bScS705QbsEbmVICfdg7XJvxBAREUlacfRgtmLN7PXADwFfvcvLFOVMoMkGZNXO6dhG0/J0lpvYkRehsHOHXdqs5hWN/mcWEREJusRuj9+fyzDNXbGvBn6ZUAz+B8CA9wH/CaiAPwFuWMAaD6VwtMgurdh43IktMbEji3X+LufrQTcVq8ROREQECImdt3v+/lyGac6reDNwF+F4k7fHx97j7q8HrgOex+YRKLKH1gaUXtG0Pvb57oBiK5bYiu2OVtll7x9AplasiIjIpvJIeJ/APrtpCrtrgF9w96eANj6WA7j7J4F3A2+d7/IOrzYrKa1mo27HPl/FK8WyZe6xmzCxy7xSYSciItIp4wkWCeyzm6awy4Hu9L2uJH3ayPN3A1fNY1GroM1KSnYu7Da6VuwSE7vhoEa7+2SsEjsREZERRSzsDlhidx/wbAB3fxJ4mK13xz4PeHx+SzvcPB+wRs16M34Ktbt5YpmFneWhWPNdbsQAyLymVWEnIiISdK3YBBK7aX47/wHw19ncX/cB4J+b2ZOEAvGNwG/Nd3mHl+eDXRO7qmkpaciWmdjFe2nbemPXmdfMaxrTVKyIiAiQVGI3TWH3U8BrzOxoTOzeBrwQ+OH4/J2EAQuZgGclA56ianYanghXii21FRv/rrqapLBb4jEsIiIiKTuIiZ2738zIbRPufhq41syuARrgLncfHz/J2fIBpT22S2Ln4RaIHlqxdb3B2i6vy73eHLQQERFZdQctsTOzc4H/Dfhjd//Q6HPufvsiFnbo7dWKrSpyc3yphV34u5pq9z12ude0KuxERESChBK7iYYn3P1x4H8HLl3sclZIEYYnNnYYnmjrdYCltmKzmNg11e7HnYTCTq1YERERIKnEbpqp2E8DJxe1kJWTr1FSs75DYtd2qdkyb57oErtYVO74Mk3FioiIbBomdgersPsp4PvN7IJFLWaVWLF7K7apYnG1xMKuSwfbvVqxNErsREREOl1il0BhN03s8ijwl8DdZvYLwJ8BT2x/kbu/d05rO9QsHzDY5eaJtrv9IV9eAZUV4e9q9rh5ovAaV2InIiISDK8U63+P3TS/nX9+5ON/scNrHFBhNwErQit2o9mhsKtjarbEZMxiEblXYldQ40ssOEVERJJWpHOl2DSF3UsWtooVlJUD8l1ascPbH5bYis27xK7eY3iCBpTYiYiIBHkJliUxPDHNOXb/bZELWTVZMaCkotohsfMusVtmKzYWkd7sMjzRtuS0eK7CTkREBACzkNolkNhNMzwhc5SVR3Ydntgs7JZ43EnZTcXukti14TnPljitKyIikrry6MFK7Mzs7Xu/Cnf3H9nHelZGXgzIzdnY6cy4XlqxMbHbrbDr1qUDikVERDaVaSR20/x2/uFdnnPA4nsVdhPIy3BpV7PDD4EPp2KXV0ANhyd2m4ptusROwxMiIiJDxZEkErtpWrHPGfN2OXA98GHgj4ArpvnLzex6M7vbzO41s7eMef7ZZvYRM7vdzD5uZpeMPPfjZnanmd1lZv/ezCw+/vH4NW+NbxdPs6Zl2SzsdphA7SOxK7vEbpep2LYGNu+VFREREcKRJwkkdhMXdu7+F2PePu3uHwZeATTA35/065lZDrwLeDlwJfAGM7ty28t+Anivu18D3AC8M37uNwHfDFwDXAW8AHjRyOd9t7tfG98ennRNy5TFtmezscMPwTCx66EVO0Fit8yhDhERkeQVaeyxm8vwhLs7cCPwd6f4tBcC97r7Z9x9A3g/8Kptr7kS+Gj8+GMjzztwBBgAa0AJPDTb6nsSC7Z2p3SshwJqmNjtUtj1cQyLiIhI8g5aYjeBATDNdWPPAj4/8uf74mOjbgNeGz9+DXDczC5w9z8kFHoPxLcPuftdI5/3c7EN+6+7Fm1yitiK3eFeVmuXX0AVExR2VWwdmxI7ERGRTYcpsTOz64D/Bbhrr9dO6c3Ai8zsE4RW6ymgMbPnAl8NXEIoBl9qZt8aP+e73f1q4Fvj2/fssOYfMLNbzOyW06dPz3nZE4iFkVc7FXb9tWLZpbAb3kqhwk5ERGRTIondNMedfGaHp54BHAdq4B9O8XefAi4d+fMl8bEhd7+fmNiZ2THgb7v7I2b2/cAfuftj8bkPAn8N+H13PxU/91Ez+2VCy/esa87c/d3AuwGuu+46n2Ld85GHxG6nVqx1xdUSjxUp480TuyV2da3ETkRE5CwHMLH7HPAX297+HPivwI8Bz3P335ni690MXG5mzzGzAfB64AOjLzCzC82sW+NbgfeMrOVFZlaYWUlI8+6Kf74wfm4J/C3gk1OsaXny3SdQe0ns8owNzzcncsfoDi82nWMnIiKyqTwCVf+F3TRXir14nn+xu9dm9ibgQ0AOvMfd7zSzG4Bb3P0DwIuBd5qZA78HvDF++o3AS4E7CIMUv+Puv2Vm57qqNKAAACAASURBVAIfikVdTig6/+M81z03XSt2hz12WQ+FXZEbFcVkrdi4R1BERERI5kqxXmMXd78JuGnbY28f+fhGQhG3/fMa4B+Nefxx4Ovnv9IFiIWR75COZW0V8tQltjzLLKMmH55VN04dC9GsUCtWRERkqDxgBxSb2Xea2Vl71Uae/wUze918lrUC8t0HFTLvMbFrd0nsYus40x47ERGRTcXREIw0O4cjyzDNHrs3AeNvrA8a4J/tbzkrpCuMxrRi29bJutRsmYldHhO7XVqxTbzb1pTYiYiIbCqPhPc9p3bTFHZfDXxil+c/QThQWCYRp2LHpWNV21JaTUsGWb60JRWZUZNju7Riu4nZ4dEoIiIiAuU54X3P++ymKezOJaRyO3HCsScyiZjEZc3ZiV3VOAMa2my5qVieGRtebE7kjtEMjztRYSciIjJUHLzE7rPAt+zy/LcQjiGRSeyyx66qW0rqpRd2ZkZj+a6FXXc8ixI7ERGREeXR8P4AJXb/GfgOM/u+7U+Y2T8AvgP49Xkt7NDrjgsZV9g1sbCz5e9jqyl2bcW28Rw7TcWKiIiMSCSxm+a4k38HvAp4t5n9C+DW+PjXEvbW3Q38H/Nd3iEWW7F5e/ZxJxtNS9FDYgfQUFDsVtg1KuxERETOcs4z4KKvBpvLba0zm+aA4kfN7JuBdwLfyeagxJeAnwZ+yN3PzH+Jh1RsxQ6PNRlRNc7AmqVeJ9bZsxUbz93LS7ViRUREhp79TfDGP+p7FdMdUOzuXwb+qZm9EbgwPvwFd1/+XasHXZyKtTEHFHetWO/hrLjayrHFZsfrbipWN0+IiIikZqZIKBZyp+e8ltWS5ThGPqaI2ojDE54tPxVryDfP0BujS+wKJXYiIiLJmebmiTea2X/d5fkPm9lZ13zJDsxosgGF17Tt1sBzo8fErrWCzCc4x67UHjsREZHUTLPD7+8Bf7bL8/cA/2Bfq1kxjRWU1Gw0Wy/0qOqWAfVSrxMbrinbq7ALz6kVKyIikp5pCrvLgTt2ef7O+BqZUJuVDKhYr7cVdo1T0M/wREuxayuWZoPGjSJf3o0YIiIiMplpCrsSOLLL80f2eF62abNBSOzOKuzClWK9JHZWkO+S2NHUVBQUuS1vUSIiIjKRaQq7e4CX7fL83wA+vb/lrBbPSko7uxW70cRWbA+3O7RZuXsrtt2goqDM+z2nR0RERM42zW/n9wF/w8x+xMyGFYeZlWb2bwmF3S/Pe4GHmecD1qipxiV21L3cx9rukdhZU1GTU2RK7ERERFIzzSaunwReDrwN+Cdm9qfx8SuAZwC/D/xf813e4eb5YPzwRFfY9ZLYFeTsPjxRkzNQYiciIpKciX87u3tFSOXeAtwHPD++fR74V8C3AYpxpuBxeOKsPXZ1GJ7oI7HzrCD3Zsfnra2oyCm1x05ERCQ5U8Uu7l65+4+7+7Xufm58ez7wMeDfA/cvZJWHVUzstk/FrjctA6t7uY/VraDY5eYJa2sqLygyJXYiIiKpmfk8DTN7BvB3CGfXXU1I6+6Z07pWQz6gtCfGJHahFZv1sccuG5Czc2JHqz12IiIiqZo6djGzv2lmvwKcIuy7WwP+LXC1u18x5/UdbsWANaqd99j1cG2XZ+HQZHa4/tfaipqCTIWdiIhIciZK7MzsMkIy973AJcAXgBuB7wLe5u6/vqD1HWqW73KOHQ1ZD7c7eHcocttAfvaPh7UVlelwYhERkRTtmtiZ2Xeb2UeAe4EfBG4BXgM8C/hhNCyxP8Xa2MJuo3EG1GQ9TMWSxX197fh9dtbWNLN38EVERGSB9voN/f8CnwH+OfA+d/9i94SZarr9snzAgJqNZuuetqppKaixvIfhiS6xazagPHrW81lbU5sKOxERkRTttcduHbgMeBVwvZmd/ZteZpYVg3DzxLbErq4qcvNerhTz7u9sxp9lZ17TqLATERFJ0l6F3TMJad0FhPTuQTP7WTP7n1Abdt+yci0mdlsHFdp6I3zQQ2I33Fe3Qys2byu1YkVERBK1a2Hn7o+4+//j7l8HXAf8ImGP3ceA/w448LSFr/KQyoq1sQcUN/V6+KCHxG64x67ZYY+d1zQanhAREUnSNDdP/H/u/kZCivc9wJ3xqZ8xs1vN7IfM7GsWscjDKivXKGnOKuzaKhZVfRR2+e7DE1lb06oVKyIikqSpz7Fz93V3/2V3/zbgK4F3AOcDNwC3zXl9h1pejp+KbZv+WrE2HJ7YoRXrNY310CIWERGRPe3rXih3/3N3fzthwOIVgM6zm0IYnmjYqLcWUd7tscv62GMXzs7zrrjcJnMldiIiIqmay29od3fgd+KbTCq2Wptqfevjw8Ru+a1Yi8MTdV0xrqzMvaIdc3CxiIiI9E83ufcpFm7ttsKuz6lYGxab4xO73BsldiIiIolSYdenrrCrtyV2dY+JXRGKtqbeobCj3jzEWERERJKiwq5PxQ7pWJ+t2Livb+fETsMTIiIiqVJh16dYuPn2dKw7aqSHvWxWrMUl7NyK9T6GOkRERGRPKuz6tEMr1uv+zrHr7qdtdjjupKBSK1ZERCRRKuz6tENiZ21/rdis2KUV605Oi2t4QkREJEkq7PrUFW7N1sTOurSsh6nYPBZ27bhz7OK6vI87bEVERGRPKuz6FAuksxO7HluxRZcijmnFxnVpj52IiEiaVNj1KQ4qsOPwRB+t2DipO+64ky6x0x47ERGRJKmw61O3x67ZIbHroYDKy5gijhue6LFFLCIiIntTYdenWNgNhyWirMfELh9O6o5J7HosOEVERGRvKuz61BV22xK7PIFW7Ng9dkrsREREkqbCrk/DqdjNIqptncz7nIrt2sPjhifq8D5bfsEpIiIie1Nh16dYRA1br8BG0zKgCX/oI7EbjN/3ByixExERSZwKuz7Fwi0bKaKqpqUgJmM9FFBlvktiF9dpPVx1JiIiIntTYdenrrDzzSKqapzSaloyyPKlL6koMirPt7SHO03cd2c9JIkiIiKyNxV2fco3W7Ft60BI7AY0tD0dAlzmRk2ON/VZzzXdnbZK7ERERJKkwq5PsbAbULPRtABs1C0ldW+3OxRZRkUO7dl77IaJXaHETkREJEUq7PoU99ANbLOwq5pQ2PWV2BW5UVHAmONOmio8lqkVKyIikiQVdn0yo7GSkpqNuivsnKLnxK4m3zyMeETXitXwhIiISJpU2PWszUoGVCOFXcvAmv4Kuy6xa8/eY9fdRqHhCRERkTSpsOtZm21N7Na7PXY9nRVXZhm175DYda3YQufYiYiIpEiFXc88H1BSU23bY0ePiV1Njo2Zim3jOXaZhidERESSpMKuZ54NWLOa9XprYec9tTtDKzbHxkzFdvfHqrATERFJkwq7nnWJ3ehU7IC6l+vEILRiKwpslz12uVqxIiIiSVJh1zPPy3COXd2dY+cUNL1NnmZZbMWOLex03ImIiEjKVNj1rUvsRlux1l9iB9BYgY0ZnhjusSuV2ImIiKRIhV3fxhR2A+pejxRpKDA/O7HzeH9sXqwte0kiIiIyARV2fcsHrFl11s0TfV7b1VhOPiaxGw5PlGrFioiIpEiFXc+s2JrYbTTee2FXU47dY+exFVtoeEJERCRJKux6Zvna1sKubsPwRI+FXWs52Q6t2NZNhZ2IiEiiVNj1zIpBmIodPe7E6l4nTxsrdyzsKnKK3HpYlYiIiOxFhV3Psm2t2CpeKdbnIcA7JXY0FRUFZa4fGxERkRTpN3TPsnKNgdVJDU+0WUHuZw9P0FbU5BSZEjsREZEUqbDrWVasbT2guHEGNP0ed2Il+W6t2Ew/NiIiIinSb+iendWKjYkdeX8DCm1WkHlz1uPWVNQU2mMnIiKSKBV2fSvWGLD1HLvCei7srBif2LUVtWt4QkREJFUq7PqWl2GPXUzs6roix3u9Usyz8YWdNTUbFJRqxYqIiCRJv6H7lq9R0rBehdZnU23Ex/tL7NxKCsa0YrvhCSV2IiIiSVJh17dYwDXVOgBt3RV2fU7FlmS00G4r7tqamlzHnYiIiCRKv6H7Fgu4Nl7X5QkUdp4V4YNm65EnWdtNxSqxExERSZEKu74VawB4TOw2C7seW7FZ/LvbbWfZtWEqNldhJyIikiQVdn2LBZzXsRUbkzuyHu9j3TGxq6kpMFNhJyIikiIVdn3rWrFdUtek0IrtErutk7HmNY3lPaxIREREJqHCrm95bMXGws67lKzPVmz3d3dFZmRtRUPRw4pERERkEr0WdmZ2vZndbWb3mtlbxjz/bDP7iJndbmYfN7NLRp77cTO708zuMrN/b7E/aGZfb2Z3xK85fDxZXSu2Ca3YFBK7YRt4Wys2b2saU2EnIiKSqt4KOzPLgXcBLweuBN5gZldue9lPAO9192uAG4B3xs/9JuCbgWuAq4AXAC+Kn/PTwPcDl8e36xf7nexTLOC8jkVUAlOx5LF4G9uKVWEnIiKSqj4TuxcC97r7Z9x9A3g/8Kptr7kS+Gj8+GMjzztwBBgAa0AJPGRmzwTOc/c/cncH3gu8erHfxj4VsYCLid1mK7a/Asq6onL78IRXKuxEREQS1mdh9yzg8yN/vi8+Nuo24LXx49cAx83sAnf/Q0Kh90B8+5C73xU//749vmZahkVUSOqsO2Kk11Zsl9hta8V6Q6vCTkREJFmpD0+8GXiRmX2C0Go9BTRm9lzgq4FLCIXbS83sW6f5wmb2A2Z2i5ndcvr06Xmve3KxgLOusGsSKOyKHRK7tlZhJyIikrA+C7tTwKUjf74kPjbk7ve7+2vd/fnA2+JjjxDSuz9y98fc/THgg8Bfi59/yW5fc+Rrv9vdr3P36y666KJ5fU/TiwVcFtMxa/s/oNh2Gp7wijZTYSciIpKqPgu7m4HLzew5ZjYAXg98YPQFZnahmXVrfCvwnvjx5whJXmFmJSHNu8vdHwDOmNk3xmnYvwv85jK+mZkl2Iq1WFQOz9aLcpTYiYiIpKy3ws7da+BNwIeAu4Bfdfc7zewGM/v2+LIXA3eb2T3ACeAd8fEbgU8DdxD24d3m7r8Vn/unwM8A98bXfHAJ387shq3YLrFLoLArQmFXby/svKHt80YMERER2VWv8Yu73wTctO2xt498fCOhiNv+eQ3wj3b4mrcQjkA5GOJ+ttw3cHeytg7ldo8tz83EbnsrtqY1FXYiIiKpSn144vCLyVxJzXrdknsKiV34u5tqJLFzp6DGtcdOREQkWSrs+havFCupeWy9piQeCtxjYZfFVmwz2oqNhxWrsBMREUmXCru+xbbngJrHnhot7PpreWaxqNwyPBH3AKqwExERSZcKu77FImowTOyaLY/3Icu7xG5kj13bFXbaYyciIpIqFXZ9G9lj9/h6IoldbMX66Dl2TdeKVWEnIiKSKhV2fcsyWisYWMXjGzWl1TgZZHlvS7Iy7Pvzen3zwVatWBERkdSpsEtAm5WUNDy+3jCg/7Pi8nGt2Kb/GzFERERkdyrsEuD5gAHVsBXbe2EXjzvZ2oqNH6sVKyIikiwVdgnwrBwZnqjxnlOxrIwHFI8Wdt1xJz0OdYiIiMjuVNglwPNBHJ5o4iHA/RZPRdHtsTs7sbNce+xERERSpcIuBfmAgdU8vlEzsKb3AYU8z6k9g+bs4Qm1YkVERNKlwi4BXWL3aHdAcc+t2DI3anI8HnECjCR2KuxERERSpcIuAZaXW8+x63kfW5FnVBTjhydU2ImIiCRLhV0K8jXWRqZiey/sspDYMVLY+TCx0/CEiIhIqlTYJcCKASXN5pVivbdis9iK3Szsuntj1YoVERFJlwq7BFixRmk1T2w0IbHreUChyI2KHGs3ho91hxVbocJOREQkVTq7IgFWjBxQbDVW9NvuLLOMyovh/bAATRUmZHMldiIiIslSYpeArAhTsY+t1wyoe9/HVsSpWGs3W7HDxE6FnYiISLJU2CXAijUGI1OxfSd2RWZUFMPbJgDa7q7Ycq2nVYmIiMheVNglwIYHFIc9dlnfhV0cnrBmNLELhZ1asSIiIulSYZeCPNwVC1DQYEW/qVjXih1N7LrrxfouOkVERGRnKuxSUKyxZqGIGlhN1vdxJ1nGBgXZyFRsd9xJrqlYERGRZKmwS0G8UgxgkMA5dkVu1J5jW/bYKbETERFJnQq7FOQlRSzsUrp5wra0YkNil5Uq7ERERFKlwi4F8UoxcErrv7AzM2orMB+9eSJ8XKgVKyIikiwVdimIhVxBQ5FAKxagsYJsNLGLZ9ppKlZERCRdKuxSEIulkjq2YvsvnhoKspEDir3eYMNzilw/MiIiIqnSb+kUxONNjrJBTtt7KxZiYucjiV1TUVOosBMREUmYfkunICZ059hTW/7cp+2FHU1FRU6RW3+LEhERkV2psEtBHhK7c+kKu/4Tu/asxK6moqDM9CMjIiKSKv2WTkEs5JIq7LKczJuRBypqJXYiIiJJU2GXgmErdn3Ln/vUWkk+ctwJTSjsShV2IiIiyVJhl4Kia8U+Gf6cpVDYFeRb9thtUHlOoVasiIhIsvRbOgVJtmLLrYVdG/bY5ZkSOxERkVSpsEtBgq1YtyIcveIeHojHnZQ67kRERCRZ+i2dghSnYrMifNCEfXbW1jruREREJHEq7FIQC7nNc+xSKOxiathsAGBxKlbHnYiIiKRLv6VTEFuvm4ld0eNioi6xa7vETsediIiIpE6FXQqK9FqxPkzswgCFtTUbXqiwExERSZgKuxR0iV1CrdidEju1YkVERNKl39Ip6PbYkc5dsZuJXSjsMq+pKch03ImIiEiyVNilYDgV2x130n9i5/nWws7amsbyHlckIiIie1Fhl4LhOXYptWJjYRdbsVlb0VgCQx0iIiKyIxV2Kdh+80SWQAGVn92KVWEnIiKSNhV2KeimYhNK7CzfOjyReU1r/e/9ExERkZ2psEtBluOWJXXcCVlcQzzuJCR22mMnIiKSMhV2iWizQVJTsRRbb57IWyV2IiIiqVNhlwjPSwprwx8SSOws3zo8kXtFq8ROREQkaSrsUpGNFHMpJHbbbp7IaGiyBNYlIiIiO1Jhl4i8DAMUbhlk/SdjWSwuvWvFeo1rKlZERCRpKuwSYUVI7CyBNixsrqetK2gbMhxP4RgWERER2ZEKu1R0BV0yhV1I7JqmGp5l16oVKyIikjQVdqmI14olsb8OyGKB2VTrw8lYJXYiIiJpU2GXiq6gSySxy2Ji19Yb0IYBCrc01iYiIiLjqbBLRVfQJdLu3LLHLrZiPVdiJyIikjIVdqkouj12aRR2ed4ldtXwLLtUik4REREZT4VdKlIbnhgt7LrETnvsREREkqbCLhV5Yoldd65esz4s7FArVkREJGkq7FKRWGKXlTGxazZbsZ6lsTYREREZT4VdKhJL7Iq8pHXDR1qxqaxNRERExlNhl4rEhifK3KjI8aYaHndiGp4QERFJmgq7VCTWii3yjJo83BWrPXYiIiIHggq7VCRW2JWZUVHEVmy4eSKVe2xFRERkPBV2qUhsj12ejbZiuwOK01ibiIiIjKfCLhWJJXahFVuEoq6Je+xU2ImIiCRNhV0qErtSrMyN2vOwvy4mdpkKOxERkaSpsEtFYlOxRZZRkUNbhXYsYEUaaxMREZHxVNilIrFWbDjupICmoqnWAcgSWZuIiIiMp8IuFYkVdt1xJ7QVTR2nYpXYiYiIJE2FXSoSm4ot4lQsTU1Txz12RRpFp4iIiIynwi4ViRV2ZZyKtbaijYldpsROREQkaSrsUtEVdIm0YvPMYiu23hyeSKToFBERkfFU2KWiWAvvEymeytzY8IJsJLHLEyk6RUREZDwVdqlIdHgitGLjHrsyjbWJiIjIeCrsUpFaYRdbsdbW4b5YINfwhIiISNJU2KUiweGJKhZ2bbNB5Tllrh8XERGRlPX6m9rMrjezu83sXjN7y5jnn21mHzGz283s42Z2SXz8JWZ268jbU2b26vjcz5vZZ0eeu3bZ39dMErtSLAxPFGQehidqcgoVdiIiIkkr+vqLzSwH3gW8DLgPuNnMPuDunxp52U8A73X3XzCzlwLvBL7H3T8GXBu/zjOAe4EPj3zev3T3G5fxfcxNkVYrFqCxMDzh9QYVOUVufS9JREREdtFnBPNC4F53/4y7bwDvB1617TVXAh+NH39szPMArwM+6O5PLGyly3DsZCjqnn5p3ysZaiwmdm1FRUGZKbETERFJWZ+/qZ8FfH7kz/fFx0bdBrw2fvwa4LiZXbDtNa8H3rftsXfE9u1PmtnavBa8UMdPwFs+D3/1G/teydCwsKtDKzbPlNiJiIikLPUI5s3Ai8zsE8CLgFNA0z1pZs8ErgY+NPI5bwWuAF4APAP4wXFf2Mx+wMxuMbNbTp8+vaDlT6k80vcKtmitIGtraOuQ2KkVKyIikrQ+C7tTwGjf8ZL42JC73+/ur3X35wNvi489MvKS/xn4z+5ejXzOAx6sAz9HaPmexd3f7e7Xuft1F1100Xy+o0OmtYLca2gqatfwhIiISOr6/E19M3C5mT3HzAaEluoHRl9gZheaWbfGtwLv2fY13sC2NmxM8TAzA14NfHIBa18JrZXkXoXCjpxCrVgREZGk9VbYuXsNvInQRr0L+FV3v9PMbjCzb48vezFwt5ndA5wA3tF9vpldRkj8/tu2L/1LZnYHcAdwIfCjC/w2DrU2K8hpoBueUGInIiKStN6OOwFw95uAm7Y99vaRj28Exh5b4u5/ztnDFrj7S+e7ytXVWvjxsPopKnLO1R47ERGRpCmCkR15Fgq7rH6SmlzHnYiIiCROv6llR11ilzdPUlGQK7ETERFJmgo72VEbb8HI6yepPafU8ISIiEjSVNjJzrYldjruREREJG36TS078jwUdkXzlO6KFREROQBU2MnOshKAvHlKwxMiIiIHgH5Ty466qdiyDYWdEjsREZG0qbCTHXkcngDCHjsNT4iIiCRNhZ3syLLN86sbCsItbSIiIpIqFXayI8/L4ceN9XpJiYiIiExAhZ3syDIVdiIiIgeJCjvZWb5ZzLWW97gQERERmYQKO9nZyPBEa+UuLxQREZEUqLCTHdnIHrs2UytW/v/27jy+qupc+PjvyTmZwCQkYQpgEq0oBBUoKFS4EEEQtSJQrghqkwqF1vrRqDhw31qZrkN5tcVL64gKrYKiBURfLqANaCkYBkEmRZQwo4QYmSSTz/vH3oknyclwMnBCeL6fz/7kZK2191575XDOw1prr22MMaaxs29rUynx7bGzwM6YBpefn09ubi7Hjx+nuLg42NUxxpwBHo+HqKgo4uLiCA8Pr/Px7NvaVEq8vnPsbCjWmIaUn5/P3r17iY2NJTk5mdDQUFtiyJgmTlUpLCzk2LFj7N27l8TExDoHdzYUayrle1fsD3ZXrDENKjc3l9jYWFq2bElYWJgFdcacA0SEsLAwWrZsSWxsLLm5uXU+pgV2plK+Q7FqQ7HGNKjjx48THR0d7GoYY4IkOjqa48eP1/k4FtiZSoV4fQM7G4o1piEVFxcTGmr/zow5V4WGhtbL3FoL7EylQrw/fslYj50xDc+GX405d9XXv38L7EylpExgZz0JxhhjTGNngZ2plMdnKNb3KRTGGGOMaZwssDOVCrEeO2OMOSskJyeTnJwc7GqYRsACO1Mpr89dsVhgZ4wxxjR6FtiZSnk8IRSoB7AeO2OMMeZsYIGdqZTXIxSVPJzEY4GdMcYY09hZYGcqFeoJoQinx05suRNjzBmQnZ2NiJCens6XX37JyJEjiY+PJyoqisGDB7N161YAjhw5wvjx40lISCAiIoIrrriCzMzMMsc6ePAgU6dOpU+fPrRt25awsDDatWvHmDFj2L59e4VzDxs2DBHhmWeeqZD3yCOPICKMHTs2oOtZu3YtIsLw4cMrLdO5c2fCw8NLnzpQUFDArFmzuP7660lKSiI8PJy4uDiuueYali5dGtD5a6K259u/fz933303HTt2JDIykri4OK688kqmTZtWp7KmbkRVg12HoOvZs6euX78+2NVodJZvO0yPN3sSL8eZdcFfuCvttmBXyZgma8eOHXTu3DnY1Qi67OxsLrjgAvr378/WrVvp3LkzV155JdnZ2SxcuJC4uDjWrFnDkCFDiI6Opn///uTm5jJ//nxCQkLYuXMniYmJAMyfP5877riDq6++muTkZM477zy++OIL3n33XcLCwli9ejVdu3YtPXdubi7du3fn66+/Zs2aNXTv3h2ADz74gMGDB9OpUyfWrVtHs2bNArqmTp06sXv3bg4ePEh8fHyZvKysLHr16sUvfvEL3nrrLQAOHz5M+/btueqqq7jkkkto1aoVhw4dYsmSJeTm5vLiiy8ybty4MscpuXEiOzs7oLrV9nzr16/n2muvJTc3l379+tG7d29OnTrF9u3bWblyZZmFdgMpe66r6eeAiGxQ1Z5+M1X1nN969OihpqJ/7vhaD/0hSfXRaJ31t/nBro4xTdr27duDXYVGYffu3QoooNOnTy+TN3XqVAU0NjZWJ0yYoMXFxaV5c+fOVUAzMjJK077++ms9duxYhXNs2rRJmzdvrkOGDKmQt3r1avV6vdqxY0c9fvy4Hj58WNu2bauRkZG6devWWl3TY489poD+z//8T4W8O++8UwF95513StNOnz6t+/btq1A2Ly9Pu3TporGxsXrq1KkyeUlJSZqUlFSr+gV6vvz8fE1OTlZAX3vttQr7+R4rkLKm5p8DwHqtJKaxHjusx64yH31xhAv+3psOksNfLn6F340ZEewqGdNkVfU/9SlLtrH94LEzXKPApLSL5tEbu9T5OCU9dsnJyezatQuPx1Oat3fvXpKSkmjWrBmHDx8mKiqqNK+4uJiIiAj69u1bYUjWn6FDh7J8+XKOHz9e4VFuTzzxBJMmTWLMmDEcOXKEFStW+O21qqn9+/eTlJTET3/6U9atW1eaXlBQQEJCbk9JuAAAIABJREFUAl6vlwMHDuD1Vj/l5emnn+b+++9n1apV9OvXrzS9Lj12gZ7v7bffZuTIkQwdOpTFixdXuX8gZU399NjZxClTKW9ICIXqASn7FApjjGlo3bp1KxPUAbRr1w6Aiy++uExQB+DxeGjTpg379+8vk/7ee+/x3HPPsX79enJycigqKiqTn5OTQ0JCQpm0hx56iMzMTF5//XUARo8eXeugDqBDhw4MHDiQFStWsH37dlJSUgBKhzrvvffeCkHdtm3bmDFjBh9++CGHDh3i9OnTZfIPHDhQ6/r4E8j51q5dC8B1111X7XEDKWvqhwV2plK+d8WK3RVrTNDUR0/Y2SYmJqZCWknw4y+vJL+wsLD095kzZ5KRkUFsbCyDBg0iMTGRZs2aISIsWrSIzZs3k5+fX+E4IsKIESNYvnw5ABkZGXW+nvT0dFasWMGcOXN48sknAZgzZw4AaWlpZcquXbuWAQMGUFRUxMCBAxk6dCjR0dGEhISwadMmFi9e7LfetRXo+fLy8gBo3759tccOpKypHxbYmUp5Q+THu2J9Fys2xphGrqioiMmTJ9O2bVs2btxYoVduzZo1le77xRdfMHHiRGJjY/nuu+8YN24cWVlZRERE1Lo+w4cPJzo6mr///e889thjHD16lKVLl9K1a9cyN3AATJ8+ne+//57MzExSU1PL5D3++OP1PqQZ6PlatGgB1KzXMJCypn7YciemUqGeEArc2D/EeuyMMWeRnJwc8vLyuOqqqyoEdSdOnGDjxo1+98vPz2fUqFGcPHmSN954g0mTJrFly5Y699pFRkZy8803c/DgQd5//31ef/11ioqKKvTWAezatYu4uLgKQRbAqlWr6lQPfwI9X+/evQFqtPRKIGVN/bDAzlTKGYp1e+y81mNnjDl7tG7dmmbNmrFhwwZOnDhRml5YWMg999xDTk6O3/0mTpzIJ598woMPPsigQYOYMmUKffr04fnnn2fBggV1qlN6ejoAc+fOZe7cuXi9Xm699dYK5ZKTk8nNzeXTTz8tkz579myWLVtWpzr4E+j5brzxRpKTk3nnnXeYN29ehXzfeY6BlDX1w4ZiTaW8IT8uUBxiN08YY84iISEh3H333TzxxBNcdtll3HTTTRQUFJCZmUlubi5XX311hbtnFy5cyKxZs+jVqxfTp08HnJsy5s2bR7du3Rg3bhw9evTgwgsvrFWd+vTpw0UXXcSCBQsoLCzkxhtvpHXr1hXKZWRksGzZMvr27cvNN99MTEwM69ev51//+hcjR44sXe+uvgR6vrCwMBYsWMDgwYMZM2YMzz//PL179+b06dPs2LGDDz74oPQmlUDKmvphPXamUqEece6KBUJsjp0x5iwzbdo0nnrqKSIjI3n++ef5xz/+Qc+ePcnKyipdxLjE3r17GTt2LDExMcyfP7/MXarnn38+L7/8MseOHeOWW26hoKCg1nVKS0srvcHD3zAswJAhQ1iyZAkpKSm88cYbzJ49m/DwcDIzM7nhhhtqfe7K1OZ8PXv2ZNOmTfz2t79lz549PP300/ztb38jLy+PqVOn1rqsqTtbxw5bx64yB/K+54unriXVs5k5A7NI+49Lgl0lY5ose/KEMaY+1rGzHjtTqdAQobDk5gmbY2eMMcY0ehbYmUp5QoRCPBRpCN5yC4UaY4wxpvGxmydMpbwe5+aJIjx4QyTY1THGmEYhOzubV199tUZlMzIyStdyO1M2bdrEokWLalR28uTJDVsZc8ZZYGcqFepxeuwK8RLqsc5dY4wBJ7CbMmVKjcqmp6cHJbCraf0ssGt67NvaVMobEkKRep0eO4/12BljDEBqaiqqWqMtOTn5jNcvPT29xvUzTY8FdqZSoR7hgLbkgLbEG2JvFWOMMaaxs29rUykR4VkdzoiCKYRaj50xxhjT6NkcO1OlkBAP+T8IXptjZ4wxxjR69m1tqlRyN6zdFWuMMcY0fhbYmSqV9NRZYGeMMcY0fhbYmSqVzK2zoVhjjDGm8bNva1Olkrth7eYJY4wxpvGzwM5UqWT9OlvuxBhjjGn87NvaVKnkiRPWY2eMMcY0fhbYmSqV3hVrc+yMMabJmDx5MiLCypUrg10VU8/s29pUye6KNcYYU5+Sk5OD8qi1c4UFdqZKP/bYWWBnjDHGNHYW2Jkq2c0TxhhjzNnDvq1NlUJtuRNjzBmUnZ2NiJCens6XX37JyJEjiY+PJyoqisGDB7N161YAjhw5wvjx40lISCAiIoIrrriCzMzMMsc6ePAgU6dOpU+fPrRt25awsDDatWvHmDFj2L59e4VzDxs2DBHhmWeeqZD3yCOPICKMHTu21tf28ccfM3LkyNK6nH/++UyYMIGDBw+WKdepUyfCwsLIycnxe5wnn3wSEWHWrFmlaZmZmYwfP56UlBSio6OJjIzk0ksvZcqUKZw+fbpG9fNte39SU1MRKftdUFBQwKxZs7j++utJSkoiPDycuLg4rrnmGpYuXVqm7MqVKxER9uzZw549exCR0q38OT/77DPS09M5//zzCQsLo02bNowZM4bPP/+8RtfiT6DvhxJZWVmMGjWK9u3bEx4eTkJCAoMHD+bNN9+sU9kGo6rn/NajRw81/o1+YY0mPfSuHj9dGOyqGNOkbd++PdhVaBR2796tgPbv31/j4+O1b9++et999+mIESNURDQ+Pl537typF154oXbr1k3vuecevf322zU0NFTDw8N1z549pceaN2+eRkZG6vXXX6933nmnPvjggzp8+HANDQ3V5s2b66ZNm8qc++jRo5qYmKjh4eG6cePG0vT3339fQ0JCNCUlRU+ePFmr65o9e7Z6PB5t1qyZ3nLLLfrAAw/osGHDNCQkRBMSEsrU+7HHHlNAn3nmGb/H6ty5s4aFhenRo0dL06699lpNSkrS0aNH68SJE/Wuu+7S7t27K6CpqalaVFRU5hiPPvqoApqZmVmh7dPS0vyet3///uqEDT86dOiQhoSEaN++fXXs2LH68MMPa1pamsbFxSmgL774YpnjP/rooxoTE6MxMTH66KOPlm4LFy4sLbd06VKNjIxUr9erw4cP1wceeEBHjx6t4eHhGh0drRs2bKi2vf0J9P2gqvrCCy+ox+PRsLAwHTlypE6aNEnHjh2rXbt21f79+9e6bGVq+jkArNdKYpqgB1WNYbPArnK3z/5Ykx56V78vKKq+sDGm1iywc5QEF4BOnz69TN7UqVMV0NjYWJ0wYYIWFxeX5s2dO1cBzcjIKE37+uuv9dixYxXOsWnTJm3evLkOGTKkQt7q1avV6/Vqx44d9fjx43r48GFt27atRkZG6tatW2t1TZ9//rmGhobqT37yE92/f3+ZvJKgcdiwYaVp+/bt05CQEPX33ZSVlaWAjhgxokz6l19+qT/88EOF8r///e8V0Pnz55dJr6/A7vTp07pv374KZfPy8rRLly4aGxurp06dKpOXlJSkSUlJfs+Rm5urLVq00Pj4eN22bVuZvC1btmjz5s21e/fufvetTqDvh23btqnX69XY2Fi/f3vf6w6kbFXqI7Dznrm+QXM2CnVvngi15U6MCZ6lD8PhLcGuRdXaXgbXPVFvh0tOTubhhx8uk5aWlsYf/vAH8vPzmTFjBiE+c3/HjBnDHXfcwaZNm0rTWrdu7ffYXbt2ZcCAASxfvpzCwkJCQ0NL86666iqmTZvGpEmTmDBhAkeOHOHw4cO8+OKLdOnSpVbX8uyzz1JYWMjMmTNp3759mbyBAwcydOhQlixZwvHjx4mKiqJDhw4MHDiQFStWsG3btjLnnTNnTmlb+Lrwwgv9nvvee+9l+vTpLFu2jFGjRtWq/lUJDw+nQ4cOFdJjYmK44447uP/++1m3bh39+vWr0fHmzp1LXl4es2bNIiUlpUzepZdeyq9//Wv+/Oc/s3379gr51Qn0/fDss89SVFTEI4884vdv73vdgZRtaBbYmSp5PYIIeGy5E2PMGdStWzc8Hk+ZtHbt2gFw8cUXExUVVSbP4/HQpk0b9u/fXyb9vffe47nnnmP9+vXk5ORQVFRUJj8nJ4eEhIQyaQ899BCZmZm8/vrrAIwePZpx48bV+lrWrFkDwKpVq1i3bl2F/G+++Ybi4mJ27txJjx49AEhPT2fFihXMmTOHP/7xj4Azn23evHm0bt2a66+/vswxTp48ycyZM1m4cCE7d+7k+PHjzrCc68CBA7Wuf3W2bdvGjBkz+PDDDzl06FCFOX2BnLukrTZv3szkyZMr5O/cuROAHTt2BBzYQWDvh7Vr1wJw3XXXVXvcQMo2NAvsTJW8npDSGyiMMUFSjz1hZ4uYmJgKaV6vt9K8kvzCwsLS32fOnElGRgaxsbEMGjSIxMREmjVrhoiwaNEiNm/eTH5+foXjiAgjRoxg+fLlAGRkZNTpWo4ePQrAjBkzqix34sSJ0tfDhw8nOjqav//97zz++ON4PB7effddcnNzycjIKG0LgMLCQgYMGEBWVhaXXnopo0aNolWrVqU9T1OmTPF7nfVh7dq1DBgwgKKiotLex+joaEJCQti0aROLFy8O6NwlbfXiiy9WWc63rWoq0PdDXl4eQIVeVn8CKdvQLLAzVfKGiPXWGWPOOkVFRUyePJm2bduycePGCr1yJT1D/nzxxRdMnDiR2NhYvvvuO8aNG0dWVhYRERG1qktJIPrdd98RHR1do30iIyO5+eabeemll1ixYgVDhgypdBh28eLFZGVlkZ6eziuvvFIm79ChQ0yZMqVG5ywZ2i7fi1WiJHjxNX36dL7//nsyMzNJTU0tk/f444+zePHiGp27RElbbd68mcsvvzygfatSm/dDixYtAKfHsVOnTlUeP5CyDc26YkyVvCEhtjixMeask5OTQ15eHldddVWFL/ETJ06wceNGv/vl5+czatQoTp48yRtvvMGkSZPYsmVLnXrtevfuDcBHH30U0H4lS4DMmTOHI0eOsHTpUi6//HK6detWptyuXbsAGDFiRIVjrFq1qsbni42NBWDfvn0V8o4dO1Y6DFr+3HFxcRWCuqrO7fF4KC4u9ptX27aqTm3eDyV1Kb9siz+BlG1oFtiZKoV6xG6cMMacdVq3bk2zZs3YsGFDmWG7wsJC7rnnnkrXiJs4cSKffPIJDz74IIMGDWLKlCn06dOH559/ngULFtSqLnfddRehoaHce++9foOjgoICv4FMnz596NixI4sXL+a5556jsLDQ7xpzJY/nKv/c16+++oqHHnqoxvWMioqiU6dOrF69usy6bsXFxdx33318//33fs+dm5vLp59+WiZ99uzZLFu2zO954uPjOXLkiN/j/epXv6JFixZMmTKFrKysCvk//PBDrZ5vW5v3w29/+1u8Xi/Tpk3zu86d73zOQMo2NBuKNVVKvaQVzcPtbWKMObuEhIRw991388QTT3DZZZdx0003UVBQQGZmJrm5uVx99dUVFjReuHAhs2bNolevXkyfPh1wepfmzZtHt27dGDduHD169Kj0DtTKdOrUiZdffpk77riDLl26MGTIEC6++GIKCwvZu3cvH330Ea1ateKzzz6rsO8vf/lLHnnkEaZNm4bX6+XWW2+tUObGG2/koosu4umnn2bLli10796dvXv38u6773LDDTewd+/eGtf1gQceYOzYsfTp04f//M//JCIigszMTAoLC+natSubN28uUz4jI4Nly5bRt29fbr75ZmJiYli/fj3/+te/GDlyJG+99VaFcwwcOJB169YxZMgQ+vXrR3h4OF27duXGG28kPj6et956i+HDh9O7d28GDhxIly5dEBH27dvHmjVrOHr0aI0XXS5Rm/dDSkoKf/3rX/nNb35D9+7duemmm+jYsSNHjx5l3bp1REdHl+4TSNkGV9k6KOfSZuvYGWOCzdaxc1S3lhru4sX+lF8frbCwUJ966int3LmzRkREaJs2bfS2227T7OxsTUtLU0B3796tqqp79uzR2NhYjYmJKU3ztWjRIgX0iiuu0Pz8/Fpd26effqppaWmamJioYWFhGhsbq126dNHx48frBx984HefPXv2aEhIiAL685//vNJj7927V8eMGaPt2rXTiIgITUlJ0SeffFILCwv9tpm/dexKvPTSS5qSkqJhYWHapk0bHT9+vObk5Phdx05VdcmSJdqrVy8977zzNCYmRgcNGqSrVq3SV155RQF95ZVXypQ/ceKE/uY3v9H27durx+Px+/fevXu3/u53v9OLLrpIw8PDNSoqSi+55BK97bbbyixmHIhA3g++/v3vf+uIESO0VatWGhoaqgkJCXrttdfqggUL6lTWn/pYx07U53boc1XPnj11/fr1wa6GMeYctmPHDjp37hzsahhjgqimnwMiskFVe/rLs8lTxhhjjDFNhAV2xhhjjDFNhM2KN8YYYwKQnZ3Nq6++WqOyGRkZpWucmfq1aNGiMo+Qq0xycrLfu4mbKgvsjDHGmABkZ2fXeNHf9PR0C+wayKJFi0oXba5K//79LbAzxhhjjH+pqanYjYfB9+qrr9a45/RcYnPsjDHGGGOaCAvsjDHGGGOaCAvsjDHGGGOaiKAGdiIyREQ+F5FdIvKwn/wkEflARD4VkZUi0sFNv1pENvlsp0VkmJt3gYh87B7zDREJO9PXZYwxtWHztow5d9XXv/+gBXYi4gH+AlwHpACjRSSlXLH/C8xV1cuBqcDjAKqaqardVLUbMAA4BSx393kS+JOqXgR8C4xt8Isxxpg68ng8FBYWBrsaxpggKSwsxOPx1Pk4weyxuxLYpapfqWoBMB+4qVyZFOCf7utMP/kAI4GlqnpKRAQn0Ct56vAcYFi919wYY+pZVFQUx44dC3Y1jDFBcuzYMaKioup8nGAGdu2BfT6/73fTfG0GRrivhwNRIhJfrswtwDz3dTyQp6pFVRzTGGManbi4OL799ltycnIoKCiwYVljzgGqSkFBATk5OXz77bfExcXV+ZiNfR27icAsEUkHPgQOAMUlmSKSAFwGLAv0wCIyHhgPkJiYWB91NcaYWgsPDycxMZHc3Fyys7MpLi6ufidjzFnP4/EQFRVFYmIi4eHhdT5eMAO7A8D5Pr93cNNKqepB3B47ETkP+IWq5vkUuRlYqKolE1OOAi1ExOv22lU4ps+xXwBeAOjZs6f919gYE3Th4eEkJCSQkJAQ7KoYY85SwRyKXQd0dO9iDcMZUn3Ht4CItBSRkjpOAl4ud4zR/DgMizpjF5k48+4A0oDFDVB3Y4wxxphGJ2iBndujdhfOMOoO4E1V3SYiU0VkqFssFfhcRHYCbYD/LtlfRJJxevxWlTv0Q8B9IrILZ87d7Aa8DGOMMcaYRkNsgq4zFLt+/fpgV8MYY4wxploiskFVe/rLsydPGGOMMcY0ERbYGWOMMcY0ERbYGWOMMcY0ERbYGWOMMcY0ERbYGWOMMcY0EXZXLCAiR4A9DXyalkBOA5/DVGTtHhzW7sFh7R4c1u7BcS63e5KqtvKXYYHdGSIi6yu7Ndk0HGv34LB2Dw5r9+Cwdg8Oa3f/bCjWGGOMMaaJsMDOGGOMMaaJsMDuzHkh2BU4R1m7B4e1e3BYuweHtXtwWLv7YXPsjDHGGGOaCOuxM8YYY4xpIiywq0ci0kJE3hKRz0Rkh4j8TETiRGSFiHzh/ox1y4qIPCMiu0TkUxH5abDrf7YSkWwR2SIim0RkvZtm7d7ARMQjIp+IyLvu7xeIyMdu274hImFuerj7+y43PzmY9T5biUiEiGSJyGYR2SYiU9x0a/cGJCLni0imiGx32/0eN90+YxqYiLwsIt+IyFafNGv3alhgV79mAv+rqp2ArsAO4GHgA1XtCHzg/g5wHdDR3cYDz5756jYpV6tqN59b363dG949OO/xEk8Cf1LVi4BvgbFu+ljgWzf9T245E7h8YICqdgW6AUNEpDfW7g2tCLhfVVOA3sDvRCQF+4w5E14FhpRLs3avjqraVg8bEAPsxp236JP+OZDgvk4APndfPw+M9lfOtoDbPhtoae1+Rtu8A86H6gDgXUBwFgr1uvk/A5a5r5cBP3Nfe91yEox6N5UNaAZsBHpZu5/xtl8MDLLPmDPW3snAVn/tae3uf7Meu/pzAXAEeMUdnnpJRJoDbVT1kFvmMNDGfd0e2Oez/343zQROgeUiskFExrtp1u4N68/Ag8AP7u/xQJ6qFrm/+7ZraZu7+d+55U2A3OHvTcA3wArgS6zdzxh3OLs78DH2GRMs1u7VsMCu/niBnwLPqmp34CQ/dhEDoM5/I+w25PrXV1V/itMV/zsR6eebae1ev0Tk58A3qroh2HU516hqsap2w+kxvRLoFOQqnTNE5DzgbSBDVY/55tlnTHBYu/tngV392Q/sV9WP3d/fwgn0vhaRBAD35zdu/gHgfJ/9O7hpJkCqesD9+Q2wEOcLz9q94fQBhopINjAfZzh2JtBCRLxuGd92LW1zNz8GOHomK9zUqGoekIkz9Grt3sBEJBQnqHtNVf/hJttnTHBYu1fDArt6oqqHgX0icombNBDYDrwDpLlpaTjzM3DTf+neydMb+M6ne9nUkIg0F5GoktfAYGAr1u4NRlUnqWoHVU0GbgH+qaq34gQaI91i5du85G8x0i1v/8sOkIi0EpEW7utInHleO7B2b1AiIsBsYIeqPu2TZZ8xwWHtXg1boLgeiUg34CUgDPgK+BVO8PwmkAjsAW5W1Vz3w2IWzh0/p4Bfqer6oFT8LCYiF+L00oEzHP66qv63iMRj7d7gRCQVmKiqP3f/FvOBOOAT4DZVzReRCOBvOHOTcoFbVPWrYNX5bCUilwNzAA/u54qqTrV2b1gi0hf4CNjCj3NK/wtnnp19xjQgEZkHpAItga+BR4FFWLtXyQI7Y4wxxpgmwoZijTHGGGOaCAvsjDHGGGOaCAvsjDHGGGOaCAvsjDHGGGOaCAvsjDHGGGOaCAvsjDHGlCEiK90FqI0xZxkL7IwxDUZEmolIhoh8JCK5IlIoIl+LyP8TkXSfJyaYM8z9u6QHUD5dRDIasErGmHpg69gZYxqEiFwEvAdcDLwPLAdygNbANe42Q1UfDFolz2Fuj1y2qqb6yQvD+X7I90lbCSS7TxwxxjRS9r9lY0y9cx959S5wIfALn+drlnhSRK4ArjjjlTPVUtWCYNfBGFM7NhRrjGkI44BLgKf8BHUAqOo6Vf1rye8iMlhE3hCRr0TkexHJE5HlItK//L4i0kVEFojIARHJF5HDIpIpIjeUKxcuIv8lIttE5LR7zCUi0r1cuRB3aPJTETkuIsdE5HMRme0+AL5KIhIhIjNE5KBb9yz3el4VES1XNtvt/Sp/jFQRUd/hURGJEpHpIvKxiOS417pLRJ4QkWaV7S8iv3KvOV9E9ojIg+XKKpAE9Hf3KdmS3fwyc+zc1/2BpHLlU0VksYicEpFoP9d0hVvuD9W1oTGmfliPnTGmIZQ8lP6FAPZJx3ne6VxgP9AeJ0D8QESuVtWPANznAP/T3ec5nOdFtgR6Ar1whn9xA7L/Ba7CeWbqLCAG+DWwWkT6+TxL8v8AU4El7jGLgQuAoUA4UFhN3ecBw9z9lwE/Af4B7A7g+v0paYO3gdeBIpwA60GcZ8Be62ef3wBtcB5cnwfchtNDul9VX3fL3A78CWdo/L999j1SST0ygMdx2vlen/QdwIs47TQaeL7cfmNxnq/6cjXXaYypJzbHzhhT70TkKOBV1ZgA9mmuqifLpbUBtgFZqnq9mzYUWAyMUtU3qzjevcDTwBBVXeaTHg1sBb4qmV8mIhuBCFVNqWl9fY43GCeYm6Oq6T7pw4CFAKoqPunZ+JnbJiKpQCbOw8tfddPCnN21sFzZacDvgV6qmlVu/0NAZ1X9zk1vhhP87lLVn1VXDzdvJeXm01U2x05EPDgB7GFVvdInvZlbl9UlfztjTMOzoVhjTEOIBo4HsoNvUCci57k9c8XAxzg9cSW+c39e52/4z8dtwGfABhFpWbIBYcAKoK87F7DkmO1FpG8gdXYNc3/OKHc9i4DPa3E832MUlAR1IuIVkVj3Gt53i/Tys9srJUGde4xTwFqgY13qUkUdi3F65K4Qkct8skbivA9mN8R5jTH+WWBnjGkIx4CoQHYQkZ+IyHwR+RYnKMzBGRq8HogtKaeqq3CGa9OBHBFZLSJTRKR8b1tnoJN7jPLbHYAHZ2gR4L+A08BH7ry910RkjNtjVp0LcYYbd/rJ21GD/askIneKyKdAPpDr1n+lmx3rZ5ev/KQdBeLrWpcqzMYJwsf6pI0FvgHeacDzGmPKscDOGNMQtgLRInJhTQqLyHnAh8AQYCZOb8+1wCCc+XTiW15V04DLcObGHQXuBz4Vkbt8DwtscY9R2XbEPd4anHlxI3GGT7sBrwGbRCQusEuvVmXzXyrMeRaR+4C/4AxpTgBucOud7hbx9xleXPcqBkZV9+HMZ7xNRMJEpCPQD5hbfhjZGNOw7OYJY0xDeBvni30cTm9YdQYC7YA7VPUV3wwRme5vB1XdihNAzhCRFjhDtk+IyF/UmTz8BdAK+Keq/lBdBVT1hFvvt93z3okTVI2l3DBrOV/hBFgX48wH9NXZT/lcnJtEyvMXBN8OZAPX+V6DiAypoj41FegE6+rKv4ATeA7DubEDbBjWmDPOeuyMMQ3hJZz5ZRNF5CZ/BUSkhxs8wY+9TFKuzGDKzSMTkTgRKfPZpap5OBP4mwERbvJcoC1wXyXnb+PzuqWfIhvdn9X12C12fz5Q7vjDcJZ8KW8n0ElE2vuUDQd+56dsMU5A5XvzhRd4uJo61cQJqr+28uVjRUQqyX8POIjTs5iGc9PEZ3WrojEmUNZjZ4ypd6p6SkR+jvNlv0hEluPcsHAUpxftapyh1j+6u/wLOAw85a6lth9nOPR2nOFU30n5vwTuFZGFwC6cpUj6u8d7U1W/d8vNxBm2nCEiA3CGdI8BiTg9hKfdegCFeW9pAAAB5ElEQVTsEJG1OL1+B4EEYDxQAMyv5lqXicgSIM0dtv1fnGHdCTg9ipeW22UWcAvwvog8h3Mzx+3AKT+HfwtnmZGlIvIPnJsRxlD98is1sRYY695huwNnnuCS8ncmlyv/c2CWiPwbJ+j8p6p+A85NFCLyMs7dulCznlpjTH1TVdtss822BtlwetDuxQncvsUJSL7GCfhuBzw+ZS/HCYpKbp5YCfwH8KrzUVVarhswByeoO4kTrG3GmWcXXu78XuBuYJ1b9iTOEO1rwGCfcg/jzPH7BucmhX3AAuCnNbzOSOApnOD0eyALGFy+7j7l03B6NAtwehofBAbg9M6l+5TzAJPca83HWbbkjzhDvApM9imbWn5/n7wK9cB5tNvbOEPDP7j7Jrt5K3GWQin/t5zt/v1KehJTy5VJcvOOAc2D/f6zzbZzcbN17IwxpoGIyKtAmvqsY9eUiUgCTlA8W1UnBLs+xpyLbI6dMcaY+vJbnF7GQJ44YoypRzbHzhhjTJ2IyC04cxcfAJap6oYgV8mYc5YFdsYYY+pqHu4Cz5RdpNgYc4bZHDtjjDHGmCbC5tgZY4wxxjQRFtgZY4wxxjQRFtgZY4wxxjQRFtgZY4wxxjQRFtgZY4wxxjQRFtgZY4wxxjQR/x/kwNQSzfDKrAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "OPTIMIZATION SUMMARY:\n",
            "-> The target accuracy configurated was: 95.00 %\n",
            "-> The minimum number of cases computed above target accuracy was: 60 cases\n",
            "-> (It represents 10.00 % from total dataset)\n",
            "\n",
            "BEST MODEL SUMMARY:\n",
            "-> BEST MODEL: Best validation accuracy found was: 100.0000 %\n",
            "-> BEST MODEL: Test accuracy found was: 98.4375 %\n",
            "-> BEST MODEL: It is a difference of 1.5625 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQfhsuf3tCCK"
      },
      "source": [
        "#5.Independent test with the number of found cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3Fx90pJnWEU"
      },
      "source": [
        "**This section is dedicated to the execution and analysis (duplicate test) of the solution (number of cases) found by the optimizer.**\n",
        "\n",
        "* Observe that the experiment is based on a stochastic process, which hinders \"perfect\" reproducibility;\n",
        "* Depending on the adjusted Reduction Step, the optimizer may offer a better \"local\" rather than better \"global\" solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZDDuV9KiTa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49bf003-178a-4f65-9939-3403d6262af1"
      },
      "source": [
        "'''\n",
        "Subset - lembrar de usar a mesma função de subset usada na otimização (\"subset\" ou \"subsetB\"):\n",
        "\"subset(Xt, Y, cases)\" deve ser usado se o pré-processamento foi feito antes do subset;\n",
        "\"subsetB(cases)\" faz o pré-processamento depois do subset.\n",
        "'''\n",
        "\n",
        "X_train, Y_train, X_val, Y_val, X_test, Y_test, n_cases = subsetB(600)\n",
        "\n",
        "# Quando for rodar uma segunda vez, habilite o código abaixo:\n",
        "#del modelx\n",
        "#del modely\n",
        "K.clear_session()\n",
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "# Carregando o modelo padrão:\n",
        "modelx = load_model(save_path)\n",
        "\n",
        "# Treino e validação:\n",
        "modely, history, acc_max, train_time = fit_model(model, X_train, Y_train, X_val, Y_val, batch_size, epochs)\n",
        "\n",
        "# Teste:\n",
        "test_accuracy = test_model(X_test, Y_test, modely)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "192/192 [==============================] - 3s 9ms/step - loss: 1.7595 - accuracy: 0.3992 - val_loss: 3.6366 - val_accuracy: 0.1165\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11654, saving model to /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current/assets\n",
            "Epoch 2/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.9558 - accuracy: 0.5679 - val_loss: 5.8298 - val_accuracy: 0.1211\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.11654 to 0.12109, saving model to /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current/assets\n",
            "Epoch 3/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.6683 - accuracy: 0.7070 - val_loss: 4.6065 - val_accuracy: 0.2298\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.12109 to 0.22982, saving model to /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current/assets\n",
            "Epoch 4/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.4020 - accuracy: 0.8247 - val_loss: 4.7640 - val_accuracy: 0.2754\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.22982 to 0.27539, saving model to /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current/assets\n",
            "Epoch 5/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.2540 - accuracy: 0.8893 - val_loss: 7.4473 - val_accuracy: 0.2936\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.27539 to 0.29362, saving model to /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current/assets\n",
            "Epoch 6/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.1623 - accuracy: 0.9226 - val_loss: 8.1930 - val_accuracy: 0.1882\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.29362\n",
            "Epoch 7/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.1103 - accuracy: 0.9450 - val_loss: 8.9853 - val_accuracy: 0.2148\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.29362\n",
            "Epoch 8/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.1143 - accuracy: 0.9427 - val_loss: 9.4517 - val_accuracy: 0.2161\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.29362\n",
            "Epoch 9/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.1036 - accuracy: 0.9426 - val_loss: 8.0644 - val_accuracy: 0.2598\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.29362\n",
            "Epoch 10/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0853 - accuracy: 0.9563 - val_loss: 12.3503 - val_accuracy: 0.2051\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.29362\n",
            "Epoch 11/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0676 - accuracy: 0.9742 - val_loss: 0.6138 - val_accuracy: 0.8105\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.29362 to 0.81055, saving model to /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current/assets\n",
            "Epoch 12/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0463 - accuracy: 0.9865 - val_loss: 9.9019 - val_accuracy: 0.2188\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.81055\n",
            "Epoch 13/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0145 - accuracy: 0.9971 - val_loss: 7.3739 - val_accuracy: 0.3034\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.81055\n",
            "Epoch 14/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0262 - accuracy: 0.9924 - val_loss: 3.5442 - val_accuracy: 0.3594\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.81055\n",
            "Epoch 15/500\n",
            "192/192 [==============================] - 2s 8ms/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 13.0027 - val_accuracy: 0.1758\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.81055\n",
            "Epoch 16/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0390 - accuracy: 0.9895 - val_loss: 0.1630 - val_accuracy: 0.9368\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.81055 to 0.93685, saving model to /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current/assets\n",
            "Epoch 17/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.1121 - val_accuracy: 0.9264\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.93685\n",
            "Epoch 18/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 7.1980 - val_accuracy: 0.3548\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.93685\n",
            "Epoch 19/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 92.8178 - val_accuracy: 0.0605\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.93685\n",
            "Epoch 20/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0955 - accuracy: 0.9708 - val_loss: 5.0618 - val_accuracy: 0.3151\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.93685\n",
            "Epoch 21/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0195 - accuracy: 0.9964 - val_loss: 0.2017 - val_accuracy: 0.9238\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.93685\n",
            "Epoch 22/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.9823 - val_accuracy: 0.6595\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.93685\n",
            "Epoch 23/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 9.4261 - val_accuracy: 0.2741\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.93685\n",
            "Epoch 24/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9928\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.93685 to 0.99284, saving model to /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current/assets\n",
            "Epoch 25/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 1.9125 - val_accuracy: 0.5091\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.99284\n",
            "Epoch 26/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 1.6288 - val_accuracy: 0.5306\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.99284\n",
            "Epoch 27/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0188 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00027: val_accuracy improved from 0.99284 to 0.99740, saving model to /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current/assets\n",
            "Epoch 28/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.1038 - val_accuracy: 0.9466\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.99740\n",
            "Epoch 29/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.99740\n",
            "Epoch 30/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.1235 - val_accuracy: 0.9518\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.99740\n",
            "Epoch 31/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.8496\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.99740\n",
            "Epoch 32/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0297 - val_accuracy: 0.9941\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.99740\n",
            "Epoch 33/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.4983e-04 - accuracy: 1.0000 - val_loss: 0.6081 - val_accuracy: 0.8053\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.99740\n",
            "Epoch 34/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.9815e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00034: val_accuracy improved from 0.99740 to 0.99870, saving model to /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current/assets\n",
            "Epoch 35/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.8077e-04 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.99870\n",
            "Epoch 36/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.5152e-04 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9232\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.99870\n",
            "Epoch 37/500\n",
            "192/192 [==============================] - 2s 8ms/step - loss: 6.7254e-04 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.8561\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.99870\n",
            "Epoch 38/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.3226e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.99870 to 0.99935, saving model to /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current/assets\n",
            "Epoch 39/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.9824e-04 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.99935\n",
            "Epoch 40/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.3320e-04 - accuracy: 1.0000 - val_loss: 2.0238 - val_accuracy: 0.4688\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.99935\n",
            "Epoch 41/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.9052 - val_accuracy: 0.7194\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.99935\n",
            "Epoch 42/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0216 - accuracy: 0.9942 - val_loss: 5.2924 - val_accuracy: 0.3145\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.99935\n",
            "Epoch 43/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 4.5861 - val_accuracy: 0.3509\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.99935\n",
            "Epoch 44/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0503 - val_accuracy: 0.9844\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.99935\n",
            "Epoch 45/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0674 - val_accuracy: 0.9785\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.99935\n",
            "Epoch 46/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.99935\n",
            "Epoch 47/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.0259e-04 - accuracy: 0.9999 - val_loss: 0.5194 - val_accuracy: 0.8112\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.99935\n",
            "Epoch 48/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.4230 - val_accuracy: 0.8854\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.99935\n",
            "\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
            "Epoch 49/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.7656 - val_accuracy: 0.7995\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.99935\n",
            "Epoch 50/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9967\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.99935\n",
            "Epoch 51/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.8996 - val_accuracy: 0.8320\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.99935\n",
            "Epoch 52/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 11.6838 - val_accuracy: 0.2552\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.99935\n",
            "Epoch 53/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.99935\n",
            "Epoch 54/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.8706e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.99935 to 1.00000, saving model to /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CargasEletricas/Vinicius/Dataset/modeled_current/assets\n",
            "Epoch 55/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.1374e-04 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 1.00000\n",
            "Epoch 56/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.2428e-04 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 0.9935\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 1.00000\n",
            "Epoch 57/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.0736e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 1.00000\n",
            "Epoch 58/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 1.00000\n",
            "Epoch 59/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.2505e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 1.00000\n",
            "Epoch 60/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.9080e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 1.00000\n",
            "Epoch 61/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 4.5410e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 1.00000\n",
            "Epoch 62/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.6387e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 1.00000\n",
            "Epoch 63/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1783 - val_accuracy: 0.9290\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 1.00000\n",
            "Epoch 64/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.2182e-04 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9954\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
            "Epoch 65/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.4503e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 1.00000\n",
            "Epoch 66/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.4227e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 1.00000\n",
            "Epoch 67/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.7648e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 1.00000\n",
            "Epoch 68/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.5190e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 1.00000\n",
            "Epoch 69/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.7929e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 1.00000\n",
            "Epoch 70/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.1012e-04 - accuracy: 1.0000 - val_loss: 8.0616e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 1.00000\n",
            "Epoch 71/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.5618e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 1.00000\n",
            "Epoch 72/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.5137e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 1.00000\n",
            "Epoch 73/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.8304e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 1.00000\n",
            "Epoch 74/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.7173e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
            "Epoch 75/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.7499e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 1.00000\n",
            "Epoch 76/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.6606e-04 - accuracy: 0.9998 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 1.00000\n",
            "Epoch 77/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.6880e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 1.00000\n",
            "Epoch 78/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0311 - val_accuracy: 0.9902\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 1.00000\n",
            "Epoch 79/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.7958e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 1.00000\n",
            "Epoch 80/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.4817e-04 - accuracy: 1.0000 - val_loss: 9.8299e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 1.00000\n",
            "Epoch 81/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.3598e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 1.00000\n",
            "Epoch 82/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.0266e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 1.00000\n",
            "Epoch 83/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.3360e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 1.00000\n",
            "Epoch 84/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.4712e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
            "Epoch 85/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.9408e-04 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.8483\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 1.00000\n",
            "Epoch 86/500\n",
            "192/192 [==============================] - 2s 8ms/step - loss: 2.6555e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 1.00000\n",
            "Epoch 87/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.2557e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 1.00000\n",
            "Epoch 88/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.8492e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 1.00000\n",
            "Epoch 89/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.9906e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 1.00000\n",
            "Epoch 90/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.4971e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 1.00000\n",
            "Epoch 91/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.1644e-04 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 1.00000\n",
            "Epoch 92/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.4965e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 1.00000\n",
            "Epoch 93/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.3707e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 1.00000\n",
            "Epoch 94/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.1453e-04 - accuracy: 0.9997 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
            "Epoch 95/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.7715e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 1.00000\n",
            "Epoch 96/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.8523e-04 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 1.00000\n",
            "Epoch 97/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.2078e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 1.00000\n",
            "Epoch 98/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.6580e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 1.00000\n",
            "Epoch 99/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.3846e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 1.00000\n",
            "Epoch 100/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4980e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 1.00000\n",
            "Epoch 101/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5456e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 1.00000\n",
            "Epoch 102/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.3003e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 1.00000\n",
            "Epoch 103/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3670e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 1.00000\n",
            "Epoch 104/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.2338e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
            "Epoch 105/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.3777e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 1.00000\n",
            "Epoch 106/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.6460e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 1.00000\n",
            "Epoch 107/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.5823e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 1.00000\n",
            "Epoch 108/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.9943e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 1.00000\n",
            "Epoch 109/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.7367e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 1.00000\n",
            "Epoch 110/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2612e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 1.00000\n",
            "Epoch 111/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5196e-04 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 1.00000\n",
            "Epoch 112/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.9499e-04 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 1.00000\n",
            "Epoch 113/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 1.00000\n",
            "Epoch 114/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.6892e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
            "Epoch 115/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.9568e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 1.00000\n",
            "Epoch 116/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.1287e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 1.00000\n",
            "Epoch 117/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2774e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 1.00000\n",
            "Epoch 118/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.6262e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 1.00000\n",
            "Epoch 119/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.6100e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 1.00000\n",
            "Epoch 120/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3621e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 1.00000\n",
            "Epoch 121/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2355e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 1.00000\n",
            "Epoch 122/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2484e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 1.00000\n",
            "Epoch 123/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.6736e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 1.00000\n",
            "Epoch 124/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1545e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00124: ReduceLROnPlateau reducing learning rate to 0.0043046717997640375.\n",
            "Epoch 125/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5642e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 1.00000\n",
            "Epoch 126/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.8348e-04 - accuracy: 1.0000 - val_loss: 9.7760e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 1.00000\n",
            "Epoch 127/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2318e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 1.00000\n",
            "Epoch 128/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.8439e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 1.00000\n",
            "Epoch 129/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.7198e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 1.00000\n",
            "Epoch 130/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.1595e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 1.00000\n",
            "Epoch 131/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4999e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 1.00000\n",
            "Epoch 132/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.6991e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 1.00000\n",
            "Epoch 133/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4561e-04 - accuracy: 1.0000 - val_loss: 9.1501e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 1.00000\n",
            "Epoch 134/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3167e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.0038742044940590858.\n",
            "Epoch 135/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4425e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 1.00000\n",
            "Epoch 136/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3714e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 1.00000\n",
            "Epoch 137/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.6668e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 1.00000\n",
            "Epoch 138/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.4551e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 1.00000\n",
            "Epoch 139/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.9554e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 1.00000\n",
            "Epoch 140/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2998e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 1.00000\n",
            "Epoch 141/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1093e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 1.00000\n",
            "Epoch 142/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.9795e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 1.00000\n",
            "Epoch 143/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.1876e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 1.00000\n",
            "Epoch 144/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2515e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00144: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00144: ReduceLROnPlateau reducing learning rate to 0.003486784128472209.\n",
            "Epoch 145/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5792e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00145: val_accuracy did not improve from 1.00000\n",
            "Epoch 146/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4370e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00146: val_accuracy did not improve from 1.00000\n",
            "Epoch 147/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.7557e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00147: val_accuracy did not improve from 1.00000\n",
            "Epoch 148/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1876e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00148: val_accuracy did not improve from 1.00000\n",
            "Epoch 149/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.9339e-04 - accuracy: 0.9998 - val_loss: 7.2858e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00149: val_accuracy did not improve from 1.00000\n",
            "Epoch 150/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5845e-04 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9948\n",
            "\n",
            "Epoch 00150: val_accuracy did not improve from 1.00000\n",
            "Epoch 151/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0973e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00151: val_accuracy did not improve from 1.00000\n",
            "Epoch 152/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0094e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00152: val_accuracy did not improve from 1.00000\n",
            "Epoch 153/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0156e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00153: val_accuracy did not improve from 1.00000\n",
            "Epoch 154/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3631e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00154: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00154: ReduceLROnPlateau reducing learning rate to 0.003138105757534504.\n",
            "Epoch 155/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2835e-04 - accuracy: 1.0000 - val_loss: 9.9129e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00155: val_accuracy did not improve from 1.00000\n",
            "Epoch 156/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.7365e-04 - accuracy: 1.0000 - val_loss: 8.5766e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00156: val_accuracy did not improve from 1.00000\n",
            "Epoch 157/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2795e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00157: val_accuracy did not improve from 1.00000\n",
            "Epoch 158/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5474e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00158: val_accuracy did not improve from 1.00000\n",
            "Epoch 159/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4285e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00159: val_accuracy did not improve from 1.00000\n",
            "Epoch 160/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.3327e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00160: val_accuracy did not improve from 1.00000\n",
            "Epoch 161/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1463e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00161: val_accuracy did not improve from 1.00000\n",
            "Epoch 162/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1704e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00162: val_accuracy did not improve from 1.00000\n",
            "Epoch 163/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0002e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00163: val_accuracy did not improve from 1.00000\n",
            "Epoch 164/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5140e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00164: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00164: ReduceLROnPlateau reducing learning rate to 0.0028242952656000854.\n",
            "Epoch 165/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4873e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00165: val_accuracy did not improve from 1.00000\n",
            "Epoch 166/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4377e-04 - accuracy: 1.0000 - val_loss: 8.3511e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00166: val_accuracy did not improve from 1.00000\n",
            "Epoch 167/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.2837e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00167: val_accuracy did not improve from 1.00000\n",
            "Epoch 168/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1384e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00168: val_accuracy did not improve from 1.00000\n",
            "Epoch 169/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2079e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00169: val_accuracy did not improve from 1.00000\n",
            "Epoch 170/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.9472e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00170: val_accuracy did not improve from 1.00000\n",
            "Epoch 171/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3159e-04 - accuracy: 0.9999 - val_loss: 0.0178 - val_accuracy: 0.9961\n",
            "\n",
            "Epoch 00171: val_accuracy did not improve from 1.00000\n",
            "Epoch 172/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1060e-04 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9974\n",
            "\n",
            "Epoch 00172: val_accuracy did not improve from 1.00000\n",
            "Epoch 173/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.4271e-05 - accuracy: 1.0000 - val_loss: 6.2917e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00173: val_accuracy did not improve from 1.00000\n",
            "Epoch 174/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.0295e-05 - accuracy: 1.0000 - val_loss: 6.5749e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00174: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00174: ReduceLROnPlateau reducing learning rate to 0.0025418657809495927.\n",
            "Epoch 175/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 1.6990 - val_accuracy: 0.6074\n",
            "\n",
            "Epoch 00175: val_accuracy did not improve from 1.00000\n",
            "Epoch 176/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.7219e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00176: val_accuracy did not improve from 1.00000\n",
            "Epoch 177/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.3853e-04 - accuracy: 1.0000 - val_loss: 7.2796e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00177: val_accuracy did not improve from 1.00000\n",
            "Epoch 178/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.6970e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00178: val_accuracy did not improve from 1.00000\n",
            "Epoch 179/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3743e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00179: val_accuracy did not improve from 1.00000\n",
            "Epoch 180/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2970e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00180: val_accuracy did not improve from 1.00000\n",
            "Epoch 181/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.3527e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00181: val_accuracy did not improve from 1.00000\n",
            "Epoch 182/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5164e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00182: val_accuracy did not improve from 1.00000\n",
            "Epoch 183/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0781e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00183: val_accuracy did not improve from 1.00000\n",
            "Epoch 184/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.6881e-04 - accuracy: 0.9998 - val_loss: 4.5225e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00184: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00184: ReduceLROnPlateau reducing learning rate to 0.0022876791190356016.\n",
            "Epoch 185/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.8041e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00185: val_accuracy did not improve from 1.00000\n",
            "Epoch 186/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5998e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00186: val_accuracy did not improve from 1.00000\n",
            "Epoch 187/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0849e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00187: val_accuracy did not improve from 1.00000\n",
            "Epoch 188/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.6540e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00188: val_accuracy did not improve from 1.00000\n",
            "Epoch 189/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5876e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00189: val_accuracy did not improve from 1.00000\n",
            "Epoch 190/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.9825e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00190: val_accuracy did not improve from 1.00000\n",
            "Epoch 191/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.4856e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00191: val_accuracy did not improve from 1.00000\n",
            "Epoch 192/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.7024e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00192: val_accuracy did not improve from 1.00000\n",
            "Epoch 193/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.6669e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00193: val_accuracy did not improve from 1.00000\n",
            "Epoch 194/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0064e-04 - accuracy: 1.0000 - val_loss: 7.2956e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00194: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00194: ReduceLROnPlateau reducing learning rate to 0.0020589112071320416.\n",
            "Epoch 195/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.4677e-04 - accuracy: 1.0000 - val_loss: 7.3581e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00195: val_accuracy did not improve from 1.00000\n",
            "Epoch 196/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0303e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00196: val_accuracy did not improve from 1.00000\n",
            "Epoch 197/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.1818e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00197: val_accuracy did not improve from 1.00000\n",
            "Epoch 198/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.8154e-05 - accuracy: 1.0000 - val_loss: 9.4589e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00198: val_accuracy did not improve from 1.00000\n",
            "Epoch 199/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5450e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00199: val_accuracy did not improve from 1.00000\n",
            "Epoch 200/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0688e-04 - accuracy: 1.0000 - val_loss: 7.8780e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00200: val_accuracy did not improve from 1.00000\n",
            "Epoch 201/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.3667e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00201: val_accuracy did not improve from 1.00000\n",
            "Epoch 202/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.9110e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00202: val_accuracy did not improve from 1.00000\n",
            "Epoch 203/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3557e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00203: val_accuracy did not improve from 1.00000\n",
            "Epoch 204/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.9718e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00204: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00204: ReduceLROnPlateau reducing learning rate to 0.0018530200235545636.\n",
            "Epoch 205/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4885e-04 - accuracy: 1.0000 - val_loss: 9.9639e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00205: val_accuracy did not improve from 1.00000\n",
            "Epoch 206/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.6648e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00206: val_accuracy did not improve from 1.00000\n",
            "Epoch 207/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.6669e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00207: val_accuracy did not improve from 1.00000\n",
            "Epoch 208/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.6434e-05 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00208: val_accuracy did not improve from 1.00000\n",
            "Epoch 209/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.4476e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00209: val_accuracy did not improve from 1.00000\n",
            "Epoch 210/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0908e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00210: val_accuracy did not improve from 1.00000\n",
            "Epoch 211/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2395e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00211: val_accuracy did not improve from 1.00000\n",
            "Epoch 212/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.7582e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00212: val_accuracy did not improve from 1.00000\n",
            "Epoch 213/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.8703e-04 - accuracy: 1.0000 - val_loss: 9.3314e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00213: val_accuracy did not improve from 1.00000\n",
            "Epoch 214/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.0746e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00214: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00214: ReduceLROnPlateau reducing learning rate to 0.0016677180421538651.\n",
            "Epoch 215/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1101e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00215: val_accuracy did not improve from 1.00000\n",
            "Epoch 216/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1253e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00216: val_accuracy did not improve from 1.00000\n",
            "Epoch 217/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.8001e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00217: val_accuracy did not improve from 1.00000\n",
            "Epoch 218/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.7733e-05 - accuracy: 1.0000 - val_loss: 6.6282e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00218: val_accuracy did not improve from 1.00000\n",
            "Epoch 219/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.0684e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00219: val_accuracy did not improve from 1.00000\n",
            "Epoch 220/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.5921e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00220: val_accuracy did not improve from 1.00000\n",
            "Epoch 221/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.1651e-05 - accuracy: 1.0000 - val_loss: 5.6404e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00221: val_accuracy did not improve from 1.00000\n",
            "Epoch 222/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2305e-04 - accuracy: 1.0000 - val_loss: 8.9942e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00222: val_accuracy did not improve from 1.00000\n",
            "Epoch 223/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2027e-04 - accuracy: 1.0000 - val_loss: 7.0361e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00223: val_accuracy did not improve from 1.00000\n",
            "Epoch 224/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.1217e-05 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00224: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00224: ReduceLROnPlateau reducing learning rate to 0.0015009462484158575.\n",
            "Epoch 225/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.9888e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00225: val_accuracy did not improve from 1.00000\n",
            "Epoch 226/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.0289e-05 - accuracy: 1.0000 - val_loss: 8.3396e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00226: val_accuracy did not improve from 1.00000\n",
            "Epoch 227/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3238e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00227: val_accuracy did not improve from 1.00000\n",
            "Epoch 228/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.8581e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00228: val_accuracy did not improve from 1.00000\n",
            "Epoch 229/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.3911e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00229: val_accuracy did not improve from 1.00000\n",
            "Epoch 230/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.9645e-05 - accuracy: 1.0000 - val_loss: 9.4082e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00230: val_accuracy did not improve from 1.00000\n",
            "Epoch 231/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 9.5524e-05 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
            "\n",
            "Epoch 00231: val_accuracy did not improve from 1.00000\n",
            "Epoch 232/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0827e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00232: val_accuracy did not improve from 1.00000\n",
            "Epoch 233/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.9975e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00233: val_accuracy did not improve from 1.00000\n",
            "Epoch 234/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5896e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00234: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00234: ReduceLROnPlateau reducing learning rate to 0.0013508516130968928.\n",
            "Epoch 235/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.9023e-05 - accuracy: 1.0000 - val_loss: 2.8176e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00235: val_accuracy did not improve from 1.00000\n",
            "Epoch 236/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.4159e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00236: val_accuracy did not improve from 1.00000\n",
            "Epoch 237/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.9574e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00237: val_accuracy did not improve from 1.00000\n",
            "Epoch 238/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.5680e-05 - accuracy: 1.0000 - val_loss: 6.1861e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00238: val_accuracy did not improve from 1.00000\n",
            "Epoch 239/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.4145e-04 - accuracy: 1.0000 - val_loss: 4.7921e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00239: val_accuracy did not improve from 1.00000\n",
            "Epoch 240/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.3970e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00240: val_accuracy did not improve from 1.00000\n",
            "Epoch 241/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.1019e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00241: val_accuracy did not improve from 1.00000\n",
            "Epoch 242/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.7386e-04 - accuracy: 0.9999 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00242: val_accuracy did not improve from 1.00000\n",
            "Epoch 243/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.9817e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00243: val_accuracy did not improve from 1.00000\n",
            "Epoch 244/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3155e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00244: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00244: ReduceLROnPlateau reducing learning rate to 0.0012157664517872036.\n",
            "Epoch 245/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.7038e-05 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00245: val_accuracy did not improve from 1.00000\n",
            "Epoch 246/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2036e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00246: val_accuracy did not improve from 1.00000\n",
            "Epoch 247/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.8474e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00247: val_accuracy did not improve from 1.00000\n",
            "Epoch 248/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.9966e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00248: val_accuracy did not improve from 1.00000\n",
            "Epoch 249/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0666e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00249: val_accuracy did not improve from 1.00000\n",
            "Epoch 250/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.1059e-05 - accuracy: 1.0000 - val_loss: 7.6222e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00250: val_accuracy did not improve from 1.00000\n",
            "Epoch 251/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5514e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00251: val_accuracy did not improve from 1.00000\n",
            "Epoch 252/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.7145e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00252: val_accuracy did not improve from 1.00000\n",
            "Epoch 253/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0737e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00253: val_accuracy did not improve from 1.00000\n",
            "Epoch 254/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.6611e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00254: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00254: ReduceLROnPlateau reducing learning rate to 0.0010941897751763463.\n",
            "Epoch 255/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.6689e-05 - accuracy: 1.0000 - val_loss: 6.7901e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00255: val_accuracy did not improve from 1.00000\n",
            "Epoch 256/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.6565e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00256: val_accuracy did not improve from 1.00000\n",
            "Epoch 257/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 7.5814e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00257: val_accuracy did not improve from 1.00000\n",
            "Epoch 258/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.9534e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00258: val_accuracy did not improve from 1.00000\n",
            "Epoch 259/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.9246e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00259: val_accuracy did not improve from 1.00000\n",
            "Epoch 260/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.6139e-04 - accuracy: 1.0000 - val_loss: 9.3801e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00260: val_accuracy did not improve from 1.00000\n",
            "Epoch 261/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.5684e-05 - accuracy: 1.0000 - val_loss: 7.4660e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00261: val_accuracy did not improve from 1.00000\n",
            "Epoch 262/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.1408e-05 - accuracy: 1.0000 - val_loss: 7.0807e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00262: val_accuracy did not improve from 1.00000\n",
            "Epoch 263/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.4566e-05 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00263: val_accuracy did not improve from 1.00000\n",
            "Epoch 264/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.3733e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00264: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00264: ReduceLROnPlateau reducing learning rate to 0.0009847708395682275.\n",
            "Epoch 265/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.7515e-05 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00265: val_accuracy did not improve from 1.00000\n",
            "Epoch 266/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.6496e-05 - accuracy: 1.0000 - val_loss: 8.0800e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00266: val_accuracy did not improve from 1.00000\n",
            "Epoch 267/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5810e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00267: val_accuracy did not improve from 1.00000\n",
            "Epoch 268/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.9467e-04 - accuracy: 1.0000 - val_loss: 9.0895e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00268: val_accuracy did not improve from 1.00000\n",
            "Epoch 269/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.9350e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00269: val_accuracy did not improve from 1.00000\n",
            "Epoch 270/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0180e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00270: val_accuracy did not improve from 1.00000\n",
            "Epoch 271/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.2880e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00271: val_accuracy did not improve from 1.00000\n",
            "Epoch 272/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1420e-04 - accuracy: 1.0000 - val_loss: 6.8125e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00272: val_accuracy did not improve from 1.00000\n",
            "Epoch 273/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.8813e-05 - accuracy: 1.0000 - val_loss: 5.6570e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00273: val_accuracy did not improve from 1.00000\n",
            "Epoch 274/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3551e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00274: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00274: ReduceLROnPlateau reducing learning rate to 0.0008862937451340258.\n",
            "Epoch 275/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.4681e-05 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00275: val_accuracy did not improve from 1.00000\n",
            "Epoch 276/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.4913e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00276: val_accuracy did not improve from 1.00000\n",
            "Epoch 277/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2285e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00277: val_accuracy did not improve from 1.00000\n",
            "Epoch 278/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.9187e-05 - accuracy: 1.0000 - val_loss: 9.1665e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00278: val_accuracy did not improve from 1.00000\n",
            "Epoch 279/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2820e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00279: val_accuracy did not improve from 1.00000\n",
            "Epoch 280/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.2400e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00280: val_accuracy did not improve from 1.00000\n",
            "Epoch 281/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.5973e-05 - accuracy: 1.0000 - val_loss: 7.7280e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00281: val_accuracy did not improve from 1.00000\n",
            "Epoch 282/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.5738e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00282: val_accuracy did not improve from 1.00000\n",
            "Epoch 283/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.8153e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00283: val_accuracy did not improve from 1.00000\n",
            "Epoch 284/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.7826e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00284: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00284: ReduceLROnPlateau reducing learning rate to 0.0007976643915753812.\n",
            "Epoch 285/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.2167e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00285: val_accuracy did not improve from 1.00000\n",
            "Epoch 286/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.2969e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00286: val_accuracy did not improve from 1.00000\n",
            "Epoch 287/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.1819e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00287: val_accuracy did not improve from 1.00000\n",
            "Epoch 288/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.2851e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00288: val_accuracy did not improve from 1.00000\n",
            "Epoch 289/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 8.5126e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00289: val_accuracy did not improve from 1.00000\n",
            "Epoch 290/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.1273e-05 - accuracy: 1.0000 - val_loss: 7.1312e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00290: val_accuracy did not improve from 1.00000\n",
            "Epoch 291/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 8.0270e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00291: val_accuracy did not improve from 1.00000\n",
            "Epoch 292/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 9.1273e-05 - accuracy: 1.0000 - val_loss: 6.4159e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00292: val_accuracy did not improve from 1.00000\n",
            "Epoch 293/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 4.6335e-05 - accuracy: 1.0000 - val_loss: 8.4184e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00293: val_accuracy did not improve from 1.00000\n",
            "Epoch 294/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 4.7272e-05 - accuracy: 1.0000 - val_loss: 4.2601e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00294: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00294: ReduceLROnPlateau reducing learning rate to 0.0007178979576565325.\n",
            "Epoch 295/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 7.5393e-05 - accuracy: 1.0000 - val_loss: 4.6717e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00295: val_accuracy did not improve from 1.00000\n",
            "Epoch 296/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.6106e-05 - accuracy: 1.0000 - val_loss: 5.9491e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00296: val_accuracy did not improve from 1.00000\n",
            "Epoch 297/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.2673e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00297: val_accuracy did not improve from 1.00000\n",
            "Epoch 298/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.2586e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00298: val_accuracy did not improve from 1.00000\n",
            "Epoch 299/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.1071e-05 - accuracy: 1.0000 - val_loss: 9.1783e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00299: val_accuracy did not improve from 1.00000\n",
            "Epoch 300/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.8447e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00300: val_accuracy did not improve from 1.00000\n",
            "Epoch 301/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0699e-04 - accuracy: 1.0000 - val_loss: 9.1439e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00301: val_accuracy did not improve from 1.00000\n",
            "Epoch 302/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.9025e-05 - accuracy: 1.0000 - val_loss: 5.5746e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00302: val_accuracy did not improve from 1.00000\n",
            "Epoch 303/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.3792e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00303: val_accuracy did not improve from 1.00000\n",
            "Epoch 304/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.6213e-05 - accuracy: 1.0000 - val_loss: 6.9693e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00304: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00304: ReduceLROnPlateau reducing learning rate to 0.0006461081618908793.\n",
            "Epoch 305/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.6899e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00305: val_accuracy did not improve from 1.00000\n",
            "Epoch 306/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4199e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00306: val_accuracy did not improve from 1.00000\n",
            "Epoch 307/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.0170e-05 - accuracy: 1.0000 - val_loss: 7.4310e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00307: val_accuracy did not improve from 1.00000\n",
            "Epoch 308/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.6507e-04 - accuracy: 1.0000 - val_loss: 8.6546e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00308: val_accuracy did not improve from 1.00000\n",
            "Epoch 309/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.8740e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00309: val_accuracy did not improve from 1.00000\n",
            "Epoch 310/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.5303e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00310: val_accuracy did not improve from 1.00000\n",
            "Epoch 311/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3061e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00311: val_accuracy did not improve from 1.00000\n",
            "Epoch 312/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.7513e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00312: val_accuracy did not improve from 1.00000\n",
            "Epoch 313/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.4775e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00313: val_accuracy did not improve from 1.00000\n",
            "Epoch 314/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 6.1249e-05 - accuracy: 1.0000 - val_loss: 9.8075e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00314: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00314: ReduceLROnPlateau reducing learning rate to 0.0005814973614178598.\n",
            "Epoch 315/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.1343e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00315: val_accuracy did not improve from 1.00000\n",
            "Epoch 316/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.0589e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00316: val_accuracy did not improve from 1.00000\n",
            "Epoch 317/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.1295e-05 - accuracy: 1.0000 - val_loss: 8.7428e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00317: val_accuracy did not improve from 1.00000\n",
            "Epoch 318/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.7032e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00318: val_accuracy did not improve from 1.00000\n",
            "Epoch 319/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1817e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00319: val_accuracy did not improve from 1.00000\n",
            "Epoch 320/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.6875e-05 - accuracy: 1.0000 - val_loss: 8.6085e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00320: val_accuracy did not improve from 1.00000\n",
            "Epoch 321/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4966e-04 - accuracy: 1.0000 - val_loss: 8.7838e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00321: val_accuracy did not improve from 1.00000\n",
            "Epoch 322/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.9540e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00322: val_accuracy did not improve from 1.00000\n",
            "Epoch 323/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.8975e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00323: val_accuracy did not improve from 1.00000\n",
            "Epoch 324/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.5971e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00324: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00324: ReduceLROnPlateau reducing learning rate to 0.0005233476462308317.\n",
            "Epoch 325/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.2827e-05 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00325: val_accuracy did not improve from 1.00000\n",
            "Epoch 326/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.0733e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00326: val_accuracy did not improve from 1.00000\n",
            "Epoch 327/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3759e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00327: val_accuracy did not improve from 1.00000\n",
            "Epoch 328/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.4028e-05 - accuracy: 1.0000 - val_loss: 7.1387e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00328: val_accuracy did not improve from 1.00000\n",
            "Epoch 329/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.1282e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00329: val_accuracy did not improve from 1.00000\n",
            "Epoch 330/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3639e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00330: val_accuracy did not improve from 1.00000\n",
            "Epoch 331/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4133e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00331: val_accuracy did not improve from 1.00000\n",
            "Epoch 332/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.2386e-05 - accuracy: 1.0000 - val_loss: 8.7045e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00332: val_accuracy did not improve from 1.00000\n",
            "Epoch 333/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.1531e-05 - accuracy: 1.0000 - val_loss: 4.5660e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00333: val_accuracy did not improve from 1.00000\n",
            "Epoch 334/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.4385e-05 - accuracy: 1.0000 - val_loss: 9.5753e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00334: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00334: ReduceLROnPlateau reducing learning rate to 0.0004710128763690591.\n",
            "Epoch 335/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 9.8354e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00335: val_accuracy did not improve from 1.00000\n",
            "Epoch 336/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 5.7555e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00336: val_accuracy did not improve from 1.00000\n",
            "Epoch 337/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.8236e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00337: val_accuracy did not improve from 1.00000\n",
            "Epoch 338/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.4549e-05 - accuracy: 1.0000 - val_loss: 8.3417e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00338: val_accuracy did not improve from 1.00000\n",
            "Epoch 339/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3848e-04 - accuracy: 1.0000 - val_loss: 6.9084e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00339: val_accuracy did not improve from 1.00000\n",
            "Epoch 340/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.8541e-05 - accuracy: 1.0000 - val_loss: 7.5976e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00340: val_accuracy did not improve from 1.00000\n",
            "Epoch 341/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.4693e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00341: val_accuracy did not improve from 1.00000\n",
            "Epoch 342/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.4988e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00342: val_accuracy did not improve from 1.00000\n",
            "Epoch 343/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0767e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00343: val_accuracy did not improve from 1.00000\n",
            "Epoch 344/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.4817e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00344: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00344: ReduceLROnPlateau reducing learning rate to 0.0004239115834934637.\n",
            "Epoch 345/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 9.6702e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00345: val_accuracy did not improve from 1.00000\n",
            "Epoch 346/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.2899e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00346: val_accuracy did not improve from 1.00000\n",
            "Epoch 347/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.5597e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00347: val_accuracy did not improve from 1.00000\n",
            "Epoch 348/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.6896e-05 - accuracy: 1.0000 - val_loss: 7.7218e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00348: val_accuracy did not improve from 1.00000\n",
            "Epoch 349/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1393e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00349: val_accuracy did not improve from 1.00000\n",
            "Epoch 350/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3508e-04 - accuracy: 1.0000 - val_loss: 9.1470e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00350: val_accuracy did not improve from 1.00000\n",
            "Epoch 351/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.4457e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00351: val_accuracy did not improve from 1.00000\n",
            "Epoch 352/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.1133e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00352: val_accuracy did not improve from 1.00000\n",
            "Epoch 353/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.8020e-05 - accuracy: 1.0000 - val_loss: 9.0453e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00353: val_accuracy did not improve from 1.00000\n",
            "Epoch 354/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.6316e-05 - accuracy: 1.0000 - val_loss: 8.6454e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00354: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00354: ReduceLROnPlateau reducing learning rate to 0.0003815204225247726.\n",
            "Epoch 355/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3149e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00355: val_accuracy did not improve from 1.00000\n",
            "Epoch 356/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.8333e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00356: val_accuracy did not improve from 1.00000\n",
            "Epoch 357/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.7661e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00357: val_accuracy did not improve from 1.00000\n",
            "Epoch 358/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.3781e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00358: val_accuracy did not improve from 1.00000\n",
            "Epoch 359/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0479e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00359: val_accuracy did not improve from 1.00000\n",
            "Epoch 360/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0432e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00360: val_accuracy did not improve from 1.00000\n",
            "Epoch 361/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0370e-04 - accuracy: 1.0000 - val_loss: 8.8940e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00361: val_accuracy did not improve from 1.00000\n",
            "Epoch 362/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.2358e-05 - accuracy: 1.0000 - val_loss: 9.4814e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00362: val_accuracy did not improve from 1.00000\n",
            "Epoch 363/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.2330e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00363: val_accuracy did not improve from 1.00000\n",
            "Epoch 364/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0616e-04 - accuracy: 1.0000 - val_loss: 9.4652e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00364: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00364: ReduceLROnPlateau reducing learning rate to 0.0003433683828916401.\n",
            "Epoch 365/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.3980e-05 - accuracy: 1.0000 - val_loss: 8.4324e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00365: val_accuracy did not improve from 1.00000\n",
            "Epoch 366/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.2982e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00366: val_accuracy did not improve from 1.00000\n",
            "Epoch 367/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.5514e-05 - accuracy: 1.0000 - val_loss: 8.9148e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00367: val_accuracy did not improve from 1.00000\n",
            "Epoch 368/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.1970e-05 - accuracy: 1.0000 - val_loss: 6.7520e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00368: val_accuracy did not improve from 1.00000\n",
            "Epoch 369/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.2806e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00369: val_accuracy did not improve from 1.00000\n",
            "Epoch 370/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.8219e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00370: val_accuracy did not improve from 1.00000\n",
            "Epoch 371/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 1.8346e-04 - accuracy: 1.0000 - val_loss: 9.3220e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00371: val_accuracy did not improve from 1.00000\n",
            "Epoch 372/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.6843e-04 - accuracy: 0.9999 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00372: val_accuracy did not improve from 1.00000\n",
            "Epoch 373/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.7576e-05 - accuracy: 1.0000 - val_loss: 8.5847e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00373: val_accuracy did not improve from 1.00000\n",
            "Epoch 374/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.9373e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00374: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00374: ReduceLROnPlateau reducing learning rate to 0.0003090315498411656.\n",
            "Epoch 375/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.7104e-05 - accuracy: 1.0000 - val_loss: 8.3694e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00375: val_accuracy did not improve from 1.00000\n",
            "Epoch 376/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.4688e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00376: val_accuracy did not improve from 1.00000\n",
            "Epoch 377/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.8538e-05 - accuracy: 1.0000 - val_loss: 7.5317e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00377: val_accuracy did not improve from 1.00000\n",
            "Epoch 378/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0719e-04 - accuracy: 1.0000 - val_loss: 5.3743e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00378: val_accuracy did not improve from 1.00000\n",
            "Epoch 379/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.4589e-05 - accuracy: 1.0000 - val_loss: 7.1353e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00379: val_accuracy did not improve from 1.00000\n",
            "Epoch 380/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.9257e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00380: val_accuracy did not improve from 1.00000\n",
            "Epoch 381/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.3588e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00381: val_accuracy did not improve from 1.00000\n",
            "Epoch 382/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.9951e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00382: val_accuracy did not improve from 1.00000\n",
            "Epoch 383/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.8475e-05 - accuracy: 1.0000 - val_loss: 8.0516e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00383: val_accuracy did not improve from 1.00000\n",
            "Epoch 384/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.4636e-05 - accuracy: 1.0000 - val_loss: 7.6432e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00384: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00384: ReduceLROnPlateau reducing learning rate to 0.00027812838961835954.\n",
            "Epoch 385/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.5174e-05 - accuracy: 1.0000 - val_loss: 8.5711e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00385: val_accuracy did not improve from 1.00000\n",
            "Epoch 386/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.3855e-05 - accuracy: 1.0000 - val_loss: 7.2061e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00386: val_accuracy did not improve from 1.00000\n",
            "Epoch 387/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.1277e-05 - accuracy: 1.0000 - val_loss: 8.5000e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00387: val_accuracy did not improve from 1.00000\n",
            "Epoch 388/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3948e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00388: val_accuracy did not improve from 1.00000\n",
            "Epoch 389/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.1716e-05 - accuracy: 1.0000 - val_loss: 9.6663e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00389: val_accuracy did not improve from 1.00000\n",
            "Epoch 390/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.4147e-05 - accuracy: 1.0000 - val_loss: 5.4523e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00390: val_accuracy did not improve from 1.00000\n",
            "Epoch 391/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.8462e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00391: val_accuracy did not improve from 1.00000\n",
            "Epoch 392/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.3715e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00392: val_accuracy did not improve from 1.00000\n",
            "Epoch 393/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.3225e-05 - accuracy: 1.0000 - val_loss: 7.0293e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00393: val_accuracy did not improve from 1.00000\n",
            "Epoch 394/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.0796e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00394: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00394: ReduceLROnPlateau reducing learning rate to 0.00025031555851455777.\n",
            "Epoch 395/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3033e-04 - accuracy: 1.0000 - val_loss: 9.4320e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00395: val_accuracy did not improve from 1.00000\n",
            "Epoch 396/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2832e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00396: val_accuracy did not improve from 1.00000\n",
            "Epoch 397/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.1208e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00397: val_accuracy did not improve from 1.00000\n",
            "Epoch 398/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.0714e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00398: val_accuracy did not improve from 1.00000\n",
            "Epoch 399/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.9698e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00399: val_accuracy did not improve from 1.00000\n",
            "Epoch 400/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.0262e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00400: val_accuracy did not improve from 1.00000\n",
            "Epoch 401/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.8706e-04 - accuracy: 0.9998 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00401: val_accuracy did not improve from 1.00000\n",
            "Epoch 402/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.8851e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00402: val_accuracy did not improve from 1.00000\n",
            "Epoch 403/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 7.5872e-05 - accuracy: 1.0000 - val_loss: 8.2475e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00403: val_accuracy did not improve from 1.00000\n",
            "Epoch 404/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.7298e-05 - accuracy: 1.0000 - val_loss: 9.9619e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00404: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00404: ReduceLROnPlateau reducing learning rate to 0.00022528400004375725.\n",
            "Epoch 405/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.5490e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00405: val_accuracy did not improve from 1.00000\n",
            "Epoch 406/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0972e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00406: val_accuracy did not improve from 1.00000\n",
            "Epoch 407/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.4993e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00407: val_accuracy did not improve from 1.00000\n",
            "Epoch 408/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.4361e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00408: val_accuracy did not improve from 1.00000\n",
            "Epoch 409/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.4537e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00409: val_accuracy did not improve from 1.00000\n",
            "Epoch 410/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.5229e-04 - accuracy: 0.9998 - val_loss: 6.4093e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00410: val_accuracy did not improve from 1.00000\n",
            "Epoch 411/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3441e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00411: val_accuracy did not improve from 1.00000\n",
            "Epoch 412/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.4880e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00412: val_accuracy did not improve from 1.00000\n",
            "Epoch 413/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.7028e-05 - accuracy: 1.0000 - val_loss: 9.5106e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00413: val_accuracy did not improve from 1.00000\n",
            "Epoch 414/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.4792e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00414: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00414: ReduceLROnPlateau reducing learning rate to 0.000202755605278071.\n",
            "Epoch 415/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.8498e-05 - accuracy: 1.0000 - val_loss: 9.6424e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00415: val_accuracy did not improve from 1.00000\n",
            "Epoch 416/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.2925e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00416: val_accuracy did not improve from 1.00000\n",
            "Epoch 417/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.0380e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00417: val_accuracy did not improve from 1.00000\n",
            "Epoch 418/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.9889e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00418: val_accuracy did not improve from 1.00000\n",
            "Epoch 419/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.6170e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00419: val_accuracy did not improve from 1.00000\n",
            "Epoch 420/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.3650e-05 - accuracy: 1.0000 - val_loss: 9.7669e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00420: val_accuracy did not improve from 1.00000\n",
            "Epoch 421/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.4109e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00421: val_accuracy did not improve from 1.00000\n",
            "Epoch 422/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.5214e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00422: val_accuracy did not improve from 1.00000\n",
            "Epoch 423/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.5499e-05 - accuracy: 1.0000 - val_loss: 9.6771e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00423: val_accuracy did not improve from 1.00000\n",
            "Epoch 424/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1999e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00424: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00424: ReduceLROnPlateau reducing learning rate to 0.00018248004344059154.\n",
            "Epoch 425/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.4127e-05 - accuracy: 1.0000 - val_loss: 9.3876e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00425: val_accuracy did not improve from 1.00000\n",
            "Epoch 426/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.2750e-05 - accuracy: 1.0000 - val_loss: 8.1928e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00426: val_accuracy did not improve from 1.00000\n",
            "Epoch 427/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1866e-04 - accuracy: 1.0000 - val_loss: 8.3074e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00427: val_accuracy did not improve from 1.00000\n",
            "Epoch 428/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 7.7121e-05 - accuracy: 1.0000 - val_loss: 7.5229e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00428: val_accuracy did not improve from 1.00000\n",
            "Epoch 429/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.2517e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00429: val_accuracy did not improve from 1.00000\n",
            "Epoch 430/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.5757e-05 - accuracy: 1.0000 - val_loss: 8.8083e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00430: val_accuracy did not improve from 1.00000\n",
            "Epoch 431/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.2465e-05 - accuracy: 1.0000 - val_loss: 8.1880e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00431: val_accuracy did not improve from 1.00000\n",
            "Epoch 432/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.2560e-05 - accuracy: 1.0000 - val_loss: 9.9430e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00432: val_accuracy did not improve from 1.00000\n",
            "Epoch 433/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0247e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00433: val_accuracy did not improve from 1.00000\n",
            "Epoch 434/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0599e-04 - accuracy: 1.0000 - val_loss: 8.8397e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00434: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00434: ReduceLROnPlateau reducing learning rate to 0.00016423203778686004.\n",
            "Epoch 435/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.3406e-05 - accuracy: 1.0000 - val_loss: 7.1519e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00435: val_accuracy did not improve from 1.00000\n",
            "Epoch 436/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.8152e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00436: val_accuracy did not improve from 1.00000\n",
            "Epoch 437/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0131e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00437: val_accuracy did not improve from 1.00000\n",
            "Epoch 438/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.4956e-05 - accuracy: 1.0000 - val_loss: 9.1980e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00438: val_accuracy did not improve from 1.00000\n",
            "Epoch 439/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.7592e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00439: val_accuracy did not improve from 1.00000\n",
            "Epoch 440/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.4988e-05 - accuracy: 1.0000 - val_loss: 9.3127e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00440: val_accuracy did not improve from 1.00000\n",
            "Epoch 441/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.0856e-05 - accuracy: 1.0000 - val_loss: 5.8785e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00441: val_accuracy did not improve from 1.00000\n",
            "Epoch 442/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.2019e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00442: val_accuracy did not improve from 1.00000\n",
            "Epoch 443/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.9397e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00443: val_accuracy did not improve from 1.00000\n",
            "Epoch 444/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0035e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00444: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00444: ReduceLROnPlateau reducing learning rate to 0.00014780883793719113.\n",
            "Epoch 445/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.7910e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00445: val_accuracy did not improve from 1.00000\n",
            "Epoch 446/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 2.0283e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00446: val_accuracy did not improve from 1.00000\n",
            "Epoch 447/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2570e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00447: val_accuracy did not improve from 1.00000\n",
            "Epoch 448/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.3260e-05 - accuracy: 1.0000 - val_loss: 7.2132e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00448: val_accuracy did not improve from 1.00000\n",
            "Epoch 449/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0212e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00449: val_accuracy did not improve from 1.00000\n",
            "Epoch 450/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.3795e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00450: val_accuracy did not improve from 1.00000\n",
            "Epoch 451/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.3388e-05 - accuracy: 1.0000 - val_loss: 7.6397e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00451: val_accuracy did not improve from 1.00000\n",
            "Epoch 452/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.8332e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00452: val_accuracy did not improve from 1.00000\n",
            "Epoch 453/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.3351e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00453: val_accuracy did not improve from 1.00000\n",
            "Epoch 454/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.8499e-05 - accuracy: 1.0000 - val_loss: 7.0186e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00454: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00454: ReduceLROnPlateau reducing learning rate to 0.00013302795414347202.\n",
            "Epoch 455/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.6658e-05 - accuracy: 1.0000 - val_loss: 7.0823e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00455: val_accuracy did not improve from 1.00000\n",
            "Epoch 456/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1493e-04 - accuracy: 1.0000 - val_loss: 5.7649e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00456: val_accuracy did not improve from 1.00000\n",
            "Epoch 457/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.1481e-05 - accuracy: 1.0000 - val_loss: 7.0062e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00457: val_accuracy did not improve from 1.00000\n",
            "Epoch 458/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.0866e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00458: val_accuracy did not improve from 1.00000\n",
            "Epoch 459/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 1.1963e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00459: val_accuracy did not improve from 1.00000\n",
            "Epoch 460/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.1641e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00460: val_accuracy did not improve from 1.00000\n",
            "Epoch 461/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.5768e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00461: val_accuracy did not improve from 1.00000\n",
            "Epoch 462/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1670e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00462: val_accuracy did not improve from 1.00000\n",
            "Epoch 463/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.1493e-05 - accuracy: 1.0000 - val_loss: 6.8712e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00463: val_accuracy did not improve from 1.00000\n",
            "Epoch 464/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.2774e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00464: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00464: ReduceLROnPlateau reducing learning rate to 0.00011972515349043534.\n",
            "Epoch 465/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 9.8623e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00465: val_accuracy did not improve from 1.00000\n",
            "Epoch 466/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.9594e-05 - accuracy: 1.0000 - val_loss: 7.8412e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00466: val_accuracy did not improve from 1.00000\n",
            "Epoch 467/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.4130e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00467: val_accuracy did not improve from 1.00000\n",
            "Epoch 468/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.3472e-04 - accuracy: 1.0000 - val_loss: 8.6212e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00468: val_accuracy did not improve from 1.00000\n",
            "Epoch 469/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.9684e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00469: val_accuracy did not improve from 1.00000\n",
            "Epoch 470/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 3.3859e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00470: val_accuracy did not improve from 1.00000\n",
            "Epoch 471/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1072e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00471: val_accuracy did not improve from 1.00000\n",
            "Epoch 472/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.9367e-05 - accuracy: 1.0000 - val_loss: 8.2613e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00472: val_accuracy did not improve from 1.00000\n",
            "Epoch 473/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.5073e-05 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00473: val_accuracy did not improve from 1.00000\n",
            "Epoch 474/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.1240e-05 - accuracy: 1.0000 - val_loss: 9.6032e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00474: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00474: ReduceLROnPlateau reducing learning rate to 0.00010775263945106417.\n",
            "Epoch 475/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.1780e-04 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00475: val_accuracy did not improve from 1.00000\n",
            "Epoch 476/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.8836e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00476: val_accuracy did not improve from 1.00000\n",
            "Epoch 477/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.1038e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00477: val_accuracy did not improve from 1.00000\n",
            "Epoch 478/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.1526e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00478: val_accuracy did not improve from 1.00000\n",
            "Epoch 479/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.0284e-05 - accuracy: 1.0000 - val_loss: 7.6346e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00479: val_accuracy did not improve from 1.00000\n",
            "Epoch 480/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.0998e-04 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00480: val_accuracy did not improve from 1.00000\n",
            "Epoch 481/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.1826e-04 - accuracy: 1.0000 - val_loss: 7.0441e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00481: val_accuracy did not improve from 1.00000\n",
            "Epoch 482/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.6623e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00482: val_accuracy did not improve from 1.00000\n",
            "Epoch 483/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0657e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00483: val_accuracy did not improve from 1.00000\n",
            "Epoch 484/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 8.2424e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00484: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00484: ReduceLROnPlateau reducing learning rate to 9.697737550595775e-05.\n",
            "Epoch 485/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 4.8104e-05 - accuracy: 1.0000 - val_loss: 6.8538e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00485: val_accuracy did not improve from 1.00000\n",
            "Epoch 486/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.8451e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00486: val_accuracy did not improve from 1.00000\n",
            "Epoch 487/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.2634e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00487: val_accuracy did not improve from 1.00000\n",
            "Epoch 488/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 5.0126e-05 - accuracy: 1.0000 - val_loss: 9.9951e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00488: val_accuracy did not improve from 1.00000\n",
            "Epoch 489/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 1.0221e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00489: val_accuracy did not improve from 1.00000\n",
            "Epoch 490/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 6.7937e-05 - accuracy: 1.0000 - val_loss: 8.1783e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00490: val_accuracy did not improve from 1.00000\n",
            "Epoch 491/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.5377e-05 - accuracy: 1.0000 - val_loss: 7.2425e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00491: val_accuracy did not improve from 1.00000\n",
            "Epoch 492/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 4.2093e-05 - accuracy: 1.0000 - val_loss: 8.8378e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00492: val_accuracy did not improve from 1.00000\n",
            "Epoch 493/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.1359e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00493: val_accuracy did not improve from 1.00000\n",
            "Epoch 494/500\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 7.5962e-05 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00494: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 00494: ReduceLROnPlateau reducing learning rate to 8.727963795536197e-05.\n",
            "Epoch 495/500\n",
            "192/192 [==============================] - 2s 8ms/step - loss: 5.5322e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00495: val_accuracy did not improve from 1.00000\n",
            "Epoch 496/500\n",
            "192/192 [==============================] - 2s 8ms/step - loss: 7.3168e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00496: val_accuracy did not improve from 1.00000\n",
            "Epoch 497/500\n",
            "192/192 [==============================] - 2s 8ms/step - loss: 4.7814e-05 - accuracy: 1.0000 - val_loss: 8.5314e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00497: val_accuracy did not improve from 1.00000\n",
            "Epoch 498/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 1.0699e-04 - accuracy: 1.0000 - val_loss: 6.5514e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00498: val_accuracy did not improve from 1.00000\n",
            "Epoch 499/500\n",
            "192/192 [==============================] - 2s 8ms/step - loss: 7.8850e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00499: val_accuracy did not improve from 1.00000\n",
            "Epoch 500/500\n",
            "192/192 [==============================] - 1s 8ms/step - loss: 1.0375e-04 - accuracy: 1.0000 - val_loss: 8.7904e-04 - val_accuracy: 0.9993\n",
            "\n",
            "Epoch 00500: val_accuracy did not improve from 1.00000\n",
            "Training/validation time was: 793.366 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "60/60 [==============================] - 0s 3ms/step - loss: 2.4657e-04 - accuracy: 1.0000\n",
            "Evaluate time was 0.241023 seconds\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhUBkA_gWraT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e74148ea-02a7-4f1d-9390-91758a1e138f"
      },
      "source": [
        "# Acurácia:\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Train_acc vs. val_acc', fontsize=20)\n",
        "plt.xlabel('Epoch',fontsize=18)\n",
        "plt.ylabel('Accuracy',fontsize=18)\n",
        "plt.legend(['Train', 'Validation'], loc='best', fontsize=18)\n",
        "plt.show()\n",
        "#Para salvar no Drive...\n",
        "#plt.savefig('/content/drive/My Drive/MESTRADO - UFES/trainacc_vs_valacc.png', transparent=True)\n",
        "\n",
        "# Perda (loss):\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs', fontsize=20)\n",
        "plt.ylabel('Loss',fontsize=18)\n",
        "plt.xlabel('Epoch',fontsize=18)\n",
        "plt.legend(['Train', 'Validation'], loc='best', fontsize=20)\n",
        "plt.show()\n",
        "#Para salvar no Drive...\n",
        "#plt.savefig('/content/drive/My Drive/MESTRADO - UFES/trainloss_vs_valloss.png', transparent=True)\n",
        "\n",
        "print('Max val_acc was:',acc_max)\n",
        "print('Eval_acc was:',test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max val_acc was: 1.0\n",
            "Eval_acc was: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXhEUYWdi1CR"
      },
      "source": [
        "# 6.Second stage simulation (CNN hyperparameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bga5471pz73f"
      },
      "source": [
        "**Briefly, the steps that make up the 2nd optimization stage are:**\r\n",
        "\r\n",
        "* 6.1 Reduction of the database according to the 1st stage of optimization;\r\n",
        "* 6.2 Definition of hyperparameters for adjustment and search space size;\r\n",
        "* 6.3 CNN implementation with architecture that allows automatic adjustment;\r\n",
        "* 6.4 Definition of fitness function;\r\n",
        "* 6.5 Implementation of the Bayesian optimizer;\r\n",
        "* 6.6 Plot the graphs with the optimization history.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4746jxTL6E4A"
      },
      "source": [
        "## 6.1.Dataset reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHOOa_O88Uel"
      },
      "source": [
        "Reduction will be the same as the identified on 1st stage:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKMqKRaJp0RR"
      },
      "source": [
        "# Redução do nº de casos na base de dados (conforme resultado do 1º estágio):\r\n",
        "X_train2, Y_train2, X_val2, Y_val2, X_test2, Y_test2, n_cases2 = subsetB(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8b30PZF6PsY"
      },
      "source": [
        "## 6.2.Hyperparameters definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoqttrfP8_I_"
      },
      "source": [
        "Definition of the hyperparameters to adjust, the search space and the standard adjustment (required by the optimizer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qv31BM2q6zT"
      },
      "source": [
        "# Definição do range de variação dos hiperparâmetros selecionados:\r\n",
        "dim_num_conv_layers = Integer(low=2, high=4, name='num_conv_layers')\r\n",
        "dim_num_conv_nodes = Integer(low=32, high=256, name='num_conv_nodes')\r\n",
        "dim_num_dense_layers = Integer(low=1, high=3, name='num_dense_layers') # Variando até 3 pois a última é de classificação, com ativador \"Softmax\".\r\n",
        "dim_num_dense_nodes = Integer(low=16, high=256, name='num_dense_nodes')\r\n",
        "\r\n",
        "# Definição do vetor que representa o espaço de busca do otimizador:\r\n",
        "hp = [dim_num_conv_layers, dim_num_conv_nodes, dim_num_dense_layers, dim_num_dense_nodes]\r\n",
        "\r\n",
        "# Definição do conjunto de hiperparâmetros padrão (requerido pelo otimizador):\r\n",
        "default_parameters = [4, 128, 3, 256]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dryt48K_616G"
      },
      "source": [
        "## 6.3.Model function (automodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xGrrZnl9O5V"
      },
      "source": [
        "Definition of new Callbacks parameters for the 2nd stage.\r\n",
        "\r\n",
        "(EarlyStopping was configurated to stop CNN after 50 epochs without accuracy improvements)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asYx7f2Mzmzx"
      },
      "source": [
        "# EarlyStopping (O modelo pára o treinamento caso não perceba melhoria):\r\n",
        "earlystopping2 = EarlyStopping(monitor=\"val_accuracy\", min_delta=0, patience=100,\r\n",
        "                              verbose=1, mode=\"auto\", baseline=None,\r\n",
        "                              restore_best_weights=True)\r\n",
        "\r\n",
        "# TensorDash (acompanhamento das métricas do modelo pelo app Android):\r\n",
        "histories2 = Tensordash(ModelName = 'AutoML2', email = 'viniciuswv@gmail.com',\r\n",
        "                       password = 'admin1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2Jx-ZGf96Pn"
      },
      "source": [
        "Definition of the CNN function, with **dynamic architecture**.\r\n",
        "\r\n",
        "(It's necessary to pass the selected hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX3lNFvwiyQ8"
      },
      "source": [
        "# Batch size (número de exemplos de treinamento usados em uma iteração/época):\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# Épocas (quantidade de ciclos de treinamento da rede neural):\r\n",
        "epochs = 500\r\n",
        "\r\n",
        "def automodel (num_conv_layers, num_conv_nodes, num_dense_layers, num_dense_nodes):\r\n",
        "  '''\r\n",
        "  Hyperparameters:\r\n",
        "  num_conv_layers: Number of convolutional layers.\r\n",
        "  num_conv_nodes: Number of neurons in each convolutional layer,\r\n",
        "  num_dense_layers: Number of dense layers.\r\n",
        "  num_dense_nodes: Number of neurons in each dense layer.\r\n",
        "  '''\r\n",
        "\r\n",
        "  # Criação das camadas com apoio do recurso 'keras.sequential':\r\n",
        "  model = Sequential() # Empilha linearmente as camadas da rede, conforme abaixo:\r\n",
        "  \r\n",
        "  # Camada de alimentação do dataset:\r\n",
        "  model.add(InputLayer(input_shape=(1666,1))) # O tensor de entrada tem o shape (1666, 1).\r\n",
        "\r\n",
        "  # Controle de camadas convolucionais (e MaxPooling/BatchNormalization):\r\n",
        "  for i in range(num_conv_layers):\r\n",
        "    name = 'layer_conv_{0}'.format(i+1) # Nome da camada.\r\n",
        "    \r\n",
        "    model.add(Conv1D(num_conv_nodes,\r\n",
        "                     kernel_size=4,\r\n",
        "                     strides=1,\r\n",
        "                     activation='relu',\r\n",
        "                     padding='same',\r\n",
        "                     name=name))\r\n",
        "    \r\n",
        "    model.add(MaxPooling1D(pool_size=3, strides=None, padding='valid'))\r\n",
        "    \r\n",
        "    model.add(BatchNormalization())\r\n",
        "  \r\n",
        "  # Camada de achatamento (flatten):\r\n",
        "  model.add(Flatten())\r\n",
        " \r\n",
        "  # Controle de camadas densas (fully connected):\r\n",
        "  for i in range(num_dense_layers):\r\n",
        "    name = 'layer_dense_{0}'.format(i+1) # Nome da camada.\r\n",
        "    model.add(Dense(num_dense_nodes, activation='relu', name=name))\r\n",
        "\r\n",
        "  # Última camada densa (necessária para a classificação das features):\r\n",
        "  model.add(Dense(16, activation='softmax'))\r\n",
        "\r\n",
        "  # Programação da Taxa de Aprendizado (decaimento exponencial):\r\n",
        "  lr_schedule2 = keras.optimizers.schedules.ExponentialDecay(\r\n",
        "  initial_learning_rate=1e-2,\r\n",
        "  decay_steps=50,\r\n",
        "  decay_rate=0.95)\r\n",
        "\r\n",
        "  # Otimizador da rede:\r\n",
        "  optimizer2 = tf.keras.optimizers.SGD(learning_rate= lr_schedule2, name=\"SGD\")\r\n",
        "\r\n",
        "  model.compile(loss= 'categorical_crossentropy',\r\n",
        "                optimizer= optimizer2,\r\n",
        "                metrics=['accuracy'])\r\n",
        " \r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moLrGBBi7AaY"
      },
      "source": [
        "##6.4.Fitness function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drymEB4y-4Qv"
      },
      "source": [
        "* The fitness function will call the dynamic CNN, that will train with a certain set of hyperparameters.\r\n",
        "\r\n",
        "* The validation accuracy will be stored after each training season, and will be used as an evaluation criterion by the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKEV4IBxmlR0"
      },
      "source": [
        "# Método padrão para implementação da fitness function:\r\n",
        "@use_named_args(dimensions=hp)\r\n",
        "def fitness(num_conv_layers, num_conv_nodes, num_dense_layers, num_dense_nodes):\r\n",
        "    \r\n",
        "    # Visualização dos hiperparâmetros durante o processo de otimização:\r\n",
        "    print('NEXT SET OF HYPERPARAMETERS IS:',\r\n",
        "          '\\n num_conv_layers:', num_conv_layers,\r\n",
        "          '\\n num_conv_nodes:', num_conv_nodes,   \r\n",
        "          '\\n num_dense_layers:', num_dense_layers,\r\n",
        "          '\\n num_dense_nodes:', num_dense_nodes,\r\n",
        "          '\\n')\r\n",
        "    \r\n",
        "    # Criação da CNN com os hiperparâmetros selecionados:\r\n",
        "    model_opt = automodel(num_conv_layers=num_conv_layers,\r\n",
        "                          num_conv_nodes=num_conv_nodes,\r\n",
        "                          num_dense_layers=num_dense_layers,\r\n",
        "                          num_dense_nodes=num_dense_nodes)\r\n",
        "\r\n",
        "    # Aplicação do método \"fit\" para treinamento do modelo (CNN):\r\n",
        "    history = model_opt.fit(X_train2,\r\n",
        "                            Y_train2,\r\n",
        "                            batch_size = batch_size,\r\n",
        "                            epochs = epochs,\r\n",
        "                            verbose = 1,\r\n",
        "                            validation_data = (X_val2, Y_val2),\r\n",
        "                            callbacks = [histories2, earlystopping2])\r\n",
        "\r\n",
        "    # Armazenamento das métricas de validação após cada época:\r\n",
        "    # (Pode escolher qual métrica será passada para o otimizador)\r\n",
        "    # Se for a acurácia, fazer o 'return' com o valor negativo, pois o\r\n",
        "    # otimizador utilizado só consegue minimizar o custo)\r\n",
        "    accuracy = history.history['val_accuracy'][-1]\r\n",
        "    loss = history.history['val_loss'][-1] # Custo a ser minimizado!\r\n",
        "\r\n",
        "    # Visualização da acurácia durante o processo de otimização:\r\n",
        "    print('\\nAccuracy: {0:.2%}'.format(accuracy))\r\n",
        "    \r\n",
        "    # Visualização da perda (loss) durante o processo de otimização:\r\n",
        "    print('Loss:', loss, '\\n')\r\n",
        "    \r\n",
        "    # Exclusão dos dados do modelo Keras (com os hiperparâmetros) da memória:\r\n",
        "    # (Evitar que a rede \"aprenda\" de uma rodada para outra)\r\n",
        "    del model_opt\r\n",
        "    K.clear_session()\r\n",
        "    tf.keras.backend.clear_session()\r\n",
        "    tf.compat.v1.reset_default_graph()\r\n",
        "    \r\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDLUCiNi7T-G"
      },
      "source": [
        "## 6.5.Bayesian optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-m97u15AbjU"
      },
      "source": [
        "Implementation of Bayesian optimization (from Scikit-optimize) using Gaussian Processes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QraF8-aGphyj",
        "outputId": "1e008cf2-fe0a-4e6a-b559-c8a7d27219e8"
      },
      "source": [
        "# Implementação de um callback para monitorar tempo:\r\n",
        "TimerCallback = skopt.callbacks.TimerCallback()\r\n",
        "\r\n",
        "# Implementação de um callback para salvar cada iteração:\r\n",
        "# (Consultar a documentação caso necessário carregar o processo \"load\")\r\n",
        "checkpoint_saver = CheckpointSaver(\"./checkpoint.pkl\")\r\n",
        "\r\n",
        "# Instanciamento do otimizador:\r\n",
        "result = gp_minimize(func= fitness,\r\n",
        "                     dimensions= hp,\r\n",
        "                     acq_func='EI', # Função de aquisição (VIANNA, 2021).\r\n",
        "                     n_calls= 100,    # Número de iterações do otimizador!\r\n",
        "                     x0= default_parameters,\r\n",
        "                     callback= [TimerCallback, checkpoint_saver])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9891 - val_loss: 0.1954 - val_accuracy: 0.8961\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9156\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.8961\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9286\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9935\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 0.9935\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 0.9870\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9935\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9935\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9935\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9935\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.0568 - val_accuracy: 0.9870\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 158/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
            "Epoch 159/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9935\n",
            "Epoch 160/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
            "Epoch 161/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
            "Epoch 162/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 163/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 164/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 165/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 166/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00166: early stopping\n",
            "\n",
            "Accuracy: 100.00%\n",
            "Loss: 0.007027422543615103 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 2 \n",
            " num_conv_nodes: 100 \n",
            " num_dense_layers: 1 \n",
            " num_dense_nodes: 228 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 1s 21ms/step - loss: 2.8395 - accuracy: 0.4697 - val_loss: 2.6685 - val_accuracy: 0.2792\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 1.5366 - accuracy: 0.7428 - val_loss: 2.5622 - val_accuracy: 0.1818\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.7610 - accuracy: 0.8128 - val_loss: 2.6755 - val_accuracy: 0.1883\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4263 - accuracy: 0.8293 - val_loss: 2.8221 - val_accuracy: 0.0974\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2215 - accuracy: 0.9086 - val_loss: 2.9631 - val_accuracy: 0.0909\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2385 - accuracy: 0.8720 - val_loss: 3.1382 - val_accuracy: 0.0909\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2213 - accuracy: 0.8918 - val_loss: 3.3214 - val_accuracy: 0.0974\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2250 - accuracy: 0.8867 - val_loss: 3.4861 - val_accuracy: 0.1883\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2314 - accuracy: 0.8882 - val_loss: 3.6249 - val_accuracy: 0.1818\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1833 - accuracy: 0.8922 - val_loss: 3.7531 - val_accuracy: 0.1883\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2077 - accuracy: 0.8770 - val_loss: 3.8022 - val_accuracy: 0.1883\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2204 - accuracy: 0.8646 - val_loss: 3.9199 - val_accuracy: 0.1883\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1783 - accuracy: 0.9148 - val_loss: 3.9759 - val_accuracy: 0.1883\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2321 - accuracy: 0.8878 - val_loss: 3.9747 - val_accuracy: 0.1883\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1846 - accuracy: 0.8986 - val_loss: 3.9555 - val_accuracy: 0.1883\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2280 - accuracy: 0.8752 - val_loss: 4.0325 - val_accuracy: 0.1883\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.8248 - val_loss: 2.9483 - val_accuracy: 0.1623\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1982 - accuracy: 0.8703 - val_loss: 2.9550 - val_accuracy: 0.1818\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2211 - accuracy: 0.8950 - val_loss: 2.8852 - val_accuracy: 0.1818\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2247 - accuracy: 0.8761 - val_loss: 2.7451 - val_accuracy: 0.1948\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1924 - accuracy: 0.8898 - val_loss: 2.5108 - val_accuracy: 0.2338\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1724 - accuracy: 0.9016 - val_loss: 2.3972 - val_accuracy: 0.2468\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1732 - accuracy: 0.9042 - val_loss: 2.0984 - val_accuracy: 0.3636\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1824 - accuracy: 0.8901 - val_loss: 1.6326 - val_accuracy: 0.4286\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1726 - accuracy: 0.8905 - val_loss: 1.9789 - val_accuracy: 0.4026\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1775 - accuracy: 0.8820 - val_loss: 1.5460 - val_accuracy: 0.5325\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1574 - accuracy: 0.9059 - val_loss: 1.3010 - val_accuracy: 0.5779\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1892 - accuracy: 0.8814 - val_loss: 1.0580 - val_accuracy: 0.6234\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1743 - accuracy: 0.8930 - val_loss: 0.8863 - val_accuracy: 0.6299\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1479 - accuracy: 0.9104 - val_loss: 0.6573 - val_accuracy: 0.6948\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1470 - accuracy: 0.9114 - val_loss: 0.5126 - val_accuracy: 0.7403\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1769 - accuracy: 0.9048 - val_loss: 0.4244 - val_accuracy: 0.7273\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1595 - accuracy: 0.8931 - val_loss: 0.2812 - val_accuracy: 0.8506\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1593 - accuracy: 0.9076 - val_loss: 0.2240 - val_accuracy: 0.9026\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1688 - accuracy: 0.9049 - val_loss: 0.2196 - val_accuracy: 0.9610\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1563 - accuracy: 0.9046 - val_loss: 0.1843 - val_accuracy: 0.9156\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1546 - accuracy: 0.9005 - val_loss: 0.3714 - val_accuracy: 0.8766\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1846 - accuracy: 0.8878 - val_loss: 0.1696 - val_accuracy: 0.9091\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1439 - accuracy: 0.9286 - val_loss: 0.3478 - val_accuracy: 0.7987\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1769 - accuracy: 0.9007 - val_loss: 0.1433 - val_accuracy: 0.9091\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1651 - accuracy: 0.8980 - val_loss: 0.1852 - val_accuracy: 0.9026\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1633 - accuracy: 0.8939 - val_loss: 0.3324 - val_accuracy: 0.8831\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1477 - accuracy: 0.9352 - val_loss: 0.3222 - val_accuracy: 0.8896\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1484 - accuracy: 0.9169 - val_loss: 0.2873 - val_accuracy: 0.8247\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1450 - accuracy: 0.9068 - val_loss: 0.3442 - val_accuracy: 0.8247\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1530 - accuracy: 0.8923 - val_loss: 0.2404 - val_accuracy: 0.8377\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1443 - accuracy: 0.9168 - val_loss: 0.2023 - val_accuracy: 0.8377\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1383 - accuracy: 0.9142 - val_loss: 0.1661 - val_accuracy: 0.9221\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1500 - accuracy: 0.9075 - val_loss: 0.1905 - val_accuracy: 0.8636\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1546 - accuracy: 0.9162 - val_loss: 0.1824 - val_accuracy: 0.8896\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1373 - accuracy: 0.9296 - val_loss: 0.1850 - val_accuracy: 0.8571\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1389 - accuracy: 0.9121 - val_loss: 0.1583 - val_accuracy: 0.9156\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1386 - accuracy: 0.9245 - val_loss: 0.1806 - val_accuracy: 0.8896\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1621 - accuracy: 0.9169 - val_loss: 0.2225 - val_accuracy: 0.8377\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1364 - accuracy: 0.9354 - val_loss: 0.1550 - val_accuracy: 0.9091\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1264 - accuracy: 0.9462 - val_loss: 0.1353 - val_accuracy: 0.9091\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1365 - accuracy: 0.9144 - val_loss: 0.2166 - val_accuracy: 0.8442\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1448 - accuracy: 0.9205 - val_loss: 0.1416 - val_accuracy: 0.9156\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1209 - accuracy: 0.9547 - val_loss: 0.1729 - val_accuracy: 0.8766\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1305 - accuracy: 0.9345 - val_loss: 0.1773 - val_accuracy: 0.8766\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1427 - accuracy: 0.9107 - val_loss: 0.1767 - val_accuracy: 0.8701\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1424 - accuracy: 0.9196 - val_loss: 0.1744 - val_accuracy: 0.8896\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1179 - accuracy: 0.9502 - val_loss: 0.2095 - val_accuracy: 0.8766\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1480 - accuracy: 0.9271 - val_loss: 0.3004 - val_accuracy: 0.8247\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1390 - accuracy: 0.9161 - val_loss: 0.1546 - val_accuracy: 0.9156\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1372 - accuracy: 0.9424 - val_loss: 0.1309 - val_accuracy: 0.9221\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1275 - accuracy: 0.9367 - val_loss: 0.1791 - val_accuracy: 0.8701\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1335 - accuracy: 0.9653 - val_loss: 0.1380 - val_accuracy: 0.9870\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1422 - accuracy: 0.9325 - val_loss: 0.1655 - val_accuracy: 0.9091\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1323 - accuracy: 0.9267 - val_loss: 0.2834 - val_accuracy: 0.8247\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1277 - accuracy: 0.9439 - val_loss: 0.1619 - val_accuracy: 0.9156\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1548 - accuracy: 0.9231 - val_loss: 0.4899 - val_accuracy: 0.8247\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1261 - accuracy: 0.9578 - val_loss: 0.2241 - val_accuracy: 0.8377\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1326 - accuracy: 0.9360 - val_loss: 0.2065 - val_accuracy: 0.8377\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1227 - accuracy: 0.9547 - val_loss: 0.3626 - val_accuracy: 0.8247\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1209 - accuracy: 0.9266 - val_loss: 0.1339 - val_accuracy: 0.9156\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1325 - accuracy: 0.9279 - val_loss: 0.1274 - val_accuracy: 0.9870\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1254 - accuracy: 0.9454 - val_loss: 0.1492 - val_accuracy: 0.9221\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1232 - accuracy: 0.9419 - val_loss: 0.2873 - val_accuracy: 0.8247\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1306 - accuracy: 0.9497 - val_loss: 0.2123 - val_accuracy: 0.8377\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1221 - accuracy: 0.9460 - val_loss: 0.1626 - val_accuracy: 0.9156\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1265 - accuracy: 0.9354 - val_loss: 0.3144 - val_accuracy: 0.8182\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1221 - accuracy: 0.9353 - val_loss: 0.2563 - val_accuracy: 0.8961\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1322 - accuracy: 0.9354 - val_loss: 0.4115 - val_accuracy: 0.8182\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1280 - accuracy: 0.9414 - val_loss: 0.2546 - val_accuracy: 0.8312\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1153 - accuracy: 0.9599 - val_loss: 0.1925 - val_accuracy: 0.8377\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1153 - accuracy: 0.9370 - val_loss: 0.2107 - val_accuracy: 0.8377\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1107 - accuracy: 0.9671 - val_loss: 0.2474 - val_accuracy: 0.8247\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1127 - accuracy: 0.9533 - val_loss: 0.1842 - val_accuracy: 0.9221\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1130 - accuracy: 0.9765 - val_loss: 0.2173 - val_accuracy: 0.8312\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1018 - accuracy: 0.9598 - val_loss: 0.2097 - val_accuracy: 0.8442\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1223 - accuracy: 0.9632 - val_loss: 0.1760 - val_accuracy: 0.8766\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1152 - accuracy: 0.9495 - val_loss: 0.1448 - val_accuracy: 0.9935\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1111 - accuracy: 0.9660 - val_loss: 0.1191 - val_accuracy: 0.9870\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1131 - accuracy: 0.9545 - val_loss: 0.1593 - val_accuracy: 0.9026\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1230 - accuracy: 0.9484 - val_loss: 0.1914 - val_accuracy: 0.8701\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0944 - accuracy: 0.9609 - val_loss: 0.2277 - val_accuracy: 0.8377\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1050 - accuracy: 0.9639 - val_loss: 0.1849 - val_accuracy: 0.9221\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1107 - accuracy: 0.9612 - val_loss: 0.1838 - val_accuracy: 0.8636\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1121 - accuracy: 0.9533 - val_loss: 0.2814 - val_accuracy: 0.8247\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1096 - accuracy: 0.9502 - val_loss: 0.1249 - val_accuracy: 0.9870\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1329 - accuracy: 0.9641 - val_loss: 0.1266 - val_accuracy: 0.9156\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1097 - accuracy: 0.9451 - val_loss: 0.1212 - val_accuracy: 0.9156\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1087 - accuracy: 0.9598 - val_loss: 0.1539 - val_accuracy: 0.9805\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1048 - accuracy: 0.9720 - val_loss: 0.3782 - val_accuracy: 0.8182\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1136 - accuracy: 0.9581 - val_loss: 0.2245 - val_accuracy: 0.8377\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1078 - accuracy: 0.9682 - val_loss: 0.1914 - val_accuracy: 0.8506\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1210 - accuracy: 0.9569 - val_loss: 0.1361 - val_accuracy: 0.9870\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1071 - accuracy: 0.9879 - val_loss: 0.1703 - val_accuracy: 0.9481\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1124 - accuracy: 0.9796 - val_loss: 0.1669 - val_accuracy: 0.8831\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0999 - accuracy: 0.9744 - val_loss: 0.1780 - val_accuracy: 0.8701\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1093 - accuracy: 0.9707 - val_loss: 0.1647 - val_accuracy: 0.8961\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0970 - accuracy: 0.9760 - val_loss: 0.1346 - val_accuracy: 0.9675\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1064 - accuracy: 0.9787 - val_loss: 0.1244 - val_accuracy: 0.9935\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1014 - accuracy: 0.9781 - val_loss: 0.2902 - val_accuracy: 0.8247\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0977 - accuracy: 0.9702 - val_loss: 0.1190 - val_accuracy: 0.9740\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1066 - accuracy: 0.9569 - val_loss: 0.1500 - val_accuracy: 0.9156\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1074 - accuracy: 0.9630 - val_loss: 0.1469 - val_accuracy: 0.9221\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1326 - accuracy: 0.9216 - val_loss: 0.1203 - val_accuracy: 0.9870\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1089 - accuracy: 0.9817 - val_loss: 0.2480 - val_accuracy: 0.8247\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1091 - accuracy: 0.9596 - val_loss: 0.1639 - val_accuracy: 0.9545\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0987 - accuracy: 0.9772 - val_loss: 0.1450 - val_accuracy: 0.9156\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1064 - accuracy: 0.9778 - val_loss: 0.1346 - val_accuracy: 0.9870\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1099 - accuracy: 0.9852 - val_loss: 0.1387 - val_accuracy: 0.9870\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0937 - accuracy: 0.9915 - val_loss: 0.1420 - val_accuracy: 0.9870\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0990 - accuracy: 0.9995 - val_loss: 0.1348 - val_accuracy: 0.9870\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1097 - accuracy: 0.9599 - val_loss: 0.1228 - val_accuracy: 0.9935\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1016 - accuracy: 0.9852 - val_loss: 0.1323 - val_accuracy: 0.9675\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0920 - accuracy: 0.9844 - val_loss: 0.1685 - val_accuracy: 0.8831\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0979 - accuracy: 0.9806 - val_loss: 0.1481 - val_accuracy: 0.9805\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0979 - accuracy: 0.9975 - val_loss: 0.1087 - val_accuracy: 0.9870\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0914 - accuracy: 0.9718 - val_loss: 0.1210 - val_accuracy: 0.9221\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1111 - accuracy: 0.9697 - val_loss: 0.1220 - val_accuracy: 0.9221\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1042 - accuracy: 0.9590 - val_loss: 0.1189 - val_accuracy: 0.9935\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0901 - accuracy: 0.9817 - val_loss: 0.1166 - val_accuracy: 0.9935\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0950 - accuracy: 0.9911 - val_loss: 0.1553 - val_accuracy: 0.9026\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1079 - accuracy: 0.9621 - val_loss: 0.1573 - val_accuracy: 0.9610\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1144 - accuracy: 0.9724 - val_loss: 0.1095 - val_accuracy: 0.9156\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1138 - accuracy: 0.9618 - val_loss: 0.2123 - val_accuracy: 0.8831\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1000 - accuracy: 0.9690 - val_loss: 0.2375 - val_accuracy: 0.8312\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0949 - accuracy: 0.9711 - val_loss: 0.1685 - val_accuracy: 0.8831\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1001 - accuracy: 0.9683 - val_loss: 0.1400 - val_accuracy: 0.9805\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0949 - accuracy: 0.9966 - val_loss: 0.1512 - val_accuracy: 0.9740\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0929 - accuracy: 0.9935 - val_loss: 0.2059 - val_accuracy: 0.9091\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0942 - accuracy: 0.9942 - val_loss: 0.1366 - val_accuracy: 0.9221\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1157 - accuracy: 0.9749 - val_loss: 0.1422 - val_accuracy: 0.9156\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0926 - accuracy: 0.9712 - val_loss: 0.1071 - val_accuracy: 0.9935\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0906 - accuracy: 0.9980 - val_loss: 0.2129 - val_accuracy: 0.8377\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0900 - accuracy: 0.9777 - val_loss: 0.1252 - val_accuracy: 0.9221\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0863 - accuracy: 0.9818 - val_loss: 0.1456 - val_accuracy: 0.9091\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1143 - accuracy: 0.9874 - val_loss: 0.1196 - val_accuracy: 0.9935\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0892 - accuracy: 0.9785 - val_loss: 0.1489 - val_accuracy: 0.9740\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0846 - accuracy: 0.9890 - val_loss: 0.1289 - val_accuracy: 0.9870\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0844 - accuracy: 0.9843 - val_loss: 0.1195 - val_accuracy: 0.9935\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0987 - accuracy: 0.9909 - val_loss: 0.1673 - val_accuracy: 0.9481\n",
            "Epoch 156/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1008 - accuracy: 0.9932 - val_loss: 0.1278 - val_accuracy: 0.9870\n",
            "Epoch 157/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0979 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9091\n",
            "Epoch 158/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 0.9862 - val_loss: 0.1508 - val_accuracy: 0.9091\n",
            "Epoch 159/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0951 - accuracy: 0.9848 - val_loss: 0.1770 - val_accuracy: 0.9221\n",
            "Epoch 160/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1054 - accuracy: 0.9742 - val_loss: 0.1493 - val_accuracy: 0.9091\n",
            "Epoch 161/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9839 - val_loss: 0.1458 - val_accuracy: 0.9675\n",
            "Epoch 162/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0861 - accuracy: 0.9819 - val_loss: 0.1203 - val_accuracy: 0.9805\n",
            "Epoch 163/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0949 - accuracy: 0.9802 - val_loss: 0.1373 - val_accuracy: 0.9805\n",
            "Epoch 164/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0956 - accuracy: 0.9854 - val_loss: 0.2813 - val_accuracy: 0.8896\n",
            "Epoch 165/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0956 - accuracy: 0.9817 - val_loss: 0.1681 - val_accuracy: 0.9286\n",
            "Epoch 166/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0800 - accuracy: 0.9986 - val_loss: 0.1503 - val_accuracy: 0.8961\n",
            "Epoch 167/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0916 - accuracy: 0.9777 - val_loss: 0.1339 - val_accuracy: 0.9156\n",
            "Epoch 168/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0933 - accuracy: 0.9966 - val_loss: 0.1414 - val_accuracy: 0.9805\n",
            "Epoch 169/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1069 - accuracy: 0.9961 - val_loss: 0.1510 - val_accuracy: 0.9351\n",
            "Epoch 170/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0951 - accuracy: 0.9968 - val_loss: 0.1345 - val_accuracy: 0.9156\n",
            "Epoch 171/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0927 - accuracy: 0.9900 - val_loss: 0.1573 - val_accuracy: 0.9481\n",
            "Epoch 172/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0912 - accuracy: 0.9988 - val_loss: 0.1234 - val_accuracy: 0.9870\n",
            "Epoch 173/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0914 - accuracy: 0.9946 - val_loss: 0.1232 - val_accuracy: 0.9870\n",
            "Epoch 174/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9870\n",
            "Epoch 175/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0943 - accuracy: 0.9946 - val_loss: 0.1135 - val_accuracy: 0.9935\n",
            "Epoch 176/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0877 - accuracy: 0.9888 - val_loss: 0.1315 - val_accuracy: 0.9805\n",
            "Epoch 177/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0962 - accuracy: 0.9916 - val_loss: 0.1190 - val_accuracy: 0.9870\n",
            "Epoch 178/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0861 - accuracy: 0.9981 - val_loss: 0.1667 - val_accuracy: 0.9351\n",
            "Epoch 179/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0802 - accuracy: 0.9864 - val_loss: 0.1564 - val_accuracy: 0.9481\n",
            "Epoch 180/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0891 - accuracy: 0.9991 - val_loss: 0.1636 - val_accuracy: 0.9091\n",
            "Epoch 181/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0890 - accuracy: 0.9994 - val_loss: 0.1337 - val_accuracy: 0.9805\n",
            "Epoch 182/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.9977 - val_loss: 0.1245 - val_accuracy: 0.9870\n",
            "Epoch 183/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0834 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9805\n",
            "Epoch 184/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0813 - accuracy: 0.9997 - val_loss: 0.1396 - val_accuracy: 0.9740\n",
            "Epoch 185/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0942 - accuracy: 0.9961 - val_loss: 0.1368 - val_accuracy: 0.9740\n",
            "Epoch 186/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9870\n",
            "Epoch 187/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9986 - val_loss: 0.1067 - val_accuracy: 0.9935\n",
            "Epoch 188/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9935\n",
            "Epoch 189/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0843 - accuracy: 0.9977 - val_loss: 0.1051 - val_accuracy: 0.9935\n",
            "Epoch 190/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9935\n",
            "Epoch 191/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9989 - val_loss: 0.1094 - val_accuracy: 0.9935\n",
            "Epoch 192/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0939 - accuracy: 0.9968 - val_loss: 0.1140 - val_accuracy: 0.9221\n",
            "Epoch 193/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0919 - accuracy: 0.9996 - val_loss: 0.1086 - val_accuracy: 0.9935\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00193: early stopping\n",
            "\n",
            "Accuracy: 99.35%\n",
            "Loss: 0.10855510085821152 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 4 \n",
            " num_conv_nodes: 256 \n",
            " num_dense_layers: 1 \n",
            " num_dense_nodes: 16 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 2s 34ms/step - loss: 2.1416 - accuracy: 0.3569 - val_loss: 2.7351 - val_accuracy: 0.0714\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.9153 - accuracy: 0.7427 - val_loss: 2.7223 - val_accuracy: 0.0974\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.5418 - accuracy: 0.8631 - val_loss: 2.7460 - val_accuracy: 0.0260\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.3395 - accuracy: 0.8891 - val_loss: 2.7891 - val_accuracy: 0.0260\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2842 - accuracy: 0.8887 - val_loss: 2.8234 - val_accuracy: 0.0260\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2217 - accuracy: 0.8945 - val_loss: 2.8524 - val_accuracy: 0.0260\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2239 - accuracy: 0.9033 - val_loss: 2.8569 - val_accuracy: 0.0260\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1878 - accuracy: 0.9072 - val_loss: 2.8871 - val_accuracy: 0.1883\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2850 - accuracy: 0.8663 - val_loss: 2.8828 - val_accuracy: 0.1883\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2562 - accuracy: 0.8472 - val_loss: 2.8765 - val_accuracy: 0.1883\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2027 - accuracy: 0.8939 - val_loss: 2.8786 - val_accuracy: 0.0974\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2197 - accuracy: 0.8651 - val_loss: 2.8102 - val_accuracy: 0.0974\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1836 - accuracy: 0.8790 - val_loss: 2.7531 - val_accuracy: 0.1883\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1851 - accuracy: 0.8881 - val_loss: 2.7167 - val_accuracy: 0.1818\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1906 - accuracy: 0.9005 - val_loss: 2.6601 - val_accuracy: 0.1883\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1848 - accuracy: 0.9119 - val_loss: 2.5691 - val_accuracy: 0.2143\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1814 - accuracy: 0.9078 - val_loss: 2.4734 - val_accuracy: 0.2662\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1432 - accuracy: 0.9484 - val_loss: 2.3326 - val_accuracy: 0.2532\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1679 - accuracy: 0.9241 - val_loss: 2.2831 - val_accuracy: 0.2532\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1679 - accuracy: 0.9078 - val_loss: 2.1490 - val_accuracy: 0.2922\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1545 - accuracy: 0.8990 - val_loss: 2.0441 - val_accuracy: 0.3377\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1491 - accuracy: 0.9091 - val_loss: 1.8928 - val_accuracy: 0.4026\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1365 - accuracy: 0.9379 - val_loss: 1.7362 - val_accuracy: 0.4351\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1817 - accuracy: 0.8941 - val_loss: 1.7614 - val_accuracy: 0.4481\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1279 - accuracy: 0.9263 - val_loss: 1.6986 - val_accuracy: 0.4740\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2196 - accuracy: 0.9129 - val_loss: 1.3211 - val_accuracy: 0.5974\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1953 - accuracy: 0.9052 - val_loss: 1.2990 - val_accuracy: 0.6104\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2491 - accuracy: 0.9064 - val_loss: 1.0077 - val_accuracy: 0.6688\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 0.1455 - accuracy: 0.9327 - val_loss: 0.8255 - val_accuracy: 0.6299\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1380 - accuracy: 0.9602 - val_loss: 0.7052 - val_accuracy: 0.6688\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1301 - accuracy: 0.9674 - val_loss: 0.6086 - val_accuracy: 0.6883\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1288 - accuracy: 0.9257 - val_loss: 0.4771 - val_accuracy: 0.7857\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1231 - accuracy: 0.9658 - val_loss: 0.3519 - val_accuracy: 0.8117\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1343 - accuracy: 0.9358 - val_loss: 0.3478 - val_accuracy: 0.8117\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1124 - accuracy: 0.9488 - val_loss: 0.2496 - val_accuracy: 0.9481\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1282 - accuracy: 0.9409 - val_loss: 0.3384 - val_accuracy: 0.8377\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1210 - accuracy: 0.9511 - val_loss: 0.2739 - val_accuracy: 0.8442\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1462 - accuracy: 0.9288 - val_loss: 0.2059 - val_accuracy: 0.9156\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1041 - accuracy: 0.9567 - val_loss: 0.1672 - val_accuracy: 0.9870\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1040 - accuracy: 0.9734 - val_loss: 0.3550 - val_accuracy: 0.8377\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0885 - accuracy: 0.9894 - val_loss: 0.1919 - val_accuracy: 0.9351\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0848 - accuracy: 0.9810 - val_loss: 0.1348 - val_accuracy: 0.9156\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0769 - accuracy: 0.9880 - val_loss: 2.6603 - val_accuracy: 0.3766\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1419 - accuracy: 0.9507 - val_loss: 0.7298 - val_accuracy: 0.6234\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0864 - accuracy: 0.9839 - val_loss: 0.5544 - val_accuracy: 0.7208\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0659 - accuracy: 0.9898 - val_loss: 0.2835 - val_accuracy: 0.9481\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0740 - accuracy: 0.9765 - val_loss: 0.1695 - val_accuracy: 0.9740\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1192 - accuracy: 0.9644 - val_loss: 0.3069 - val_accuracy: 0.8831\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0745 - accuracy: 0.9926 - val_loss: 0.1744 - val_accuracy: 0.9286\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0633 - accuracy: 0.9877 - val_loss: 0.2446 - val_accuracy: 0.8961\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0645 - accuracy: 0.9923 - val_loss: 0.6362 - val_accuracy: 0.8247\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0657 - accuracy: 0.9829 - val_loss: 0.2776 - val_accuracy: 0.8896\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0625 - accuracy: 0.9853 - val_loss: 0.1861 - val_accuracy: 0.8831\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9351\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.8961\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9286\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9870\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0225 - accuracy: 0.9998 - val_loss: 0.2715 - val_accuracy: 0.8961\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0372 - accuracy: 0.9917 - val_loss: 0.3870 - val_accuracy: 0.8896\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.3288 - val_accuracy: 0.8961\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 0.7720 - val_accuracy: 0.8766\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0330 - accuracy: 0.9997 - val_loss: 0.1188 - val_accuracy: 0.9740\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9870\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9740\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.2907 - val_accuracy: 0.7597\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0172 - accuracy: 0.9991 - val_loss: 0.3426 - val_accuracy: 0.8961\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0164 - accuracy: 0.9992 - val_loss: 0.4518 - val_accuracy: 0.8896\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9935\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 0.9935\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9935\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9286\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9935\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9935\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 0.9935\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9740\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9481\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0079 - accuracy: 0.9998 - val_loss: 0.7136 - val_accuracy: 0.8766\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0135 - accuracy: 0.9980 - val_loss: 0.2547 - val_accuracy: 0.9026\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9026\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9026\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9091\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5787 - val_accuracy: 0.8377\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9221\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9870\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.5668 - val_accuracy: 0.8182\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9221\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 0.9997 - val_loss: 0.4587 - val_accuracy: 0.8896\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.8247\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9935\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9026\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9156\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9091\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.9935\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.8312\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9610\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9416\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9935\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.3023 - val_accuracy: 0.8896\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9286\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.8961\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9935\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 158/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
            "Epoch 159/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
            "Epoch 160/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
            "Epoch 161/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
            "Epoch 162/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
            "Epoch 163/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
            "Epoch 164/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
            "Epoch 165/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00165: early stopping\n",
            "\n",
            "Accuracy: 100.00%\n",
            "Loss: 0.029993314296007156 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 2 \n",
            " num_conv_nodes: 256 \n",
            " num_dense_layers: 3 \n",
            " num_dense_nodes: 16 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 2.6096 - accuracy: 0.1496 - val_loss: 2.7292 - val_accuracy: 0.1558\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 1.9263 - accuracy: 0.2376 - val_loss: 2.7139 - val_accuracy: 0.1818\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.6418 - accuracy: 0.4285 - val_loss: 2.6832 - val_accuracy: 0.1234\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 1.4330 - accuracy: 0.5645 - val_loss: 2.6966 - val_accuracy: 0.1234\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 1.1406 - accuracy: 0.6499 - val_loss: 2.7209 - val_accuracy: 0.1364\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.7097 - accuracy: 0.7441 - val_loss: 2.7660 - val_accuracy: 0.1364\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.8101 - accuracy: 0.7556 - val_loss: 2.8198 - val_accuracy: 0.1364\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.5085 - accuracy: 0.7939 - val_loss: 3.0422 - val_accuracy: 0.1299\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.3556 - accuracy: 0.8484 - val_loss: 3.2303 - val_accuracy: 0.1883\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.3301 - accuracy: 0.8141 - val_loss: 3.3745 - val_accuracy: 0.1883\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2859 - accuracy: 0.8593 - val_loss: 3.5008 - val_accuracy: 0.1883\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.3383 - accuracy: 0.8466 - val_loss: 3.5201 - val_accuracy: 0.1818\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.4321 - accuracy: 0.7939 - val_loss: 3.6180 - val_accuracy: 0.1818\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2769 - accuracy: 0.8501 - val_loss: 3.9291 - val_accuracy: 0.2143\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.5612 - accuracy: 0.8388 - val_loss: 3.8003 - val_accuracy: 0.2338\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2399 - accuracy: 0.8727 - val_loss: 3.7959 - val_accuracy: 0.2273\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2522 - accuracy: 0.8627 - val_loss: 3.8442 - val_accuracy: 0.1753\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.3898 - accuracy: 0.8270 - val_loss: 3.5481 - val_accuracy: 0.1688\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2291 - accuracy: 0.8771 - val_loss: 3.8149 - val_accuracy: 0.2273\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2195 - accuracy: 0.8891 - val_loss: 3.4810 - val_accuracy: 0.2403\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2381 - accuracy: 0.8611 - val_loss: 3.1029 - val_accuracy: 0.2403\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2217 - accuracy: 0.8539 - val_loss: 2.8689 - val_accuracy: 0.2792\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.2083 - accuracy: 0.8984 - val_loss: 2.6035 - val_accuracy: 0.2532\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1997 - accuracy: 0.8954 - val_loss: 2.2394 - val_accuracy: 0.3377\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2208 - accuracy: 0.8824 - val_loss: 1.8240 - val_accuracy: 0.3571\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2141 - accuracy: 0.8765 - val_loss: 1.5684 - val_accuracy: 0.4740\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1903 - accuracy: 0.8844 - val_loss: 1.1988 - val_accuracy: 0.5000\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1922 - accuracy: 0.8864 - val_loss: 1.1695 - val_accuracy: 0.5195\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2014 - accuracy: 0.8847 - val_loss: 0.7897 - val_accuracy: 0.6818\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1908 - accuracy: 0.8945 - val_loss: 0.8184 - val_accuracy: 0.7273\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2187 - accuracy: 0.8874 - val_loss: 0.6907 - val_accuracy: 0.7338\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2053 - accuracy: 0.8796 - val_loss: 0.3412 - val_accuracy: 0.7792\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2042 - accuracy: 0.8728 - val_loss: 0.2495 - val_accuracy: 0.9091\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1856 - accuracy: 0.9008 - val_loss: 0.2874 - val_accuracy: 0.8117\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1877 - accuracy: 0.8867 - val_loss: 0.7341 - val_accuracy: 0.7727\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2349 - accuracy: 0.8919 - val_loss: 0.2977 - val_accuracy: 0.7792\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1758 - accuracy: 0.8852 - val_loss: 0.2456 - val_accuracy: 0.8377\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1718 - accuracy: 0.9010 - val_loss: 0.2139 - val_accuracy: 0.8442\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1611 - accuracy: 0.9106 - val_loss: 0.1833 - val_accuracy: 0.9026\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1779 - accuracy: 0.8844 - val_loss: 0.1949 - val_accuracy: 0.8636\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1721 - accuracy: 0.8947 - val_loss: 0.2078 - val_accuracy: 0.8377\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1856 - accuracy: 0.8798 - val_loss: 0.2616 - val_accuracy: 0.8312\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1752 - accuracy: 0.8880 - val_loss: 0.2309 - val_accuracy: 0.8442\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1682 - accuracy: 0.9083 - val_loss: 0.1982 - val_accuracy: 0.8506\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1620 - accuracy: 0.9101 - val_loss: 0.2406 - val_accuracy: 0.8377\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1907 - accuracy: 0.8712 - val_loss: 0.3222 - val_accuracy: 0.7857\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1955 - accuracy: 0.8904 - val_loss: 0.1722 - val_accuracy: 0.9026\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1766 - accuracy: 0.8948 - val_loss: 0.1666 - val_accuracy: 0.9091\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1832 - accuracy: 0.8907 - val_loss: 0.2085 - val_accuracy: 0.8442\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.1647 - accuracy: 0.8995 - val_loss: 0.2253 - val_accuracy: 0.8442\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1853 - accuracy: 0.8987 - val_loss: 0.1685 - val_accuracy: 0.9091\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1869 - accuracy: 0.8744 - val_loss: 0.1642 - val_accuracy: 0.9091\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1816 - accuracy: 0.8992 - val_loss: 0.1665 - val_accuracy: 0.9221\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1659 - accuracy: 0.9040 - val_loss: 0.1988 - val_accuracy: 0.8442\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1913 - accuracy: 0.8796 - val_loss: 0.1907 - val_accuracy: 0.8636\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1544 - accuracy: 0.9109 - val_loss: 0.2128 - val_accuracy: 0.8701\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1812 - accuracy: 0.9079 - val_loss: 0.1929 - val_accuracy: 0.8506\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1830 - accuracy: 0.8974 - val_loss: 0.1579 - val_accuracy: 0.9221\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1739 - accuracy: 0.9012 - val_loss: 0.2286 - val_accuracy: 0.8312\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1791 - accuracy: 0.8899 - val_loss: 0.1759 - val_accuracy: 0.9091\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1769 - accuracy: 0.8834 - val_loss: 0.1985 - val_accuracy: 0.8442\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1515 - accuracy: 0.9071 - val_loss: 0.2435 - val_accuracy: 0.8377\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1492 - accuracy: 0.9185 - val_loss: 0.2349 - val_accuracy: 0.8247\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1761 - accuracy: 0.8959 - val_loss: 0.2107 - val_accuracy: 0.8442\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1628 - accuracy: 0.9032 - val_loss: 0.2618 - val_accuracy: 0.8377\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1605 - accuracy: 0.9011 - val_loss: 0.2157 - val_accuracy: 0.8377\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1639 - accuracy: 0.8932 - val_loss: 0.2540 - val_accuracy: 0.8247\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1584 - accuracy: 0.8941 - val_loss: 0.1802 - val_accuracy: 0.9156\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1541 - accuracy: 0.9205 - val_loss: 0.3258 - val_accuracy: 0.8312\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1743 - accuracy: 0.8862 - val_loss: 0.1554 - val_accuracy: 0.9156\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1700 - accuracy: 0.8928 - val_loss: 0.2139 - val_accuracy: 0.8377\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1654 - accuracy: 0.8961 - val_loss: 0.2344 - val_accuracy: 0.8247\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1513 - accuracy: 0.9084 - val_loss: 0.2023 - val_accuracy: 0.8442\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1589 - accuracy: 0.9232 - val_loss: 0.2073 - val_accuracy: 0.8377\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1523 - accuracy: 0.9043 - val_loss: 0.2391 - val_accuracy: 0.8961\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1670 - accuracy: 0.9188 - val_loss: 0.2118 - val_accuracy: 0.8442\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.1737 - accuracy: 0.9008 - val_loss: 0.2297 - val_accuracy: 0.8377\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1741 - accuracy: 0.8845 - val_loss: 0.2302 - val_accuracy: 0.8312\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1616 - accuracy: 0.9103 - val_loss: 0.1941 - val_accuracy: 0.8442\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1681 - accuracy: 0.9236 - val_loss: 0.2179 - val_accuracy: 0.8377\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1593 - accuracy: 0.9072 - val_loss: 0.1894 - val_accuracy: 0.8506\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1627 - accuracy: 0.9074 - val_loss: 0.2273 - val_accuracy: 0.8442\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1668 - accuracy: 0.8954 - val_loss: 0.1919 - val_accuracy: 0.8442\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1749 - accuracy: 0.9058 - val_loss: 0.2095 - val_accuracy: 0.8442\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1647 - accuracy: 0.9033 - val_loss: 0.1928 - val_accuracy: 0.8442\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1668 - accuracy: 0.9110 - val_loss: 0.2279 - val_accuracy: 0.8377\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1601 - accuracy: 0.8906 - val_loss: 0.2121 - val_accuracy: 0.8442\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1676 - accuracy: 0.8810 - val_loss: 0.1699 - val_accuracy: 0.9221\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1460 - accuracy: 0.9182 - val_loss: 0.1572 - val_accuracy: 0.9156\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1626 - accuracy: 0.9026 - val_loss: 0.1632 - val_accuracy: 0.9091\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1781 - accuracy: 0.8915 - val_loss: 0.2182 - val_accuracy: 0.8377\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1625 - accuracy: 0.9137 - val_loss: 0.2442 - val_accuracy: 0.8377\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1627 - accuracy: 0.9052 - val_loss: 0.1844 - val_accuracy: 0.8506\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1557 - accuracy: 0.8905 - val_loss: 0.2429 - val_accuracy: 0.8312\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1736 - accuracy: 0.8863 - val_loss: 0.1931 - val_accuracy: 0.8442\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1607 - accuracy: 0.8995 - val_loss: 0.1616 - val_accuracy: 0.9156\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1622 - accuracy: 0.9066 - val_loss: 0.1750 - val_accuracy: 0.9221\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1523 - accuracy: 0.9165 - val_loss: 0.1977 - val_accuracy: 0.8442\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1555 - accuracy: 0.9272 - val_loss: 0.1839 - val_accuracy: 0.8636\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1637 - accuracy: 0.9173 - val_loss: 0.1797 - val_accuracy: 0.8766\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1562 - accuracy: 0.9109 - val_loss: 0.2056 - val_accuracy: 0.8442\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1450 - accuracy: 0.9027 - val_loss: 0.1751 - val_accuracy: 0.9091\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1523 - accuracy: 0.9160 - val_loss: 0.1867 - val_accuracy: 0.8766\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.1435 - accuracy: 0.9303 - val_loss: 0.1984 - val_accuracy: 0.8442\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1703 - accuracy: 0.9064 - val_loss: 0.1749 - val_accuracy: 0.9091\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1524 - accuracy: 0.9072 - val_loss: 0.1963 - val_accuracy: 0.8442\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1705 - accuracy: 0.8881 - val_loss: 0.2025 - val_accuracy: 0.8442\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1614 - accuracy: 0.9012 - val_loss: 0.1660 - val_accuracy: 0.9156\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1511 - accuracy: 0.9052 - val_loss: 0.1957 - val_accuracy: 0.8442\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1795 - accuracy: 0.9221 - val_loss: 0.2158 - val_accuracy: 0.8377\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1393 - accuracy: 0.9344 - val_loss: 0.2169 - val_accuracy: 0.8312\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1389 - accuracy: 0.9295 - val_loss: 0.1694 - val_accuracy: 0.9870\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1464 - accuracy: 0.9165 - val_loss: 0.1781 - val_accuracy: 0.8961\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1575 - accuracy: 0.8918 - val_loss: 0.1879 - val_accuracy: 0.8506\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1522 - accuracy: 0.9144 - val_loss: 0.2452 - val_accuracy: 0.8377\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1492 - accuracy: 0.9040 - val_loss: 0.2046 - val_accuracy: 0.8506\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1376 - accuracy: 0.9316 - val_loss: 0.2032 - val_accuracy: 0.8442\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9214 - val_loss: 0.1795 - val_accuracy: 0.8766\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1557 - accuracy: 0.9148 - val_loss: 0.1903 - val_accuracy: 0.8442\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1435 - accuracy: 0.9373 - val_loss: 0.1895 - val_accuracy: 0.8442\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1430 - accuracy: 0.9109 - val_loss: 0.1773 - val_accuracy: 0.8831\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1523 - accuracy: 0.9118 - val_loss: 0.1759 - val_accuracy: 0.8961\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1561 - accuracy: 0.9173 - val_loss: 0.1871 - val_accuracy: 0.8442\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1477 - accuracy: 0.9283 - val_loss: 0.1905 - val_accuracy: 0.8442\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1467 - accuracy: 0.9139 - val_loss: 0.1805 - val_accuracy: 0.8701\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1557 - accuracy: 0.9130 - val_loss: 0.1959 - val_accuracy: 0.8377\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1422 - accuracy: 0.9438 - val_loss: 0.2021 - val_accuracy: 0.8506\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1430 - accuracy: 0.9027 - val_loss: 0.2034 - val_accuracy: 0.8442\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1401 - accuracy: 0.9287 - val_loss: 0.1807 - val_accuracy: 0.8701\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1527 - accuracy: 0.9040 - val_loss: 0.2019 - val_accuracy: 0.8442\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.1510 - accuracy: 0.9178 - val_loss: 0.1871 - val_accuracy: 0.8506\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1375 - accuracy: 0.9423 - val_loss: 0.1931 - val_accuracy: 0.8442\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1428 - accuracy: 0.9257 - val_loss: 0.1923 - val_accuracy: 0.8442\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1665 - accuracy: 0.9084 - val_loss: 0.1651 - val_accuracy: 0.9221\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1487 - accuracy: 0.9252 - val_loss: 0.1750 - val_accuracy: 0.9026\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1582 - accuracy: 0.9244 - val_loss: 0.1809 - val_accuracy: 0.8766\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1637 - accuracy: 0.9059 - val_loss: 0.1840 - val_accuracy: 0.8636\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1494 - accuracy: 0.9286 - val_loss: 0.1814 - val_accuracy: 0.8766\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1467 - accuracy: 0.9089 - val_loss: 0.1753 - val_accuracy: 0.9026\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1390 - accuracy: 0.9264 - val_loss: 0.1857 - val_accuracy: 0.8506\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1654 - accuracy: 0.9182 - val_loss: 0.1935 - val_accuracy: 0.8442\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1626 - accuracy: 0.9155 - val_loss: 0.1821 - val_accuracy: 0.8701\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1660 - accuracy: 0.9064 - val_loss: 0.1938 - val_accuracy: 0.8442\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1422 - accuracy: 0.9165 - val_loss: 0.1748 - val_accuracy: 0.9026\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1672 - accuracy: 0.8906 - val_loss: 0.1789 - val_accuracy: 0.8766\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1417 - accuracy: 0.9258 - val_loss: 0.1804 - val_accuracy: 0.9221\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1418 - accuracy: 0.9227 - val_loss: 0.1933 - val_accuracy: 0.9091\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1598 - accuracy: 0.9125 - val_loss: 0.1987 - val_accuracy: 0.9026\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1537 - accuracy: 0.9194 - val_loss: 0.2133 - val_accuracy: 0.8442\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1410 - accuracy: 0.9106 - val_loss: 0.1733 - val_accuracy: 0.9156\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1577 - accuracy: 0.8987 - val_loss: 0.2113 - val_accuracy: 0.8442\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1331 - accuracy: 0.9239 - val_loss: 0.1901 - val_accuracy: 0.8442\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1428 - accuracy: 0.9034 - val_loss: 0.1940 - val_accuracy: 0.8377\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1391 - accuracy: 0.9395 - val_loss: 0.1871 - val_accuracy: 0.8442\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1385 - accuracy: 0.9251 - val_loss: 0.1992 - val_accuracy: 0.8377\n",
            "Epoch 156/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1424 - accuracy: 0.9274 - val_loss: 0.1812 - val_accuracy: 0.8636\n",
            "Epoch 157/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1526 - accuracy: 0.9231 - val_loss: 0.1830 - val_accuracy: 0.8571\n",
            "Epoch 158/500\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.1636 - accuracy: 0.9139 - val_loss: 0.1971 - val_accuracy: 0.8442\n",
            "Epoch 159/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1404 - accuracy: 0.9352 - val_loss: 0.2075 - val_accuracy: 0.8506\n",
            "Epoch 160/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1558 - accuracy: 0.9363 - val_loss: 0.2107 - val_accuracy: 0.8506\n",
            "Epoch 161/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1463 - accuracy: 0.9327 - val_loss: 0.1960 - val_accuracy: 0.8442\n",
            "Epoch 162/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1617 - accuracy: 0.9109 - val_loss: 0.2087 - val_accuracy: 0.8442\n",
            "Epoch 163/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1486 - accuracy: 0.9289 - val_loss: 0.1766 - val_accuracy: 0.8961\n",
            "Epoch 164/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1422 - accuracy: 0.9331 - val_loss: 0.1722 - val_accuracy: 0.9156\n",
            "Epoch 165/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1593 - accuracy: 0.9209 - val_loss: 0.1647 - val_accuracy: 0.9221\n",
            "Epoch 166/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1423 - accuracy: 0.9351 - val_loss: 0.1861 - val_accuracy: 0.8506\n",
            "Epoch 167/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1533 - accuracy: 0.9295 - val_loss: 0.1908 - val_accuracy: 0.8442\n",
            "Epoch 168/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1453 - accuracy: 0.9056 - val_loss: 0.1847 - val_accuracy: 0.8571\n",
            "Epoch 169/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1496 - accuracy: 0.9153 - val_loss: 0.1747 - val_accuracy: 0.9091\n",
            "Epoch 170/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1644 - accuracy: 0.9298 - val_loss: 0.1781 - val_accuracy: 0.8961\n",
            "Epoch 171/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1439 - accuracy: 0.8979 - val_loss: 0.1920 - val_accuracy: 0.8442\n",
            "Epoch 172/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1491 - accuracy: 0.9414 - val_loss: 0.1944 - val_accuracy: 0.8442\n",
            "Epoch 173/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1590 - accuracy: 0.9256 - val_loss: 0.1843 - val_accuracy: 0.8636\n",
            "Epoch 174/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1361 - accuracy: 0.9398 - val_loss: 0.1868 - val_accuracy: 0.8442\n",
            "Epoch 175/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1446 - accuracy: 0.9240 - val_loss: 0.1781 - val_accuracy: 0.8961\n",
            "Epoch 176/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1308 - accuracy: 0.9437 - val_loss: 0.1820 - val_accuracy: 0.8701\n",
            "Epoch 177/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1591 - accuracy: 0.9268 - val_loss: 0.1913 - val_accuracy: 0.8442\n",
            "Epoch 178/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1354 - accuracy: 0.9318 - val_loss: 0.1588 - val_accuracy: 0.9156\n",
            "Epoch 179/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1408 - accuracy: 0.9304 - val_loss: 0.1622 - val_accuracy: 0.9221\n",
            "Epoch 180/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1655 - accuracy: 0.8949 - val_loss: 0.1698 - val_accuracy: 0.9156\n",
            "Epoch 181/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1441 - accuracy: 0.9359 - val_loss: 0.1745 - val_accuracy: 0.9156\n",
            "Epoch 182/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1477 - accuracy: 0.9367 - val_loss: 0.1893 - val_accuracy: 0.8377\n",
            "Epoch 183/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1531 - accuracy: 0.9202 - val_loss: 0.1729 - val_accuracy: 0.9091\n",
            "Epoch 184/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1680 - accuracy: 0.9171 - val_loss: 0.1713 - val_accuracy: 0.9091\n",
            "Epoch 185/500\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.1428 - accuracy: 0.9297 - val_loss: 0.1867 - val_accuracy: 0.8377\n",
            "Epoch 186/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1576 - accuracy: 0.9187 - val_loss: 0.1864 - val_accuracy: 0.8377\n",
            "Epoch 187/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1263 - accuracy: 0.9291 - val_loss: 0.1889 - val_accuracy: 0.8377\n",
            "Epoch 188/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1384 - accuracy: 0.9253 - val_loss: 0.1887 - val_accuracy: 0.8377\n",
            "Epoch 189/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1331 - accuracy: 0.9387 - val_loss: 0.1934 - val_accuracy: 0.8701\n",
            "Epoch 190/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1623 - accuracy: 0.8958 - val_loss: 0.1856 - val_accuracy: 0.8442\n",
            "Epoch 191/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1444 - accuracy: 0.9383 - val_loss: 0.1885 - val_accuracy: 0.8442\n",
            "Epoch 192/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1596 - accuracy: 0.9193 - val_loss: 0.1954 - val_accuracy: 0.8442\n",
            "Epoch 193/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1505 - accuracy: 0.9384 - val_loss: 0.2027 - val_accuracy: 0.8442\n",
            "Epoch 194/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1477 - accuracy: 0.9212 - val_loss: 0.2035 - val_accuracy: 0.8766\n",
            "Epoch 195/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1366 - accuracy: 0.9433 - val_loss: 0.1920 - val_accuracy: 0.8377\n",
            "Epoch 196/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1430 - accuracy: 0.9140 - val_loss: 0.2012 - val_accuracy: 0.8377\n",
            "Epoch 197/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1305 - accuracy: 0.9326 - val_loss: 0.1888 - val_accuracy: 0.8377\n",
            "Epoch 198/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1478 - accuracy: 0.9167 - val_loss: 0.1859 - val_accuracy: 0.8442\n",
            "Epoch 199/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1407 - accuracy: 0.9144 - val_loss: 0.1904 - val_accuracy: 0.8377\n",
            "Epoch 200/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1559 - accuracy: 0.9091 - val_loss: 0.1862 - val_accuracy: 0.8377\n",
            "Epoch 201/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1370 - accuracy: 0.9350 - val_loss: 0.1847 - val_accuracy: 0.9156\n",
            "Epoch 202/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1394 - accuracy: 0.9316 - val_loss: 0.1837 - val_accuracy: 0.8442\n",
            "Epoch 203/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1505 - accuracy: 0.9297 - val_loss: 0.1880 - val_accuracy: 0.8377\n",
            "Epoch 204/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1274 - accuracy: 0.9315 - val_loss: 0.1789 - val_accuracy: 0.8896\n",
            "Epoch 205/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1467 - accuracy: 0.9168 - val_loss: 0.1849 - val_accuracy: 0.8442\n",
            "Epoch 206/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1339 - accuracy: 0.9346 - val_loss: 0.1912 - val_accuracy: 0.8377\n",
            "Epoch 207/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1468 - accuracy: 0.9352 - val_loss: 0.1916 - val_accuracy: 0.9091\n",
            "Epoch 208/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1529 - accuracy: 0.9087 - val_loss: 0.1829 - val_accuracy: 0.8636\n",
            "Epoch 209/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1472 - accuracy: 0.9203 - val_loss: 0.1831 - val_accuracy: 0.8636\n",
            "Epoch 210/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1460 - accuracy: 0.9285 - val_loss: 0.1843 - val_accuracy: 0.8506\n",
            "Epoch 211/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1411 - accuracy: 0.9203 - val_loss: 0.1769 - val_accuracy: 0.8961\n",
            "Epoch 212/500\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.1362 - accuracy: 0.9222 - val_loss: 0.1808 - val_accuracy: 0.8766\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00212: early stopping\n",
            "\n",
            "Accuracy: 87.66%\n",
            "Loss: 0.18079975247383118 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 3 \n",
            " num_conv_nodes: 72 \n",
            " num_dense_layers: 3 \n",
            " num_dense_nodes: 256 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 1s 22ms/step - loss: 1.9764 - accuracy: 0.4768 - val_loss: 2.7401 - val_accuracy: 0.1623\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.7284 - accuracy: 0.8432 - val_loss: 2.7385 - val_accuracy: 0.1558\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4545 - accuracy: 0.8307 - val_loss: 2.7376 - val_accuracy: 0.0909\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2997 - accuracy: 0.8821 - val_loss: 2.7481 - val_accuracy: 0.0909\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3818 - accuracy: 0.8406 - val_loss: 2.7528 - val_accuracy: 0.0909\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2454 - accuracy: 0.8974 - val_loss: 2.7762 - val_accuracy: 0.0909\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2503 - accuracy: 0.8696 - val_loss: 2.7849 - val_accuracy: 0.0909\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2183 - accuracy: 0.8926 - val_loss: 2.7877 - val_accuracy: 0.0909\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2203 - accuracy: 0.9090 - val_loss: 2.7926 - val_accuracy: 0.1558\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2457 - accuracy: 0.8844 - val_loss: 2.7686 - val_accuracy: 0.1558\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1996 - accuracy: 0.8926 - val_loss: 2.7341 - val_accuracy: 0.1558\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1831 - accuracy: 0.9124 - val_loss: 2.7081 - val_accuracy: 0.1623\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1774 - accuracy: 0.9055 - val_loss: 2.6762 - val_accuracy: 0.2013\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2759 - accuracy: 0.8606 - val_loss: 2.6026 - val_accuracy: 0.2143\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1937 - accuracy: 0.9090 - val_loss: 2.5705 - val_accuracy: 0.2273\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1842 - accuracy: 0.9044 - val_loss: 2.4689 - val_accuracy: 0.2338\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1829 - accuracy: 0.8907 - val_loss: 2.4291 - val_accuracy: 0.2403\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1755 - accuracy: 0.9017 - val_loss: 2.3282 - val_accuracy: 0.2338\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1881 - accuracy: 0.8935 - val_loss: 2.2437 - val_accuracy: 0.1818\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1758 - accuracy: 0.9184 - val_loss: 2.3034 - val_accuracy: 0.2143\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2101 - accuracy: 0.8719 - val_loss: 2.0946 - val_accuracy: 0.2403\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1593 - accuracy: 0.9315 - val_loss: 1.9807 - val_accuracy: 0.2403\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1467 - accuracy: 0.9261 - val_loss: 1.8177 - val_accuracy: 0.2532\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.1724 - accuracy: 0.9013 - val_loss: 1.6066 - val_accuracy: 0.3506\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1380 - accuracy: 0.9482 - val_loss: 1.4727 - val_accuracy: 0.4545\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1499 - accuracy: 0.9262 - val_loss: 1.7427 - val_accuracy: 0.4545\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1968 - accuracy: 0.9151 - val_loss: 1.0604 - val_accuracy: 0.6169\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1503 - accuracy: 0.9346 - val_loss: 0.8219 - val_accuracy: 0.7078\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1337 - accuracy: 0.9397 - val_loss: 0.7809 - val_accuracy: 0.7143\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1185 - accuracy: 0.9335 - val_loss: 0.4647 - val_accuracy: 0.8117\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1188 - accuracy: 0.9600 - val_loss: 0.4430 - val_accuracy: 0.8506\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1115 - accuracy: 0.9495 - val_loss: 0.3775 - val_accuracy: 0.8182\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0996 - accuracy: 0.9691 - val_loss: 0.2994 - val_accuracy: 0.9481\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1062 - accuracy: 0.9630 - val_loss: 0.3244 - val_accuracy: 0.8701\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0970 - accuracy: 0.9630 - val_loss: 0.6822 - val_accuracy: 0.7273\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1519 - accuracy: 0.9267 - val_loss: 0.2787 - val_accuracy: 0.8312\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0927 - accuracy: 0.9490 - val_loss: 0.4509 - val_accuracy: 0.9416\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0787 - accuracy: 0.9828 - val_loss: 0.3652 - val_accuracy: 0.8896\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1003 - accuracy: 0.9498 - val_loss: 0.8703 - val_accuracy: 0.6753\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0832 - accuracy: 0.9769 - val_loss: 0.7531 - val_accuracy: 0.8117\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1669 - accuracy: 0.9341 - val_loss: 0.6784 - val_accuracy: 0.8247\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2173 - accuracy: 0.9255 - val_loss: 0.5933 - val_accuracy: 0.8831\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1007 - accuracy: 0.9625 - val_loss: 0.4605 - val_accuracy: 0.8247\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0921 - accuracy: 0.9696 - val_loss: 0.5657 - val_accuracy: 0.7662\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0702 - accuracy: 0.9638 - val_loss: 0.5266 - val_accuracy: 0.8182\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0792 - accuracy: 0.9679 - val_loss: 2.8698 - val_accuracy: 0.4221\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1062 - accuracy: 0.9674 - val_loss: 0.8875 - val_accuracy: 0.7792\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0636 - accuracy: 0.9881 - val_loss: 0.8477 - val_accuracy: 0.8312\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0608 - accuracy: 0.9970 - val_loss: 2.3249 - val_accuracy: 0.5065\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0626 - accuracy: 0.9944 - val_loss: 2.2210 - val_accuracy: 0.4870\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0570 - accuracy: 0.9920 - val_loss: 1.0043 - val_accuracy: 0.7792\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0522 - accuracy: 0.9948 - val_loss: 0.6410 - val_accuracy: 0.7403\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0484 - accuracy: 0.9954 - val_loss: 1.3726 - val_accuracy: 0.7403\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0504 - accuracy: 0.9978 - val_loss: 0.9717 - val_accuracy: 0.7597\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9977 - val_loss: 0.1087 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0359 - accuracy: 0.9934 - val_loss: 1.6419 - val_accuracy: 0.6623\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 1.3097 - val_accuracy: 0.7532\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9156\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9935\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.7922\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.3554 - val_accuracy: 0.7597\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.8896\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9610\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.8052\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9156\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9870\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9286\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 0.9977 - val_loss: 0.0744 - val_accuracy: 0.9870\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9870\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9946 - val_loss: 2.7850 - val_accuracy: 0.5195\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.4531 - val_accuracy: 0.6883\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.9796 - val_accuracy: 0.7857\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.8571\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.5538 - val_accuracy: 0.7857\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.8831\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5175 - val_accuracy: 0.8312\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9870\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9416\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 0.9998 - val_loss: 6.7583 - val_accuracy: 0.3117\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.4347 - val_accuracy: 0.7597\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9870\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0207 - accuracy: 0.9998 - val_loss: 0.2545 - val_accuracy: 0.8701\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0097 - accuracy: 0.9998 - val_loss: 0.1547 - val_accuracy: 0.9805\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9935\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9416\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9935\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9935\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.4961 - val_accuracy: 0.7727\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.8701\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0319 - val_accuracy: 0.9870\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9935\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9935\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9870\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9870\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9935\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9870\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9935\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00155: early stopping\n",
            "\n",
            "Accuracy: 100.00%\n",
            "Loss: 0.006251691374927759 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 4 \n",
            " num_conv_nodes: 79 \n",
            " num_dense_layers: 3 \n",
            " num_dense_nodes: 236 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 2s 29ms/step - loss: 2.2927 - accuracy: 0.3271 - val_loss: 2.7594 - val_accuracy: 0.0974\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.9816 - accuracy: 0.7995 - val_loss: 2.7510 - val_accuracy: 0.0974\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.5084 - accuracy: 0.8678 - val_loss: 2.7461 - val_accuracy: 0.0974\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3395 - accuracy: 0.8821 - val_loss: 2.7474 - val_accuracy: 0.0260\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3286 - accuracy: 0.8640 - val_loss: 2.7460 - val_accuracy: 0.0260\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.2933 - accuracy: 0.8718 - val_loss: 2.7548 - val_accuracy: 0.0260\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.2376 - accuracy: 0.8743 - val_loss: 2.7400 - val_accuracy: 0.0260\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.2965 - accuracy: 0.8745 - val_loss: 2.7543 - val_accuracy: 0.1169\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1948 - accuracy: 0.9157 - val_loss: 2.7312 - val_accuracy: 0.0909\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2031 - accuracy: 0.9028 - val_loss: 2.7328 - val_accuracy: 0.0909\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1998 - accuracy: 0.9047 - val_loss: 2.7367 - val_accuracy: 0.1429\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2061 - accuracy: 0.9112 - val_loss: 2.6584 - val_accuracy: 0.2338\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1985 - accuracy: 0.9006 - val_loss: 2.6103 - val_accuracy: 0.2273\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1994 - accuracy: 0.8935 - val_loss: 2.5743 - val_accuracy: 0.2338\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.1764 - accuracy: 0.9128 - val_loss: 2.5470 - val_accuracy: 0.1688\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.1871 - accuracy: 0.9214 - val_loss: 2.4226 - val_accuracy: 0.2273\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.1716 - accuracy: 0.9187 - val_loss: 2.4385 - val_accuracy: 0.2468\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.1700 - accuracy: 0.9326 - val_loss: 2.2644 - val_accuracy: 0.2662\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1626 - accuracy: 0.9196 - val_loss: 2.0624 - val_accuracy: 0.2792\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1594 - accuracy: 0.9156 - val_loss: 1.9940 - val_accuracy: 0.3312\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1544 - accuracy: 0.9310 - val_loss: 1.9026 - val_accuracy: 0.4026\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1771 - accuracy: 0.8971 - val_loss: 1.7798 - val_accuracy: 0.3701\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.1445 - accuracy: 0.9421 - val_loss: 1.8859 - val_accuracy: 0.3052\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1456 - accuracy: 0.9207 - val_loss: 1.4795 - val_accuracy: 0.6104\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.1264 - accuracy: 0.9562 - val_loss: 1.3998 - val_accuracy: 0.5649\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1247 - accuracy: 0.9552 - val_loss: 1.4179 - val_accuracy: 0.5714\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.1238 - accuracy: 0.9482 - val_loss: 1.0728 - val_accuracy: 0.6234\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1080 - accuracy: 0.9732 - val_loss: 0.9587 - val_accuracy: 0.8182\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1227 - accuracy: 0.9522 - val_loss: 0.7094 - val_accuracy: 0.8506\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1078 - accuracy: 0.9538 - val_loss: 0.6309 - val_accuracy: 0.8247\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0999 - accuracy: 0.9655 - val_loss: 0.6086 - val_accuracy: 0.8506\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1060 - accuracy: 0.9629 - val_loss: 0.9919 - val_accuracy: 0.6364\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1133 - accuracy: 0.9705 - val_loss: 0.5220 - val_accuracy: 0.8117\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0691 - accuracy: 0.9937 - val_loss: 0.4452 - val_accuracy: 0.7922\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0759 - accuracy: 0.9810 - val_loss: 0.4040 - val_accuracy: 0.8831\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1168 - accuracy: 0.9519 - val_loss: 0.2655 - val_accuracy: 0.9026\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0816 - accuracy: 0.9812 - val_loss: 0.5460 - val_accuracy: 0.8506\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1089 - accuracy: 0.9498 - val_loss: 0.2590 - val_accuracy: 0.9740\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0790 - accuracy: 0.9806 - val_loss: 0.2070 - val_accuracy: 0.9545\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0841 - accuracy: 0.9734 - val_loss: 0.3558 - val_accuracy: 0.9026\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0749 - accuracy: 0.9885 - val_loss: 0.8275 - val_accuracy: 0.7532\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.8831\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0390 - accuracy: 0.9998 - val_loss: 1.8253 - val_accuracy: 0.4481\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0607 - accuracy: 0.9872 - val_loss: 1.0189 - val_accuracy: 0.6623\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.7078\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.8926 - val_accuracy: 0.7727\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 1.4211 - val_accuracy: 0.6753\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.7556 - val_accuracy: 0.7597\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 0.8312\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9935\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0172 - accuracy: 0.9998 - val_loss: 0.1620 - val_accuracy: 0.9545\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9286\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0461 - accuracy: 0.9816 - val_loss: 0.1434 - val_accuracy: 0.9870\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9870\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9221\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9156\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9935\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9675\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9610\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0120 - accuracy: 0.9998 - val_loss: 1.4597 - val_accuracy: 0.5714\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0647 - accuracy: 0.9874 - val_loss: 0.7080 - val_accuracy: 0.7338\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9610\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 0.9805\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0126 - accuracy: 0.9998 - val_loss: 0.7003 - val_accuracy: 0.7597\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0252 - accuracy: 0.9944 - val_loss: 0.2513 - val_accuracy: 0.9156\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 0.9998 - val_loss: 0.5642 - val_accuracy: 0.8052\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.8117\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.4891 - val_accuracy: 0.8896\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.8896\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.9940 - val_accuracy: 0.7338\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.6181 - val_accuracy: 0.8896\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.4785 - val_accuracy: 0.8961\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.8961\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.8961\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.8961\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.3148 - val_accuracy: 0.9026\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.8312\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9675\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9805\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9805\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9805\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9870\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.4568 - val_accuracy: 0.6169\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9935\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9935\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9935\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9870\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9870\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9416\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9935\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.5620 - val_accuracy: 0.5909\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.7987\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9805\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9870\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9870\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9935\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 0.9805\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9870\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9481\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 0.9998 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9675\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9870\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00152: early stopping\n",
            "\n",
            "Accuracy: 98.70%\n",
            "Loss: 0.05166434124112129 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 3 \n",
            " num_conv_nodes: 62 \n",
            " num_dense_layers: 2 \n",
            " num_dense_nodes: 256 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 2s 35ms/step - loss: 2.0164 - accuracy: 0.4337 - val_loss: 2.7253 - val_accuracy: 0.1429\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6075 - accuracy: 0.8326 - val_loss: 2.7230 - val_accuracy: 0.1364\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4342 - accuracy: 0.8445 - val_loss: 2.7401 - val_accuracy: 0.0260\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3487 - accuracy: 0.8627 - val_loss: 2.7646 - val_accuracy: 0.0260\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2815 - accuracy: 0.8657 - val_loss: 2.7735 - val_accuracy: 0.1169\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2180 - accuracy: 0.8988 - val_loss: 2.7778 - val_accuracy: 0.1688\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2398 - accuracy: 0.9039 - val_loss: 2.8297 - val_accuracy: 0.0779\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2129 - accuracy: 0.8873 - val_loss: 2.7977 - val_accuracy: 0.1494\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2626 - accuracy: 0.8917 - val_loss: 2.8010 - val_accuracy: 0.1494\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1953 - accuracy: 0.8975 - val_loss: 2.8008 - val_accuracy: 0.1429\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1962 - accuracy: 0.9038 - val_loss: 2.7573 - val_accuracy: 0.1429\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1896 - accuracy: 0.9007 - val_loss: 2.7625 - val_accuracy: 0.1429\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2519 - accuracy: 0.8854 - val_loss: 2.7121 - val_accuracy: 0.1494\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1725 - accuracy: 0.8997 - val_loss: 2.6919 - val_accuracy: 0.1429\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1999 - accuracy: 0.8987 - val_loss: 2.6504 - val_accuracy: 0.2143\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1738 - accuracy: 0.9184 - val_loss: 2.5690 - val_accuracy: 0.1494\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1816 - accuracy: 0.8928 - val_loss: 2.4201 - val_accuracy: 0.2143\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1679 - accuracy: 0.9124 - val_loss: 2.2567 - val_accuracy: 0.1494\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1364 - accuracy: 0.9483 - val_loss: 2.2614 - val_accuracy: 0.1494\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1302 - accuracy: 0.9676 - val_loss: 2.0611 - val_accuracy: 0.1494\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1797 - accuracy: 0.9221 - val_loss: 2.0885 - val_accuracy: 0.3831\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1649 - accuracy: 0.9302 - val_loss: 1.8228 - val_accuracy: 0.3961\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1283 - accuracy: 0.9451 - val_loss: 1.6204 - val_accuracy: 0.4740\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2146 - accuracy: 0.9147 - val_loss: 1.4812 - val_accuracy: 0.4935\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1273 - accuracy: 0.9485 - val_loss: 1.4340 - val_accuracy: 0.5065\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0990 - accuracy: 0.9759 - val_loss: 0.9845 - val_accuracy: 0.7273\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0859 - accuracy: 0.9582 - val_loss: 1.0278 - val_accuracy: 0.5455\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0925 - accuracy: 0.9753 - val_loss: 0.6406 - val_accuracy: 0.8442\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0928 - accuracy: 0.9856 - val_loss: 0.6292 - val_accuracy: 0.9870\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0860 - accuracy: 0.9750 - val_loss: 0.8654 - val_accuracy: 0.7468\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0747 - accuracy: 0.9918 - val_loss: 0.5339 - val_accuracy: 0.7727\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0872 - accuracy: 0.9790 - val_loss: 0.5962 - val_accuracy: 0.7922\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0972 - accuracy: 0.9697 - val_loss: 0.5310 - val_accuracy: 0.7792\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0841 - accuracy: 0.9828 - val_loss: 0.2920 - val_accuracy: 0.9026\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0463 - accuracy: 0.9974 - val_loss: 0.8745 - val_accuracy: 0.6234\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0536 - accuracy: 0.9912 - val_loss: 0.2576 - val_accuracy: 0.9870\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 0.9948 - val_loss: 0.2364 - val_accuracy: 0.9935\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 0.9995 - val_loss: 0.2106 - val_accuracy: 0.9935\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0314 - accuracy: 0.9933 - val_loss: 0.1812 - val_accuracy: 0.9870\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0242 - accuracy: 0.9981 - val_loss: 0.4164 - val_accuracy: 0.8571\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0536 - accuracy: 0.9882 - val_loss: 0.2042 - val_accuracy: 0.9935\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9982 - val_loss: 0.2710 - val_accuracy: 0.8961\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 1.0000\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9870\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9935\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0186 - accuracy: 0.9984 - val_loss: 0.3073 - val_accuracy: 0.8896\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0149 - accuracy: 0.9989 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.6247 - val_accuracy: 0.7597\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0752 - accuracy: 0.9863 - val_loss: 0.8519 - val_accuracy: 0.7468\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0131 - accuracy: 0.9995 - val_loss: 0.3718 - val_accuracy: 0.9091\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9935\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9870\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9870\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9935\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.4674 - val_accuracy: 0.8052\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9416\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.8052\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9351\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9870\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9221\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.9318 - val_accuracy: 0.8377\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.1526 - val_accuracy: 0.8182\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.7846 - val_accuracy: 0.8506\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.8896\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9286\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0150 - accuracy: 0.9968 - val_loss: 1.5145 - val_accuracy: 0.6494\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.8766\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.8896\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0102 - accuracy: 0.9998 - val_loss: 0.3056 - val_accuracy: 0.9610\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9965 - val_loss: 0.2490 - val_accuracy: 0.9870\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9870\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9870\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9870\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0101 - accuracy: 0.9995 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 0.9740\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9935\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 0.9805\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9935\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9935\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9935\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.8455 - val_accuracy: 0.8506\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.8896\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9740\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9740\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.8896\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9935\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8596 - val_accuracy: 0.5065\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1431 - accuracy: 0.9248 - val_loss: 0.8570 - val_accuracy: 0.7532\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0153 - accuracy: 0.9997 - val_loss: 0.5734 - val_accuracy: 0.8182\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.8831\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.8896\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9805\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9805\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9351\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9286\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9416\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9481\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9091\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9740\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9870\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.8766\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.8896\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9416\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9870\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9935\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 0.1318 - val_accuracy: 0.9221\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 0.9805\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9740\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9870\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9935\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 0.9935\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9870\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00143: early stopping\n",
            "\n",
            "Accuracy: 100.00%\n",
            "Loss: 0.013103424571454525 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 4 \n",
            " num_conv_nodes: 256 \n",
            " num_dense_layers: 1 \n",
            " num_dense_nodes: 66 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 2s 30ms/step - loss: 1.8204 - accuracy: 0.4784 - val_loss: 2.7678 - val_accuracy: 0.0519\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.6104 - accuracy: 0.7935 - val_loss: 2.8613 - val_accuracy: 0.0519\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.3612 - accuracy: 0.8457 - val_loss: 3.0219 - val_accuracy: 0.0519\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2794 - accuracy: 0.8716 - val_loss: 3.2377 - val_accuracy: 0.0519\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.3619 - accuracy: 0.8429 - val_loss: 3.4340 - val_accuracy: 0.0519\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2990 - accuracy: 0.8635 - val_loss: 3.6313 - val_accuracy: 0.0519\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2366 - accuracy: 0.8872 - val_loss: 3.8340 - val_accuracy: 0.0519\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.2074 - accuracy: 0.9033 - val_loss: 3.9611 - val_accuracy: 0.0519\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1903 - accuracy: 0.9039 - val_loss: 4.0208 - val_accuracy: 0.0519\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1927 - accuracy: 0.8922 - val_loss: 4.3070 - val_accuracy: 0.0519\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.5986 - accuracy: 0.8305 - val_loss: 4.2984 - val_accuracy: 0.0519\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2512 - accuracy: 0.8808 - val_loss: 4.3568 - val_accuracy: 0.0519\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1860 - accuracy: 0.9011 - val_loss: 4.4279 - val_accuracy: 0.0519\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1715 - accuracy: 0.9266 - val_loss: 4.5151 - val_accuracy: 0.0519\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 0.1631 - accuracy: 0.9122 - val_loss: 4.5601 - val_accuracy: 0.0519\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2014 - accuracy: 0.8977 - val_loss: 4.4150 - val_accuracy: 0.1169\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1703 - accuracy: 0.9048 - val_loss: 4.3124 - val_accuracy: 0.1169\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1783 - accuracy: 0.9050 - val_loss: 4.2306 - val_accuracy: 0.1169\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1566 - accuracy: 0.9274 - val_loss: 4.1120 - val_accuracy: 0.1234\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1518 - accuracy: 0.9318 - val_loss: 4.0283 - val_accuracy: 0.1364\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1574 - accuracy: 0.9093 - val_loss: 3.8136 - val_accuracy: 0.1429\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1260 - accuracy: 0.9527 - val_loss: 3.6316 - val_accuracy: 0.1429\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1494 - accuracy: 0.9375 - val_loss: 3.3485 - val_accuracy: 0.1429\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1559 - accuracy: 0.9231 - val_loss: 3.1584 - val_accuracy: 0.1429\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1237 - accuracy: 0.9418 - val_loss: 2.6991 - val_accuracy: 0.1623\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1587 - accuracy: 0.9156 - val_loss: 2.4426 - val_accuracy: 0.2792\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1397 - accuracy: 0.9291 - val_loss: 2.2157 - val_accuracy: 0.3182\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1308 - accuracy: 0.9476 - val_loss: 1.7017 - val_accuracy: 0.4156\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1187 - accuracy: 0.9777 - val_loss: 1.3349 - val_accuracy: 0.5130\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1478 - accuracy: 0.9160 - val_loss: 0.8068 - val_accuracy: 0.7338\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1685 - accuracy: 0.9034 - val_loss: 0.9113 - val_accuracy: 0.6818\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1178 - accuracy: 0.9417 - val_loss: 0.8543 - val_accuracy: 0.6948\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1243 - accuracy: 0.9377 - val_loss: 0.6278 - val_accuracy: 0.7143\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1114 - accuracy: 0.9566 - val_loss: 0.5711 - val_accuracy: 0.7078\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1109 - accuracy: 0.9555 - val_loss: 0.3552 - val_accuracy: 0.7338\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1120 - accuracy: 0.9417 - val_loss: 0.3473 - val_accuracy: 0.7727\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1035 - accuracy: 0.9470 - val_loss: 0.2239 - val_accuracy: 0.9286\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0929 - accuracy: 0.9816 - val_loss: 0.2356 - val_accuracy: 0.8701\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0920 - accuracy: 0.9716 - val_loss: 0.1823 - val_accuracy: 0.9740\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0888 - accuracy: 0.9661 - val_loss: 0.1799 - val_accuracy: 0.8961\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0800 - accuracy: 0.9906 - val_loss: 0.1105 - val_accuracy: 0.9870\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0964 - accuracy: 0.9876 - val_loss: 0.1562 - val_accuracy: 0.9156\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0721 - accuracy: 0.9772 - val_loss: 0.7938 - val_accuracy: 0.8896\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0790 - accuracy: 0.9821 - val_loss: 0.6213 - val_accuracy: 0.8442\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0680 - accuracy: 0.9890 - val_loss: 0.4119 - val_accuracy: 0.8247\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0704 - accuracy: 0.9768 - val_loss: 0.9018 - val_accuracy: 0.8571\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0598 - accuracy: 0.9874 - val_loss: 1.2652 - val_accuracy: 0.7403\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0672 - accuracy: 0.9802 - val_loss: 0.4400 - val_accuracy: 0.9026\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0684 - accuracy: 0.9650 - val_loss: 0.6173 - val_accuracy: 0.8182\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0494 - accuracy: 0.9887 - val_loss: 0.2437 - val_accuracy: 0.9740\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0809 - accuracy: 0.9864 - val_loss: 0.3546 - val_accuracy: 0.8247\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0471 - accuracy: 0.9998 - val_loss: 1.0064 - val_accuracy: 0.7857\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0422 - accuracy: 0.9950 - val_loss: 0.3378 - val_accuracy: 0.8961\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0380 - accuracy: 0.9946 - val_loss: 0.1328 - val_accuracy: 0.9351\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0300 - accuracy: 0.9998 - val_loss: 0.2661 - val_accuracy: 0.8961\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0232 - accuracy: 0.9961 - val_loss: 0.6817 - val_accuracy: 0.7987\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0426 - accuracy: 0.9946 - val_loss: 0.2379 - val_accuracy: 0.9026\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0254 - accuracy: 0.9980 - val_loss: 0.0815 - val_accuracy: 0.9935\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.8766\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.5757 - val_accuracy: 0.7013\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0770 - accuracy: 0.9897 - val_loss: 0.1695 - val_accuracy: 0.9221\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0279 - accuracy: 0.9973 - val_loss: 0.1248 - val_accuracy: 0.9805\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0184 - accuracy: 0.9998 - val_loss: 0.3283 - val_accuracy: 0.8961\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.9026\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9286\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9351\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0143 - accuracy: 0.9996 - val_loss: 0.1547 - val_accuracy: 0.9026\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9935\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5159 - val_accuracy: 0.9026\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.9026\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9026\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9026\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0083 - accuracy: 0.9998 - val_loss: 0.3669 - val_accuracy: 0.7987\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.7987\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0350 - accuracy: 0.9870 - val_loss: 4.3548 - val_accuracy: 0.4026\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0314 - accuracy: 0.9938 - val_loss: 2.4636 - val_accuracy: 0.5909\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.1642 - val_accuracy: 0.6818\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.8510 - val_accuracy: 0.8247\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9221\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.8831\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9935\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9870\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0111 - accuracy: 0.9998 - val_loss: 0.5048 - val_accuracy: 0.7987\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9935\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9156\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 0.9935\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.8961\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9026\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9026\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9026\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9026\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9026\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9935\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9156\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 0.9935\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9935\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9026\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.1865 - val_accuracy: 0.9156\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0208 - accuracy: 0.9961 - val_loss: 0.0608 - val_accuracy: 0.9870\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9935\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 3.9023 - val_accuracy: 0.4610\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0593 - accuracy: 0.9891 - val_loss: 1.1903 - val_accuracy: 0.6688\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.9860 - val_accuracy: 0.6883\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.3749 - val_accuracy: 0.8961\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0130 - accuracy: 0.9982 - val_loss: 0.1206 - val_accuracy: 0.9545\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.8961\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9935\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9221\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9935\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9091\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9026\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9610\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9870\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9026\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9091\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9935\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9416\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9026\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9091\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9416\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9935\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9870\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9870\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9221\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9935\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9935\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9935\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9221\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9935\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9935\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9026\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9416\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9740\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9935\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9935\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9870\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9935\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9870\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3199 - val_accuracy: 0.9026\n",
            "Epoch 156/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9026\n",
            "Epoch 157/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 0.9870\n",
            "Epoch 158/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9935\n",
            "Epoch 159/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9935\n",
            "Epoch 160/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9935\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00160: early stopping\n",
            "\n",
            "Accuracy: 99.35%\n",
            "Loss: 0.03638707101345062 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 3 \n",
            " num_conv_nodes: 244 \n",
            " num_dense_layers: 1 \n",
            " num_dense_nodes: 42 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 2s 29ms/step - loss: 1.7814 - accuracy: 0.4926 - val_loss: 2.7067 - val_accuracy: 0.2078\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.5353 - accuracy: 0.7507 - val_loss: 2.7534 - val_accuracy: 0.0909\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.3382 - accuracy: 0.8435 - val_loss: 2.8700 - val_accuracy: 0.0909\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2917 - accuracy: 0.8582 - val_loss: 3.0206 - val_accuracy: 0.0909\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2319 - accuracy: 0.8713 - val_loss: 3.1991 - val_accuracy: 0.0909\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2125 - accuracy: 0.8767 - val_loss: 3.3137 - val_accuracy: 0.0909\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.3842 - accuracy: 0.8261 - val_loss: 3.5597 - val_accuracy: 0.0909\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2266 - accuracy: 0.8713 - val_loss: 3.8490 - val_accuracy: 0.0909\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.3993 - accuracy: 0.8386 - val_loss: 4.0968 - val_accuracy: 0.0909\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2315 - accuracy: 0.8758 - val_loss: 4.1104 - val_accuracy: 0.0909\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2062 - accuracy: 0.9007 - val_loss: 4.0700 - val_accuracy: 0.1623\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2550 - accuracy: 0.8663 - val_loss: 4.1334 - val_accuracy: 0.1623\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2086 - accuracy: 0.8803 - val_loss: 4.2285 - val_accuracy: 0.1558\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 0.1943 - accuracy: 0.8710 - val_loss: 4.2174 - val_accuracy: 0.1558\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1629 - accuracy: 0.9191 - val_loss: 4.1619 - val_accuracy: 0.1558\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1542 - accuracy: 0.9052 - val_loss: 4.1882 - val_accuracy: 0.1623\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1792 - accuracy: 0.8727 - val_loss: 4.4976 - val_accuracy: 0.1558\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.4934 - accuracy: 0.8318 - val_loss: 4.6931 - val_accuracy: 0.1558\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2121 - accuracy: 0.8826 - val_loss: 4.2594 - val_accuracy: 0.1558\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1760 - accuracy: 0.9003 - val_loss: 4.2758 - val_accuracy: 0.1558\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2455 - accuracy: 0.8776 - val_loss: 3.9469 - val_accuracy: 0.1558\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1620 - accuracy: 0.9132 - val_loss: 3.4999 - val_accuracy: 0.1623\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2531 - accuracy: 0.8648 - val_loss: 3.3888 - val_accuracy: 0.1558\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1675 - accuracy: 0.8876 - val_loss: 3.0258 - val_accuracy: 0.1558\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1658 - accuracy: 0.8849 - val_loss: 2.6958 - val_accuracy: 0.1883\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1689 - accuracy: 0.9035 - val_loss: 2.2413 - val_accuracy: 0.2273\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1480 - accuracy: 0.9161 - val_loss: 1.8564 - val_accuracy: 0.2468\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1401 - accuracy: 0.9271 - val_loss: 1.3088 - val_accuracy: 0.4156\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1507 - accuracy: 0.9042 - val_loss: 1.2008 - val_accuracy: 0.4351\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1387 - accuracy: 0.9163 - val_loss: 0.9391 - val_accuracy: 0.5974\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1328 - accuracy: 0.9391 - val_loss: 0.5809 - val_accuracy: 0.6429\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1044 - accuracy: 0.9526 - val_loss: 0.3829 - val_accuracy: 0.8247\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1176 - accuracy: 0.9375 - val_loss: 0.4371 - val_accuracy: 0.8182\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1090 - accuracy: 0.9463 - val_loss: 0.4275 - val_accuracy: 0.7922\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1193 - accuracy: 0.9265 - val_loss: 0.3016 - val_accuracy: 0.8312\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1116 - accuracy: 0.9395 - val_loss: 0.8883 - val_accuracy: 0.7273\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1195 - accuracy: 0.9303 - val_loss: 1.0829 - val_accuracy: 0.7727\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1339 - accuracy: 0.9245 - val_loss: 0.1664 - val_accuracy: 0.9156\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1263 - accuracy: 0.9093 - val_loss: 0.1374 - val_accuracy: 0.9156\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1177 - accuracy: 0.9324 - val_loss: 1.3356 - val_accuracy: 0.7403\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1048 - accuracy: 0.9425 - val_loss: 0.3528 - val_accuracy: 0.8247\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1072 - accuracy: 0.9340 - val_loss: 0.1420 - val_accuracy: 1.0000\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0916 - accuracy: 0.9417 - val_loss: 0.1787 - val_accuracy: 0.9156\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0937 - accuracy: 0.9473 - val_loss: 0.9661 - val_accuracy: 0.7662\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0969 - accuracy: 0.9421 - val_loss: 0.1196 - val_accuracy: 0.9351\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0751 - accuracy: 0.9560 - val_loss: 0.1174 - val_accuracy: 0.9286\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0971 - accuracy: 0.9585 - val_loss: 0.1248 - val_accuracy: 0.9351\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0828 - accuracy: 0.9435 - val_loss: 0.1356 - val_accuracy: 0.9221\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0844 - accuracy: 0.9563 - val_loss: 0.7677 - val_accuracy: 0.6169\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1048 - accuracy: 0.9446 - val_loss: 0.3588 - val_accuracy: 0.8247\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1055 - accuracy: 0.9244 - val_loss: 2.0033 - val_accuracy: 0.5390\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1007 - accuracy: 0.9404 - val_loss: 0.4791 - val_accuracy: 0.8247\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0884 - accuracy: 0.9612 - val_loss: 0.1191 - val_accuracy: 0.9286\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0885 - accuracy: 0.9622 - val_loss: 0.1075 - val_accuracy: 0.9351\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0798 - accuracy: 0.9551 - val_loss: 0.3955 - val_accuracy: 0.8247\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0848 - accuracy: 0.9585 - val_loss: 0.1175 - val_accuracy: 0.9286\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0975 - accuracy: 0.9250 - val_loss: 3.3005 - val_accuracy: 0.4675\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0976 - accuracy: 0.9385 - val_loss: 0.1157 - val_accuracy: 0.9221\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0932 - accuracy: 0.9420 - val_loss: 0.1117 - val_accuracy: 0.9286\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0768 - accuracy: 0.9502 - val_loss: 0.0980 - val_accuracy: 0.9416\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0744 - accuracy: 0.9601 - val_loss: 4.2177 - val_accuracy: 0.4221\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1013 - accuracy: 0.9410 - val_loss: 2.1484 - val_accuracy: 0.7078\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0757 - accuracy: 0.9679 - val_loss: 1.4539 - val_accuracy: 0.7208\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0783 - accuracy: 0.9656 - val_loss: 1.1097 - val_accuracy: 0.7532\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0789 - accuracy: 0.9389 - val_loss: 1.0526 - val_accuracy: 0.7597\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0843 - accuracy: 0.9514 - val_loss: 0.2081 - val_accuracy: 0.8506\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0915 - accuracy: 0.9466 - val_loss: 0.9276 - val_accuracy: 0.6429\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0836 - accuracy: 0.9616 - val_loss: 0.1752 - val_accuracy: 0.9156\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0907 - accuracy: 0.9358 - val_loss: 0.1100 - val_accuracy: 0.9286\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0835 - accuracy: 0.9591 - val_loss: 0.1037 - val_accuracy: 0.9286\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0921 - accuracy: 0.9342 - val_loss: 0.6284 - val_accuracy: 0.7987\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0913 - accuracy: 0.9499 - val_loss: 0.1465 - val_accuracy: 0.9351\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0985 - accuracy: 0.9625 - val_loss: 0.1024 - val_accuracy: 0.9351\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0865 - accuracy: 0.9678 - val_loss: 0.1477 - val_accuracy: 0.9286\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0754 - accuracy: 0.9576 - val_loss: 0.1458 - val_accuracy: 0.9156\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0922 - accuracy: 0.9403 - val_loss: 0.1029 - val_accuracy: 0.9351\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0669 - accuracy: 0.9627 - val_loss: 0.1973 - val_accuracy: 0.8377\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0768 - accuracy: 0.9534 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0836 - accuracy: 0.9758 - val_loss: 0.1205 - val_accuracy: 0.9286\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0788 - accuracy: 0.9564 - val_loss: 0.1163 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0747 - accuracy: 0.9702 - val_loss: 0.1038 - val_accuracy: 0.9351\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0850 - accuracy: 0.9545 - val_loss: 0.0951 - val_accuracy: 0.9351\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0811 - accuracy: 0.9816 - val_loss: 0.0948 - val_accuracy: 0.9351\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0709 - accuracy: 0.9669 - val_loss: 0.2199 - val_accuracy: 0.8377\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0783 - accuracy: 0.9575 - val_loss: 0.2678 - val_accuracy: 0.8961\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0694 - accuracy: 0.9547 - val_loss: 1.1261 - val_accuracy: 0.7403\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0946 - accuracy: 0.9517 - val_loss: 1.3881 - val_accuracy: 0.7338\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0796 - accuracy: 0.9519 - val_loss: 1.0703 - val_accuracy: 0.8182\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0870 - accuracy: 0.9426 - val_loss: 0.9420 - val_accuracy: 0.8377\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0774 - accuracy: 0.9570 - val_loss: 0.6429 - val_accuracy: 0.8182\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0875 - accuracy: 0.9750 - val_loss: 0.5795 - val_accuracy: 0.8247\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0777 - accuracy: 0.9783 - val_loss: 0.1712 - val_accuracy: 0.8636\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0839 - accuracy: 0.9891 - val_loss: 0.2110 - val_accuracy: 0.8247\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0718 - accuracy: 0.9849 - val_loss: 0.1539 - val_accuracy: 0.9870\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0741 - accuracy: 0.9718 - val_loss: 0.2867 - val_accuracy: 0.8247\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0854 - accuracy: 0.9541 - val_loss: 0.0931 - val_accuracy: 0.9351\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0767 - accuracy: 0.9655 - val_loss: 0.0912 - val_accuracy: 0.9351\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0667 - accuracy: 0.9871 - val_loss: 0.1028 - val_accuracy: 0.9156\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0842 - accuracy: 0.9411 - val_loss: 0.0903 - val_accuracy: 0.9545\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0746 - accuracy: 0.9724 - val_loss: 0.0913 - val_accuracy: 0.9935\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0698 - accuracy: 0.9628 - val_loss: 0.0938 - val_accuracy: 0.9351\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0684 - accuracy: 0.9941 - val_loss: 0.1924 - val_accuracy: 0.8506\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0786 - accuracy: 0.9793 - val_loss: 0.0887 - val_accuracy: 0.9351\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0709 - accuracy: 0.9752 - val_loss: 0.0907 - val_accuracy: 0.9351\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0677 - accuracy: 0.9800 - val_loss: 0.1038 - val_accuracy: 0.9351\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0653 - accuracy: 0.9832 - val_loss: 0.1020 - val_accuracy: 0.9351\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0752 - accuracy: 0.9709 - val_loss: 0.0875 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0672 - accuracy: 0.9833 - val_loss: 0.3588 - val_accuracy: 0.8247\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0750 - accuracy: 0.9536 - val_loss: 0.1427 - val_accuracy: 0.9286\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0677 - accuracy: 0.9772 - val_loss: 0.1009 - val_accuracy: 0.9870\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0757 - accuracy: 0.9842 - val_loss: 0.0873 - val_accuracy: 0.9351\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0720 - accuracy: 0.9858 - val_loss: 0.0902 - val_accuracy: 0.9740\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0822 - accuracy: 0.9694 - val_loss: 0.0871 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0644 - accuracy: 0.9818 - val_loss: 0.0909 - val_accuracy: 0.9351\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0672 - accuracy: 0.9812 - val_loss: 0.0897 - val_accuracy: 0.9351\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.0650 - accuracy: 0.9842 - val_loss: 0.1133 - val_accuracy: 0.9286\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0552 - accuracy: 0.9846 - val_loss: 0.0917 - val_accuracy: 0.9351\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0569 - accuracy: 0.9974 - val_loss: 0.1057 - val_accuracy: 0.9286\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0493 - accuracy: 0.9928 - val_loss: 0.0850 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0606 - accuracy: 0.9958 - val_loss: 0.0920 - val_accuracy: 0.9351\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0453 - accuracy: 0.9867 - val_loss: 0.0777 - val_accuracy: 0.9351\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0528 - accuracy: 0.9965 - val_loss: 0.1021 - val_accuracy: 0.9351\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0564 - accuracy: 0.9873 - val_loss: 0.0885 - val_accuracy: 0.9351\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0521 - accuracy: 0.9882 - val_loss: 0.1111 - val_accuracy: 0.9870\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0567 - accuracy: 0.9988 - val_loss: 0.0789 - val_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0540 - accuracy: 0.9951 - val_loss: 0.1701 - val_accuracy: 0.8636\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9935\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.8961\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9286\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9805\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0440 - accuracy: 0.9973 - val_loss: 0.1059 - val_accuracy: 0.9870\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0380 - accuracy: 0.9992 - val_loss: 0.0829 - val_accuracy: 0.9870\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9351\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0467 - accuracy: 0.9924 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9870\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0407 - accuracy: 0.9989 - val_loss: 0.0743 - val_accuracy: 0.9351\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0415 - accuracy: 0.9954 - val_loss: 0.0662 - val_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0352 - accuracy: 0.9993 - val_loss: 0.0891 - val_accuracy: 0.9351\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0375 - accuracy: 0.9946 - val_loss: 0.0591 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0385 - accuracy: 0.9906 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00142: early stopping\n",
            "\n",
            "Accuracy: 100.00%\n",
            "Loss: 0.059008918702602386 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 4 \n",
            " num_conv_nodes: 247 \n",
            " num_dense_layers: 1 \n",
            " num_dense_nodes: 105 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 2s 34ms/step - loss: 1.9034 - accuracy: 0.4366 - val_loss: 2.7289 - val_accuracy: 0.0909\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.3787 - accuracy: 0.8389 - val_loss: 2.7620 - val_accuracy: 0.0260\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2943 - accuracy: 0.8825 - val_loss: 2.8329 - val_accuracy: 0.0260\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.3024 - accuracy: 0.8532 - val_loss: 2.9688 - val_accuracy: 0.0260\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.3854 - accuracy: 0.8483 - val_loss: 3.0851 - val_accuracy: 0.0260\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.4358 - accuracy: 0.8590 - val_loss: 3.2373 - val_accuracy: 0.0260\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2769 - accuracy: 0.8629 - val_loss: 3.3185 - val_accuracy: 0.0260\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1791 - accuracy: 0.9195 - val_loss: 3.3913 - val_accuracy: 0.0260\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2226 - accuracy: 0.8704 - val_loss: 3.4297 - val_accuracy: 0.0974\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1870 - accuracy: 0.8951 - val_loss: 3.4612 - val_accuracy: 0.0974\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1751 - accuracy: 0.9001 - val_loss: 3.3985 - val_accuracy: 0.0325\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2041 - accuracy: 0.8865 - val_loss: 3.2030 - val_accuracy: 0.1948\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.2110 - accuracy: 0.8888 - val_loss: 3.1942 - val_accuracy: 0.1753\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1669 - accuracy: 0.9148 - val_loss: 3.0992 - val_accuracy: 0.1948\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1671 - accuracy: 0.9155 - val_loss: 3.0136 - val_accuracy: 0.1948\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1700 - accuracy: 0.9010 - val_loss: 2.9661 - val_accuracy: 0.2857\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1470 - accuracy: 0.9149 - val_loss: 2.9638 - val_accuracy: 0.2857\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1889 - accuracy: 0.8956 - val_loss: 2.8894 - val_accuracy: 0.2857\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1562 - accuracy: 0.9153 - val_loss: 2.8214 - val_accuracy: 0.2857\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1382 - accuracy: 0.9184 - val_loss: 2.6732 - val_accuracy: 0.2857\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1703 - accuracy: 0.8920 - val_loss: 2.5080 - val_accuracy: 0.2857\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1683 - accuracy: 0.8986 - val_loss: 2.3778 - val_accuracy: 0.2857\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1524 - accuracy: 0.9258 - val_loss: 2.2769 - val_accuracy: 0.3182\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1306 - accuracy: 0.9373 - val_loss: 2.1254 - val_accuracy: 0.3377\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1419 - accuracy: 0.9154 - val_loss: 2.0024 - val_accuracy: 0.4221\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1334 - accuracy: 0.9338 - val_loss: 1.7296 - val_accuracy: 0.5000\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1239 - accuracy: 0.9456 - val_loss: 1.4317 - val_accuracy: 0.5909\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.1628 - accuracy: 0.9235 - val_loss: 1.3228 - val_accuracy: 0.6688\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1149 - accuracy: 0.9499 - val_loss: 1.1635 - val_accuracy: 0.6169\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1346 - accuracy: 0.9296 - val_loss: 0.8180 - val_accuracy: 0.7208\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1119 - accuracy: 0.9571 - val_loss: 0.6865 - val_accuracy: 0.7468\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1277 - accuracy: 0.9422 - val_loss: 0.6846 - val_accuracy: 0.7143\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1141 - accuracy: 0.9514 - val_loss: 0.7909 - val_accuracy: 0.6883\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1524 - accuracy: 0.9385 - val_loss: 0.3708 - val_accuracy: 0.8117\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0993 - accuracy: 0.9650 - val_loss: 0.2526 - val_accuracy: 0.9091\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1639 - accuracy: 0.9273 - val_loss: 0.2229 - val_accuracy: 0.8831\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1203 - accuracy: 0.9526 - val_loss: 0.2073 - val_accuracy: 0.8766\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1255 - accuracy: 0.9462 - val_loss: 0.4074 - val_accuracy: 0.7792\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1292 - accuracy: 0.9351 - val_loss: 0.4453 - val_accuracy: 0.8377\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0909 - accuracy: 0.9641 - val_loss: 0.2417 - val_accuracy: 0.8377\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0890 - accuracy: 0.9693 - val_loss: 0.2202 - val_accuracy: 0.8312\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1236 - accuracy: 0.9448 - val_loss: 0.3198 - val_accuracy: 0.8312\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0790 - accuracy: 0.9798 - val_loss: 0.1464 - val_accuracy: 0.9286\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0889 - accuracy: 0.9907 - val_loss: 0.1326 - val_accuracy: 0.9221\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0600 - accuracy: 0.9908 - val_loss: 0.1486 - val_accuracy: 0.9545\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0726 - accuracy: 0.9832 - val_loss: 0.1182 - val_accuracy: 0.9870\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0516 - accuracy: 0.9898 - val_loss: 0.1033 - val_accuracy: 0.9416\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0470 - accuracy: 0.9952 - val_loss: 0.1072 - val_accuracy: 0.9870\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0341 - accuracy: 0.9975 - val_loss: 1.2566 - val_accuracy: 0.6104\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0552 - accuracy: 0.9971 - val_loss: 0.5597 - val_accuracy: 0.7532\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0397 - accuracy: 0.9989 - val_loss: 0.1737 - val_accuracy: 0.9545\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0549 - accuracy: 0.9921 - val_loss: 0.0947 - val_accuracy: 0.9870\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0232 - accuracy: 0.9998 - val_loss: 0.1723 - val_accuracy: 0.9026\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0367 - accuracy: 0.9933 - val_loss: 0.1062 - val_accuracy: 0.9935\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9935\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0267 - accuracy: 0.9971 - val_loss: 0.2523 - val_accuracy: 0.8961\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9026\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0276 - accuracy: 0.9934 - val_loss: 0.0786 - val_accuracy: 0.9935\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0273 - accuracy: 0.9968 - val_loss: 0.0553 - val_accuracy: 0.9870\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9935\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9935\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9026\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9935\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 0.9935\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9935\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0096 - accuracy: 0.9998 - val_loss: 2.7943 - val_accuracy: 0.5195\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0329 - accuracy: 0.9998 - val_loss: 1.2892 - val_accuracy: 0.5649\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0197 - accuracy: 0.9984 - val_loss: 0.5995 - val_accuracy: 0.8247\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9286\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0167 - accuracy: 0.9997 - val_loss: 0.0633 - val_accuracy: 0.9870\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9026\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0131 - accuracy: 0.9998 - val_loss: 0.0480 - val_accuracy: 0.9935\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9870\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0140 - accuracy: 0.9946 - val_loss: 0.0305 - val_accuracy: 0.9935\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9935\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9935\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0939 - val_accuracy: 0.9545\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9610\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0949 - val_accuracy: 0.9481\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9935\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9026\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.0557 - val_accuracy: 0.9870\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.4348 - val_accuracy: 0.8961\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9091\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0713 - val_accuracy: 0.9935\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9805\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9935\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9935\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.0818 - val_accuracy: 0.9805\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0109 - accuracy: 0.9998 - val_loss: 2.7203 - val_accuracy: 0.4805\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.8524 - val_accuracy: 0.7273\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.8896\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9675\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9935\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9935\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9935\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 0.9935\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.0331 - val_accuracy: 0.9935\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9481\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9870\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 0.9935\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9935\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 3.4980 - val_accuracy: 0.5909\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.9514 - val_accuracy: 0.6429\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.8766\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6185 - val_accuracy: 0.8961\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.8961\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9026\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9935\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 0.9935\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 1.9825 - val_accuracy: 0.8506\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0110 - accuracy: 0.9988 - val_loss: 0.1323 - val_accuracy: 0.9351\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0627 - val_accuracy: 0.9935\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9870\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9286\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9935\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9935\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9935\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9935\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9935\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9935\n",
            "Epoch 156/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
            "Epoch 158/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
            "Epoch 159/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
            "Epoch 160/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00160: early stopping\n",
            "\n",
            "Accuracy: 100.00%\n",
            "Loss: 0.02434242144227028 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 4 \n",
            " num_conv_nodes: 256 \n",
            " num_dense_layers: 2 \n",
            " num_dense_nodes: 107 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 2s 31ms/step - loss: 1.7862 - accuracy: 0.4359 - val_loss: 2.7580 - val_accuracy: 0.1558\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.4619 - accuracy: 0.8313 - val_loss: 2.8021 - val_accuracy: 0.0909\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.5378 - accuracy: 0.8422 - val_loss: 2.8971 - val_accuracy: 0.0909\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.3169 - accuracy: 0.8712 - val_loss: 3.0487 - val_accuracy: 0.0909\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2517 - accuracy: 0.8615 - val_loss: 3.1568 - val_accuracy: 0.0909\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2249 - accuracy: 0.8879 - val_loss: 3.3043 - val_accuracy: 0.0909\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2601 - accuracy: 0.8611 - val_loss: 3.4612 - val_accuracy: 0.0909\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1983 - accuracy: 0.8830 - val_loss: 3.4369 - val_accuracy: 0.0909\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.6208 - accuracy: 0.8569 - val_loss: 3.5024 - val_accuracy: 0.0909\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2362 - accuracy: 0.8954 - val_loss: 3.5576 - val_accuracy: 0.0909\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2163 - accuracy: 0.8893 - val_loss: 3.7087 - val_accuracy: 0.0909\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2194 - accuracy: 0.8949 - val_loss: 3.6764 - val_accuracy: 0.0909\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.3881 - accuracy: 0.8379 - val_loss: 3.7144 - val_accuracy: 0.2078\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1931 - accuracy: 0.8922 - val_loss: 3.7116 - val_accuracy: 0.2273\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1739 - accuracy: 0.9046 - val_loss: 3.6866 - val_accuracy: 0.2143\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1784 - accuracy: 0.8903 - val_loss: 3.6624 - val_accuracy: 0.2273\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1579 - accuracy: 0.9141 - val_loss: 3.5734 - val_accuracy: 0.2338\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1810 - accuracy: 0.9048 - val_loss: 3.5026 - val_accuracy: 0.2338\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1719 - accuracy: 0.9030 - val_loss: 3.4866 - val_accuracy: 0.2338\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1704 - accuracy: 0.8923 - val_loss: 3.4001 - val_accuracy: 0.2338\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1913 - accuracy: 0.8875 - val_loss: 3.3678 - val_accuracy: 0.2338\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.1521 - accuracy: 0.9012 - val_loss: 3.2816 - val_accuracy: 0.2403\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1727 - accuracy: 0.8938 - val_loss: 3.0095 - val_accuracy: 0.2403\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1613 - accuracy: 0.9107 - val_loss: 2.7460 - val_accuracy: 0.2403\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1560 - accuracy: 0.9093 - val_loss: 2.7419 - val_accuracy: 0.2338\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1647 - accuracy: 0.9053 - val_loss: 2.4926 - val_accuracy: 0.2338\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1430 - accuracy: 0.9323 - val_loss: 2.1955 - val_accuracy: 0.2403\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1795 - accuracy: 0.8888 - val_loss: 1.6500 - val_accuracy: 0.5130\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1775 - accuracy: 0.9027 - val_loss: 1.5399 - val_accuracy: 0.5714\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1645 - accuracy: 0.9117 - val_loss: 1.3187 - val_accuracy: 0.5519\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1382 - accuracy: 0.9203 - val_loss: 1.2032 - val_accuracy: 0.6558\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1548 - accuracy: 0.9044 - val_loss: 0.9610 - val_accuracy: 0.7078\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1690 - accuracy: 0.9032 - val_loss: 0.6463 - val_accuracy: 0.6883\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1496 - accuracy: 0.9382 - val_loss: 0.4708 - val_accuracy: 0.6558\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1365 - accuracy: 0.9310 - val_loss: 0.3421 - val_accuracy: 0.7987\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2004 - accuracy: 0.8865 - val_loss: 0.2536 - val_accuracy: 0.9156\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1365 - accuracy: 0.9438 - val_loss: 0.6017 - val_accuracy: 0.7468\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1989 - accuracy: 0.9012 - val_loss: 0.2425 - val_accuracy: 0.9221\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1669 - accuracy: 0.9173 - val_loss: 0.2060 - val_accuracy: 0.9156\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1390 - accuracy: 0.9227 - val_loss: 0.1595 - val_accuracy: 0.9221\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1744 - accuracy: 0.8985 - val_loss: 0.1801 - val_accuracy: 0.9156\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1257 - accuracy: 0.9345 - val_loss: 0.1901 - val_accuracy: 0.8636\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1434 - accuracy: 0.9350 - val_loss: 0.1621 - val_accuracy: 0.9286\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1362 - accuracy: 0.9450 - val_loss: 0.4110 - val_accuracy: 0.7662\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1349 - accuracy: 0.9215 - val_loss: 0.1626 - val_accuracy: 0.9221\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1211 - accuracy: 0.9457 - val_loss: 0.2062 - val_accuracy: 0.8636\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1252 - accuracy: 0.9655 - val_loss: 0.1681 - val_accuracy: 0.9026\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1113 - accuracy: 0.9479 - val_loss: 0.2584 - val_accuracy: 0.9091\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1559 - accuracy: 0.9216 - val_loss: 0.2103 - val_accuracy: 0.9740\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.1230 - accuracy: 0.9543 - val_loss: 0.3498 - val_accuracy: 0.7792\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1119 - accuracy: 0.9682 - val_loss: 0.1637 - val_accuracy: 0.9156\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1149 - accuracy: 0.9562 - val_loss: 0.1410 - val_accuracy: 0.9870\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1112 - accuracy: 0.9390 - val_loss: 0.1503 - val_accuracy: 0.9221\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0957 - accuracy: 0.9631 - val_loss: 0.2532 - val_accuracy: 0.9091\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1016 - accuracy: 0.9726 - val_loss: 0.1730 - val_accuracy: 0.9026\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0895 - accuracy: 0.9824 - val_loss: 0.1612 - val_accuracy: 0.9805\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1001 - accuracy: 0.9737 - val_loss: 0.4883 - val_accuracy: 0.8182\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0933 - accuracy: 0.9741 - val_loss: 0.9983 - val_accuracy: 0.6364\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1454 - accuracy: 0.9011 - val_loss: 0.6612 - val_accuracy: 0.8766\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1016 - accuracy: 0.9619 - val_loss: 1.4109 - val_accuracy: 0.6104\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1064 - accuracy: 0.9424 - val_loss: 0.6778 - val_accuracy: 0.7078\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0819 - accuracy: 0.9808 - val_loss: 0.2851 - val_accuracy: 0.8377\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0739 - accuracy: 0.9862 - val_loss: 0.1079 - val_accuracy: 0.9870\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0858 - accuracy: 0.9742 - val_loss: 0.1481 - val_accuracy: 0.9286\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0855 - accuracy: 0.9614 - val_loss: 0.1499 - val_accuracy: 0.9935\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0683 - accuracy: 0.9881 - val_loss: 0.1337 - val_accuracy: 0.9156\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0616 - accuracy: 0.9789 - val_loss: 0.1215 - val_accuracy: 0.9221\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0366 - accuracy: 0.9984 - val_loss: 0.1872 - val_accuracy: 0.9156\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0359 - accuracy: 0.9958 - val_loss: 0.2128 - val_accuracy: 0.8636\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.8506\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9610\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.8831\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9026\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9935\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0230 - accuracy: 0.9996 - val_loss: 0.0760 - val_accuracy: 0.9935\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0173 - accuracy: 0.9992 - val_loss: 0.2303 - val_accuracy: 0.8896\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9935\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5470 - val_accuracy: 0.8636\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 0.9935\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0132 - accuracy: 0.9998 - val_loss: 0.4261 - val_accuracy: 0.9221\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0346 - accuracy: 0.9959 - val_loss: 0.9263 - val_accuracy: 0.7013\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9156\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.8766\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.8052\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9351\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9870\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.8961\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9091\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.8896\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9545\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9740\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9740\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9740\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.8896\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9545\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 0.9998 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.9230 - val_accuracy: 0.6299\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 0.9998 - val_loss: 2.3359 - val_accuracy: 0.6039\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.7987\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.8961\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9221\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9870\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9610\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.9301 - val_accuracy: 0.5779\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5532 - val_accuracy: 0.7727\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.8896\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9870\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 0.9998 - val_loss: 0.2243 - val_accuracy: 0.9286\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.8312\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9805\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0250 - val_accuracy: 0.9935\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9740\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.8896\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9481\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9351\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 158/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 159/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 160/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 161/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 162/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 163/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 164/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
            "Epoch 165/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 166/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 167/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 168/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 169/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
            "Epoch 170/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 171/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 172/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 173/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 174/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 175/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 176/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00176: early stopping\n",
            "\n",
            "Accuracy: 100.00%\n",
            "Loss: 0.011079052463173866 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 2 \n",
            " num_conv_nodes: 246 \n",
            " num_dense_layers: 3 \n",
            " num_dense_nodes: 102 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 2.0313 - accuracy: 0.3957 - val_loss: 2.6936 - val_accuracy: 0.1429\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.9601 - accuracy: 0.7461 - val_loss: 2.7130 - val_accuracy: 0.1623\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.6363 - accuracy: 0.7862 - val_loss: 2.7688 - val_accuracy: 0.1688\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.3780 - accuracy: 0.8349 - val_loss: 2.8630 - val_accuracy: 0.1623\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.4875 - accuracy: 0.8080 - val_loss: 3.0399 - val_accuracy: 0.1623\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.6665 - accuracy: 0.8191 - val_loss: 3.1469 - val_accuracy: 0.1883\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2607 - accuracy: 0.8552 - val_loss: 3.3377 - val_accuracy: 0.1688\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2824 - accuracy: 0.8559 - val_loss: 3.4773 - val_accuracy: 0.1623\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2152 - accuracy: 0.8869 - val_loss: 3.6719 - val_accuracy: 0.1558\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2798 - accuracy: 0.8424 - val_loss: 3.8845 - val_accuracy: 0.1558\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1976 - accuracy: 0.8978 - val_loss: 4.0619 - val_accuracy: 0.1623\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2408 - accuracy: 0.8633 - val_loss: 4.1339 - val_accuracy: 0.1558\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1835 - accuracy: 0.8986 - val_loss: 4.2714 - val_accuracy: 0.1753\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2544 - accuracy: 0.8648 - val_loss: 4.4428 - val_accuracy: 0.1623\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2206 - accuracy: 0.8637 - val_loss: 4.3008 - val_accuracy: 0.1753\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2010 - accuracy: 0.8724 - val_loss: 4.4509 - val_accuracy: 0.1818\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2198 - accuracy: 0.8760 - val_loss: 4.4670 - val_accuracy: 0.1883\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1728 - accuracy: 0.8932 - val_loss: 4.4135 - val_accuracy: 0.1883\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1742 - accuracy: 0.8869 - val_loss: 4.5811 - val_accuracy: 0.1818\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2434 - accuracy: 0.8684 - val_loss: 4.2838 - val_accuracy: 0.1818\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1831 - accuracy: 0.8848 - val_loss: 4.1485 - val_accuracy: 0.1883\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2082 - accuracy: 0.8768 - val_loss: 3.8562 - val_accuracy: 0.1818\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1906 - accuracy: 0.8560 - val_loss: 3.3400 - val_accuracy: 0.1818\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2024 - accuracy: 0.8639 - val_loss: 2.8375 - val_accuracy: 0.2013\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1625 - accuracy: 0.8830 - val_loss: 2.4098 - val_accuracy: 0.2143\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1695 - accuracy: 0.9086 - val_loss: 2.4163 - val_accuracy: 0.2208\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1912 - accuracy: 0.8728 - val_loss: 2.0557 - val_accuracy: 0.3312\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1981 - accuracy: 0.8849 - val_loss: 1.6176 - val_accuracy: 0.4481\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1640 - accuracy: 0.8981 - val_loss: 1.2994 - val_accuracy: 0.5065\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1620 - accuracy: 0.9032 - val_loss: 0.9714 - val_accuracy: 0.5974\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1987 - accuracy: 0.8735 - val_loss: 0.6223 - val_accuracy: 0.6494\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.1540 - accuracy: 0.9039 - val_loss: 0.3968 - val_accuracy: 0.7727\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2069 - accuracy: 0.8730 - val_loss: 0.4050 - val_accuracy: 0.7208\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1756 - accuracy: 0.8845 - val_loss: 0.2440 - val_accuracy: 0.8571\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1707 - accuracy: 0.9189 - val_loss: 0.2135 - val_accuracy: 0.9156\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1494 - accuracy: 0.8985 - val_loss: 0.2382 - val_accuracy: 0.9026\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1626 - accuracy: 0.8932 - val_loss: 0.3724 - val_accuracy: 0.8506\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1896 - accuracy: 0.8778 - val_loss: 0.1713 - val_accuracy: 0.9156\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1871 - accuracy: 0.8758 - val_loss: 0.1805 - val_accuracy: 0.8961\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1882 - accuracy: 0.8839 - val_loss: 0.1835 - val_accuracy: 0.8766\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1515 - accuracy: 0.9106 - val_loss: 0.1631 - val_accuracy: 0.9091\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1758 - accuracy: 0.8930 - val_loss: 0.1467 - val_accuracy: 0.9091\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1624 - accuracy: 0.8883 - val_loss: 0.2292 - val_accuracy: 0.8312\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1684 - accuracy: 0.8930 - val_loss: 0.1839 - val_accuracy: 0.8961\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1776 - accuracy: 0.9065 - val_loss: 0.1867 - val_accuracy: 0.9091\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1663 - accuracy: 0.9240 - val_loss: 0.2052 - val_accuracy: 0.8442\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1678 - accuracy: 0.8908 - val_loss: 0.4744 - val_accuracy: 0.7727\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.2157 - accuracy: 0.8813 - val_loss: 0.2018 - val_accuracy: 0.8377\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1708 - accuracy: 0.9000 - val_loss: 0.2019 - val_accuracy: 0.8377\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1649 - accuracy: 0.8942 - val_loss: 0.1580 - val_accuracy: 0.9156\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1681 - accuracy: 0.8913 - val_loss: 0.1734 - val_accuracy: 0.8961\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1751 - accuracy: 0.8956 - val_loss: 0.4434 - val_accuracy: 0.8182\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1962 - accuracy: 0.9029 - val_loss: 0.2725 - val_accuracy: 0.8247\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1715 - accuracy: 0.8924 - val_loss: 0.2716 - val_accuracy: 0.8247\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1554 - accuracy: 0.8991 - val_loss: 0.1764 - val_accuracy: 0.8766\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1395 - accuracy: 0.9000 - val_loss: 0.2430 - val_accuracy: 0.8247\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1837 - accuracy: 0.9053 - val_loss: 0.2123 - val_accuracy: 0.8312\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1565 - accuracy: 0.9087 - val_loss: 0.1916 - val_accuracy: 0.9026\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.1397 - accuracy: 0.9241 - val_loss: 0.2570 - val_accuracy: 0.8701\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1633 - accuracy: 0.8959 - val_loss: 0.2638 - val_accuracy: 0.8831\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.2090 - accuracy: 0.8582 - val_loss: 0.1453 - val_accuracy: 0.9091\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1444 - accuracy: 0.9014 - val_loss: 0.1518 - val_accuracy: 0.9091\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1565 - accuracy: 0.9053 - val_loss: 0.3187 - val_accuracy: 0.8247\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1515 - accuracy: 0.8996 - val_loss: 0.1874 - val_accuracy: 0.8506\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1626 - accuracy: 0.8982 - val_loss: 0.1477 - val_accuracy: 0.9156\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1429 - accuracy: 0.9126 - val_loss: 0.2454 - val_accuracy: 0.8312\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1853 - accuracy: 0.8893 - val_loss: 0.2734 - val_accuracy: 0.8312\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1479 - accuracy: 0.9040 - val_loss: 0.1382 - val_accuracy: 0.9221\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1607 - accuracy: 0.9140 - val_loss: 0.2014 - val_accuracy: 0.8312\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1421 - accuracy: 0.9212 - val_loss: 0.2394 - val_accuracy: 0.8312\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1496 - accuracy: 0.9107 - val_loss: 0.2313 - val_accuracy: 0.8247\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1497 - accuracy: 0.9121 - val_loss: 0.1647 - val_accuracy: 0.8961\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1882 - accuracy: 0.9006 - val_loss: 0.1409 - val_accuracy: 0.9091\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1686 - accuracy: 0.9028 - val_loss: 0.1996 - val_accuracy: 0.8312\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1516 - accuracy: 0.9081 - val_loss: 0.1445 - val_accuracy: 0.9091\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1591 - accuracy: 0.8991 - val_loss: 0.1814 - val_accuracy: 0.8506\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1400 - accuracy: 0.9049 - val_loss: 0.1363 - val_accuracy: 0.9221\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1499 - accuracy: 0.9221 - val_loss: 0.1507 - val_accuracy: 0.9870\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1477 - accuracy: 0.9215 - val_loss: 0.1719 - val_accuracy: 0.9156\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1483 - accuracy: 0.9149 - val_loss: 0.1673 - val_accuracy: 0.9156\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1495 - accuracy: 0.9121 - val_loss: 0.1999 - val_accuracy: 0.8442\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1398 - accuracy: 0.9114 - val_loss: 0.1503 - val_accuracy: 0.9221\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1457 - accuracy: 0.9232 - val_loss: 0.1593 - val_accuracy: 0.9156\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1438 - accuracy: 0.9136 - val_loss: 0.2937 - val_accuracy: 0.8247\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1543 - accuracy: 0.9135 - val_loss: 0.2348 - val_accuracy: 0.8247\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.1584 - accuracy: 0.9180 - val_loss: 0.1419 - val_accuracy: 0.9156\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1484 - accuracy: 0.9144 - val_loss: 0.2474 - val_accuracy: 0.8312\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1381 - accuracy: 0.9325 - val_loss: 0.1474 - val_accuracy: 0.9221\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1526 - accuracy: 0.9001 - val_loss: 0.2296 - val_accuracy: 0.8312\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1234 - accuracy: 0.9400 - val_loss: 0.3223 - val_accuracy: 0.8247\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1246 - accuracy: 0.9378 - val_loss: 0.1551 - val_accuracy: 0.9221\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1573 - accuracy: 0.9029 - val_loss: 0.1740 - val_accuracy: 0.9221\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1514 - accuracy: 0.9123 - val_loss: 0.3502 - val_accuracy: 0.8182\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1495 - accuracy: 0.9139 - val_loss: 0.2367 - val_accuracy: 0.8247\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1346 - accuracy: 0.9210 - val_loss: 0.2136 - val_accuracy: 0.8377\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1346 - accuracy: 0.9225 - val_loss: 0.1815 - val_accuracy: 0.8571\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1392 - accuracy: 0.9209 - val_loss: 0.1462 - val_accuracy: 0.9221\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1451 - accuracy: 0.9263 - val_loss: 0.1308 - val_accuracy: 0.9870\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1420 - accuracy: 0.9308 - val_loss: 0.2923 - val_accuracy: 0.8312\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1390 - accuracy: 0.9151 - val_loss: 0.2340 - val_accuracy: 0.8312\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1317 - accuracy: 0.9535 - val_loss: 0.2563 - val_accuracy: 0.8961\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1378 - accuracy: 0.9000 - val_loss: 0.1366 - val_accuracy: 0.9870\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1338 - accuracy: 0.9281 - val_loss: 0.2058 - val_accuracy: 0.8312\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1450 - accuracy: 0.9136 - val_loss: 0.1433 - val_accuracy: 0.9870\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1396 - accuracy: 0.9418 - val_loss: 0.1774 - val_accuracy: 0.8831\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1384 - accuracy: 0.9350 - val_loss: 0.3020 - val_accuracy: 0.8312\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1318 - accuracy: 0.9412 - val_loss: 0.1435 - val_accuracy: 0.9286\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1328 - accuracy: 0.9237 - val_loss: 0.1981 - val_accuracy: 0.8377\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1339 - accuracy: 0.9372 - val_loss: 0.2170 - val_accuracy: 0.8312\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1320 - accuracy: 0.9183 - val_loss: 0.1625 - val_accuracy: 0.9221\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1269 - accuracy: 0.9375 - val_loss: 0.1329 - val_accuracy: 0.9091\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1279 - accuracy: 0.9346 - val_loss: 0.1351 - val_accuracy: 0.9221\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.1361 - accuracy: 0.9565 - val_loss: 0.1293 - val_accuracy: 0.9156\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1230 - accuracy: 0.9403 - val_loss: 0.1786 - val_accuracy: 0.9286\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1297 - accuracy: 0.9480 - val_loss: 0.1300 - val_accuracy: 0.9805\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1246 - accuracy: 0.9273 - val_loss: 0.1905 - val_accuracy: 0.8442\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1116 - accuracy: 0.9677 - val_loss: 0.1470 - val_accuracy: 0.9870\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1254 - accuracy: 0.9481 - val_loss: 0.1287 - val_accuracy: 0.9805\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1354 - accuracy: 0.9391 - val_loss: 0.1880 - val_accuracy: 0.8442\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1282 - accuracy: 0.9419 - val_loss: 0.1546 - val_accuracy: 0.9286\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1120 - accuracy: 0.9399 - val_loss: 0.3585 - val_accuracy: 0.8247\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1358 - accuracy: 0.9324 - val_loss: 0.1482 - val_accuracy: 0.9221\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1237 - accuracy: 0.9532 - val_loss: 0.1910 - val_accuracy: 0.9026\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1236 - accuracy: 0.9557 - val_loss: 0.1437 - val_accuracy: 0.9286\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1274 - accuracy: 0.9424 - val_loss: 0.1248 - val_accuracy: 0.9221\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1242 - accuracy: 0.9486 - val_loss: 0.1665 - val_accuracy: 0.9026\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1310 - accuracy: 0.9459 - val_loss: 0.1648 - val_accuracy: 0.9091\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1241 - accuracy: 0.9549 - val_loss: 0.1424 - val_accuracy: 0.9286\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1304 - accuracy: 0.9751 - val_loss: 0.1577 - val_accuracy: 0.9286\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1210 - accuracy: 0.9749 - val_loss: 0.1430 - val_accuracy: 0.9935\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1250 - accuracy: 0.9435 - val_loss: 0.1347 - val_accuracy: 0.9740\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1122 - accuracy: 0.9785 - val_loss: 0.1286 - val_accuracy: 0.9870\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1215 - accuracy: 0.9559 - val_loss: 0.1424 - val_accuracy: 0.9286\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1343 - accuracy: 0.9582 - val_loss: 0.1473 - val_accuracy: 0.9286\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1168 - accuracy: 0.9434 - val_loss: 0.1681 - val_accuracy: 0.8961\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1195 - accuracy: 0.9390 - val_loss: 0.2142 - val_accuracy: 0.8312\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1361 - accuracy: 0.9224 - val_loss: 0.2516 - val_accuracy: 0.8312\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1288 - accuracy: 0.9846 - val_loss: 0.2027 - val_accuracy: 0.8377\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1228 - accuracy: 0.9595 - val_loss: 0.2074 - val_accuracy: 0.8377\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.1190 - accuracy: 0.9646 - val_loss: 0.1854 - val_accuracy: 0.9026\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1093 - accuracy: 0.9924 - val_loss: 0.1469 - val_accuracy: 0.9870\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1158 - accuracy: 0.9501 - val_loss: 0.1566 - val_accuracy: 0.9221\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1169 - accuracy: 0.9343 - val_loss: 0.1976 - val_accuracy: 0.8442\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1106 - accuracy: 0.9713 - val_loss: 0.1858 - val_accuracy: 0.8506\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1257 - accuracy: 0.9433 - val_loss: 0.1514 - val_accuracy: 0.9870\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1196 - accuracy: 0.9894 - val_loss: 0.1548 - val_accuracy: 0.9805\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1151 - accuracy: 0.9641 - val_loss: 0.1961 - val_accuracy: 0.8377\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1181 - accuracy: 0.9864 - val_loss: 0.1667 - val_accuracy: 0.9026\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1276 - accuracy: 0.9513 - val_loss: 0.1744 - val_accuracy: 0.8831\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1343 - accuracy: 0.9517 - val_loss: 0.1380 - val_accuracy: 0.9610\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1063 - accuracy: 0.9678 - val_loss: 0.3336 - val_accuracy: 0.8247\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1053 - accuracy: 0.9485 - val_loss: 0.1423 - val_accuracy: 0.9221\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1282 - accuracy: 0.9760 - val_loss: 0.1318 - val_accuracy: 0.9156\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1221 - accuracy: 0.9439 - val_loss: 0.1548 - val_accuracy: 0.9221\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1183 - accuracy: 0.9492 - val_loss: 0.1674 - val_accuracy: 0.9675\n",
            "Epoch 156/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1243 - accuracy: 0.9417 - val_loss: 0.1341 - val_accuracy: 0.9221\n",
            "Epoch 157/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1119 - accuracy: 0.9442 - val_loss: 0.1398 - val_accuracy: 0.9870\n",
            "Epoch 158/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1132 - accuracy: 0.9769 - val_loss: 0.1678 - val_accuracy: 0.9610\n",
            "Epoch 159/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1133 - accuracy: 0.9827 - val_loss: 0.1735 - val_accuracy: 0.9416\n",
            "Epoch 160/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1088 - accuracy: 0.9909 - val_loss: 0.1832 - val_accuracy: 0.9286\n",
            "Epoch 161/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1276 - accuracy: 0.9801 - val_loss: 0.1580 - val_accuracy: 0.9156\n",
            "Epoch 162/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1038 - accuracy: 0.9723 - val_loss: 0.2430 - val_accuracy: 0.8506\n",
            "Epoch 163/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1249 - accuracy: 0.9745 - val_loss: 0.1816 - val_accuracy: 0.9286\n",
            "Epoch 164/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1220 - accuracy: 0.9629 - val_loss: 0.1576 - val_accuracy: 0.9156\n",
            "Epoch 165/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1184 - accuracy: 0.9502 - val_loss: 0.1695 - val_accuracy: 0.8896\n",
            "Epoch 166/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1274 - accuracy: 0.9894 - val_loss: 0.1655 - val_accuracy: 0.9026\n",
            "Epoch 167/500\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.1164 - accuracy: 0.9730 - val_loss: 0.1505 - val_accuracy: 0.9221\n",
            "Epoch 168/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1046 - accuracy: 0.9722 - val_loss: 0.2461 - val_accuracy: 0.8961\n",
            "Epoch 169/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1195 - accuracy: 0.9718 - val_loss: 0.1861 - val_accuracy: 0.9156\n",
            "Epoch 170/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1126 - accuracy: 0.9759 - val_loss: 0.1762 - val_accuracy: 0.9351\n",
            "Epoch 171/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1128 - accuracy: 0.9672 - val_loss: 0.1534 - val_accuracy: 0.9870\n",
            "Epoch 172/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1156 - accuracy: 0.9652 - val_loss: 0.1677 - val_accuracy: 0.9610\n",
            "Epoch 173/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1139 - accuracy: 0.9683 - val_loss: 0.1797 - val_accuracy: 0.9286\n",
            "Epoch 174/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.9479 - val_loss: 0.1599 - val_accuracy: 0.9740\n",
            "Epoch 175/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1088 - accuracy: 0.9532 - val_loss: 0.1582 - val_accuracy: 0.9156\n",
            "Epoch 176/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1188 - accuracy: 0.9740 - val_loss: 0.1478 - val_accuracy: 0.9221\n",
            "Epoch 177/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1099 - accuracy: 0.9647 - val_loss: 0.1476 - val_accuracy: 0.9870\n",
            "Epoch 178/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1174 - accuracy: 0.9666 - val_loss: 0.1456 - val_accuracy: 0.9870\n",
            "Epoch 179/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1152 - accuracy: 0.9669 - val_loss: 0.1404 - val_accuracy: 0.9935\n",
            "Epoch 180/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1207 - accuracy: 0.9634 - val_loss: 0.1498 - val_accuracy: 0.9221\n",
            "Epoch 181/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1094 - accuracy: 0.9718 - val_loss: 0.1683 - val_accuracy: 0.8961\n",
            "Epoch 182/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1165 - accuracy: 0.9583 - val_loss: 0.1535 - val_accuracy: 0.9221\n",
            "Epoch 183/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1103 - accuracy: 0.9578 - val_loss: 0.1518 - val_accuracy: 0.9286\n",
            "Epoch 184/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1160 - accuracy: 0.9822 - val_loss: 0.1502 - val_accuracy: 0.9870\n",
            "Epoch 185/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1171 - accuracy: 0.9841 - val_loss: 0.1535 - val_accuracy: 0.9610\n",
            "Epoch 186/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1092 - accuracy: 0.9684 - val_loss: 0.1527 - val_accuracy: 0.9870\n",
            "Epoch 187/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1099 - accuracy: 0.9977 - val_loss: 0.1571 - val_accuracy: 0.9156\n",
            "Epoch 188/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1041 - accuracy: 0.9852 - val_loss: 0.1772 - val_accuracy: 0.9286\n",
            "Epoch 189/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1158 - accuracy: 0.9730 - val_loss: 0.1729 - val_accuracy: 0.9416\n",
            "Epoch 190/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1125 - accuracy: 0.9879 - val_loss: 0.1505 - val_accuracy: 0.9870\n",
            "Epoch 191/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1138 - accuracy: 0.9960 - val_loss: 0.1598 - val_accuracy: 0.9740\n",
            "Epoch 192/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1104 - accuracy: 0.9921 - val_loss: 0.1559 - val_accuracy: 0.9156\n",
            "Epoch 193/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1042 - accuracy: 0.9571 - val_loss: 0.1511 - val_accuracy: 0.9221\n",
            "Epoch 194/500\n",
            "20/20 [==============================] - 0s 20ms/step - loss: 0.1155 - accuracy: 0.9757 - val_loss: 0.1366 - val_accuracy: 0.9286\n",
            "Epoch 195/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1099 - accuracy: 0.9551 - val_loss: 0.1460 - val_accuracy: 0.9286\n",
            "Epoch 196/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1083 - accuracy: 0.9723 - val_loss: 0.1610 - val_accuracy: 0.9026\n",
            "Epoch 197/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1160 - accuracy: 0.9604 - val_loss: 0.1581 - val_accuracy: 0.9091\n",
            "Epoch 198/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1011 - accuracy: 0.9843 - val_loss: 0.1555 - val_accuracy: 0.9156\n",
            "Epoch 199/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1085 - accuracy: 0.9911 - val_loss: 0.1686 - val_accuracy: 0.8896\n",
            "Epoch 200/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1061 - accuracy: 0.9821 - val_loss: 0.1600 - val_accuracy: 0.9481\n",
            "Epoch 201/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1095 - accuracy: 0.9879 - val_loss: 0.1547 - val_accuracy: 0.9805\n",
            "Epoch 202/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1129 - accuracy: 0.9868 - val_loss: 0.1540 - val_accuracy: 0.9805\n",
            "Epoch 203/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1114 - accuracy: 0.9977 - val_loss: 0.1429 - val_accuracy: 0.9870\n",
            "Epoch 204/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1076 - accuracy: 0.9899 - val_loss: 0.1500 - val_accuracy: 0.9870\n",
            "Epoch 205/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1180 - accuracy: 0.9942 - val_loss: 0.1452 - val_accuracy: 0.9221\n",
            "Epoch 206/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1234 - accuracy: 0.9968 - val_loss: 0.1538 - val_accuracy: 0.9156\n",
            "Epoch 207/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1054 - accuracy: 0.9720 - val_loss: 0.1611 - val_accuracy: 0.9026\n",
            "Epoch 208/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1155 - accuracy: 0.9716 - val_loss: 0.1627 - val_accuracy: 0.8961\n",
            "Epoch 209/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1121 - accuracy: 0.9714 - val_loss: 0.1385 - val_accuracy: 0.9286\n",
            "Epoch 210/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1053 - accuracy: 0.9794 - val_loss: 0.1505 - val_accuracy: 0.9221\n",
            "Epoch 211/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1033 - accuracy: 0.9794 - val_loss: 0.1514 - val_accuracy: 0.9221\n",
            "Epoch 212/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1217 - accuracy: 0.9842 - val_loss: 0.1604 - val_accuracy: 0.9091\n",
            "Epoch 213/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1004 - accuracy: 0.9818 - val_loss: 0.1642 - val_accuracy: 0.9091\n",
            "Epoch 214/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1109 - accuracy: 0.9867 - val_loss: 0.1620 - val_accuracy: 0.9675\n",
            "Epoch 215/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1233 - accuracy: 0.9995 - val_loss: 0.1663 - val_accuracy: 0.8961\n",
            "Epoch 216/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0960 - accuracy: 0.9931 - val_loss: 0.1601 - val_accuracy: 0.9740\n",
            "Epoch 217/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1098 - accuracy: 0.9972 - val_loss: 0.1629 - val_accuracy: 0.9026\n",
            "Epoch 218/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1151 - accuracy: 0.9926 - val_loss: 0.1607 - val_accuracy: 0.9416\n",
            "Epoch 219/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1028 - accuracy: 0.9880 - val_loss: 0.1729 - val_accuracy: 0.9286\n",
            "Epoch 220/500\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.1158 - accuracy: 0.9850 - val_loss: 0.1557 - val_accuracy: 0.9805\n",
            "Epoch 221/500\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.1145 - accuracy: 0.9973 - val_loss: 0.1493 - val_accuracy: 0.9870\n",
            "Epoch 222/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1075 - accuracy: 0.9840 - val_loss: 0.1558 - val_accuracy: 0.9805\n",
            "Epoch 223/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.0994 - accuracy: 0.9996 - val_loss: 0.1529 - val_accuracy: 0.9805\n",
            "Epoch 224/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1153 - accuracy: 0.9898 - val_loss: 0.1676 - val_accuracy: 0.8961\n",
            "Epoch 225/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1103 - accuracy: 0.9867 - val_loss: 0.1552 - val_accuracy: 0.9805\n",
            "Epoch 226/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1099 - accuracy: 0.9906 - val_loss: 0.1600 - val_accuracy: 0.9740\n",
            "Epoch 227/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1043 - accuracy: 0.9921 - val_loss: 0.1472 - val_accuracy: 0.9870\n",
            "Epoch 228/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1159 - accuracy: 0.9959 - val_loss: 0.1606 - val_accuracy: 0.9740\n",
            "Epoch 229/500\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.1017 - accuracy: 0.9910 - val_loss: 0.1591 - val_accuracy: 0.9740\n",
            "Epoch 230/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1217 - accuracy: 0.9929 - val_loss: 0.1576 - val_accuracy: 0.9740\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00230: early stopping\n",
            "\n",
            "Accuracy: 97.40%\n",
            "Loss: 0.1576075255870819 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 4 \n",
            " num_conv_nodes: 256 \n",
            " num_dense_layers: 1 \n",
            " num_dense_nodes: 125 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 2s 32ms/step - loss: 1.6792 - accuracy: 0.5070 - val_loss: 2.7256 - val_accuracy: 0.0909\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.4358 - accuracy: 0.8469 - val_loss: 2.7381 - val_accuracy: 0.0909\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.4606 - accuracy: 0.8114 - val_loss: 2.7559 - val_accuracy: 0.0909\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.4127 - accuracy: 0.8463 - val_loss: 2.8184 - val_accuracy: 0.0909\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2184 - accuracy: 0.8994 - val_loss: 2.8904 - val_accuracy: 0.0909\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2555 - accuracy: 0.8691 - val_loss: 2.9524 - val_accuracy: 0.0909\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.3333 - accuracy: 0.8518 - val_loss: 3.0666 - val_accuracy: 0.0909\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1948 - accuracy: 0.8910 - val_loss: 3.1167 - val_accuracy: 0.0909\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.3118 - accuracy: 0.8504 - val_loss: 3.2325 - val_accuracy: 0.0909\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1937 - accuracy: 0.8981 - val_loss: 3.3125 - val_accuracy: 0.1558\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1922 - accuracy: 0.8919 - val_loss: 3.3416 - val_accuracy: 0.1623\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.1504 - accuracy: 0.9155 - val_loss: 3.4165 - val_accuracy: 0.1623\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2046 - accuracy: 0.8964 - val_loss: 3.4375 - val_accuracy: 0.1623\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1874 - accuracy: 0.8928 - val_loss: 3.5088 - val_accuracy: 0.1558\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2155 - accuracy: 0.8846 - val_loss: 3.4329 - val_accuracy: 0.1558\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1623 - accuracy: 0.9141 - val_loss: 3.4641 - val_accuracy: 0.1558\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1409 - accuracy: 0.9314 - val_loss: 3.4511 - val_accuracy: 0.1558\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1607 - accuracy: 0.9147 - val_loss: 3.4837 - val_accuracy: 0.1558\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1968 - accuracy: 0.8920 - val_loss: 3.4404 - val_accuracy: 0.1558\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1809 - accuracy: 0.8953 - val_loss: 3.3698 - val_accuracy: 0.2532\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1297 - accuracy: 0.9382 - val_loss: 3.2641 - val_accuracy: 0.1883\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1490 - accuracy: 0.9190 - val_loss: 3.1752 - val_accuracy: 0.2078\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1647 - accuracy: 0.9273 - val_loss: 2.9624 - val_accuracy: 0.2208\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1414 - accuracy: 0.9196 - val_loss: 2.8554 - val_accuracy: 0.2273\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1337 - accuracy: 0.9443 - val_loss: 2.4318 - val_accuracy: 0.2532\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1973 - accuracy: 0.9122 - val_loss: 2.4114 - val_accuracy: 0.2922\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1541 - accuracy: 0.9367 - val_loss: 2.1191 - val_accuracy: 0.3442\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1236 - accuracy: 0.9396 - val_loss: 2.0832 - val_accuracy: 0.3182\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1329 - accuracy: 0.9437 - val_loss: 1.7521 - val_accuracy: 0.4675\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1244 - accuracy: 0.9502 - val_loss: 1.6249 - val_accuracy: 0.3961\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1462 - accuracy: 0.9333 - val_loss: 1.3927 - val_accuracy: 0.5844\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1158 - accuracy: 0.9671 - val_loss: 1.0372 - val_accuracy: 0.6169\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1019 - accuracy: 0.9654 - val_loss: 0.7706 - val_accuracy: 0.7208\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0943 - accuracy: 0.9787 - val_loss: 0.5113 - val_accuracy: 0.7273\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1441 - accuracy: 0.9542 - val_loss: 0.5013 - val_accuracy: 0.8247\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1409 - accuracy: 0.9246 - val_loss: 0.2217 - val_accuracy: 0.9221\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1751 - accuracy: 0.9392 - val_loss: 0.2169 - val_accuracy: 0.9675\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0961 - accuracy: 0.9651 - val_loss: 0.2034 - val_accuracy: 0.9351\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0828 - accuracy: 0.9915 - val_loss: 0.3027 - val_accuracy: 0.8247\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0582 - accuracy: 0.9966 - val_loss: 0.4035 - val_accuracy: 0.8701\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0714 - accuracy: 0.9859 - val_loss: 0.1710 - val_accuracy: 0.9221\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0944 - accuracy: 0.9785 - val_loss: 0.1865 - val_accuracy: 0.9156\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0487 - accuracy: 0.9914 - val_loss: 0.1622 - val_accuracy: 0.9870\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0535 - accuracy: 0.9900 - val_loss: 1.0473 - val_accuracy: 0.6364\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0639 - accuracy: 0.9819 - val_loss: 0.4159 - val_accuracy: 0.8377\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0591 - accuracy: 0.9910 - val_loss: 0.1708 - val_accuracy: 0.9610\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0557 - accuracy: 0.9998 - val_loss: 0.4027 - val_accuracy: 0.8766\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0479 - accuracy: 0.9891 - val_loss: 0.1481 - val_accuracy: 0.9156\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9935\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0375 - accuracy: 0.9927 - val_loss: 0.9090 - val_accuracy: 0.6039\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0597 - accuracy: 0.9837 - val_loss: 0.1025 - val_accuracy: 0.9870\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.8896\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.8961\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0295 - accuracy: 0.9968 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0152 - accuracy: 0.9998 - val_loss: 1.9078 - val_accuracy: 0.5649\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9870\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0189 - accuracy: 0.9972 - val_loss: 0.2069 - val_accuracy: 0.9026\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9026\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9156\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0146 - accuracy: 0.9977 - val_loss: 0.1029 - val_accuracy: 0.9221\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8636\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9026\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.8896\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.8961\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9416\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.8961\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9026\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.8961\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.8961\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.9280 - val_accuracy: 0.6688\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.8896\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0120 - accuracy: 0.9989 - val_loss: 0.6658 - val_accuracy: 0.8701\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 0.8766\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.8831\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9026\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9870\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9286\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9026\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.8961\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.8831\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9870\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9870\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9675\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.8896\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9935\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9805\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3060 - val_accuracy: 0.7597\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8571\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.8961\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.8961\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.8961\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.8831\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9026\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.8961\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.8961\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9870\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9935\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.8961\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9935\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9935\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9805\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9675\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5172 - val_accuracy: 0.8896\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.8961\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9026\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.8961\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9091\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9091\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.8896\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.5404 - val_accuracy: 0.8506\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0621 - accuracy: 0.9812 - val_loss: 0.2949 - val_accuracy: 0.8961\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.8961\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9156\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9675\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9935\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9870\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9935\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3207 - val_accuracy: 0.8961\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.1858 - val_accuracy: 0.9026\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9026\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9091\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9870\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 0.9998 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9805\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9870\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9870\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.8961\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00154: early stopping\n",
            "\n",
            "Accuracy: 100.00%\n",
            "Loss: 0.010160251520574093 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 3 \n",
            " num_conv_nodes: 256 \n",
            " num_dense_layers: 1 \n",
            " num_dense_nodes: 98 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 2s 28ms/step - loss: 2.0408 - accuracy: 0.5057 - val_loss: 2.7152 - val_accuracy: 0.1558\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.5060 - accuracy: 0.8255 - val_loss: 2.8139 - val_accuracy: 0.0260\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.3315 - accuracy: 0.8252 - val_loss: 3.0986 - val_accuracy: 0.0909\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.3386 - accuracy: 0.8456 - val_loss: 3.2256 - val_accuracy: 0.1169\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.5076 - accuracy: 0.7937 - val_loss: 3.4565 - val_accuracy: 0.1169\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2791 - accuracy: 0.8918 - val_loss: 3.6489 - val_accuracy: 0.1169\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2560 - accuracy: 0.8697 - val_loss: 4.2177 - val_accuracy: 0.0909\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.7381 - accuracy: 0.8292 - val_loss: 4.0456 - val_accuracy: 0.0909\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2657 - accuracy: 0.8496 - val_loss: 4.1613 - val_accuracy: 0.0909\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2505 - accuracy: 0.8515 - val_loss: 4.1744 - val_accuracy: 0.0909\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2267 - accuracy: 0.8992 - val_loss: 4.0179 - val_accuracy: 0.1558\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.3158 - accuracy: 0.8508 - val_loss: 4.5645 - val_accuracy: 0.1558\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1734 - accuracy: 0.8864 - val_loss: 4.6187 - val_accuracy: 0.1558\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1865 - accuracy: 0.8809 - val_loss: 4.7281 - val_accuracy: 0.1558\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1427 - accuracy: 0.9241 - val_loss: 4.6993 - val_accuracy: 0.1558\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1929 - accuracy: 0.8970 - val_loss: 4.7054 - val_accuracy: 0.1623\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.1932 - accuracy: 0.8758 - val_loss: 4.6541 - val_accuracy: 0.1753\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1482 - accuracy: 0.9329 - val_loss: 4.5516 - val_accuracy: 0.1883\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1648 - accuracy: 0.9060 - val_loss: 4.4437 - val_accuracy: 0.1818\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2113 - accuracy: 0.8906 - val_loss: 4.3410 - val_accuracy: 0.1883\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1606 - accuracy: 0.9059 - val_loss: 4.0995 - val_accuracy: 0.1883\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1733 - accuracy: 0.9071 - val_loss: 3.6801 - val_accuracy: 0.1818\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2337 - accuracy: 0.8727 - val_loss: 3.7766 - val_accuracy: 0.1883\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1438 - accuracy: 0.9341 - val_loss: 3.4822 - val_accuracy: 0.1883\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1640 - accuracy: 0.9217 - val_loss: 3.2678 - val_accuracy: 0.1883\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1513 - accuracy: 0.9100 - val_loss: 2.6525 - val_accuracy: 0.2403\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1419 - accuracy: 0.9163 - val_loss: 2.4217 - val_accuracy: 0.2857\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1434 - accuracy: 0.9095 - val_loss: 1.9889 - val_accuracy: 0.4416\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1716 - accuracy: 0.8933 - val_loss: 0.8768 - val_accuracy: 0.6688\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2067 - accuracy: 0.9014 - val_loss: 1.0627 - val_accuracy: 0.6883\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1608 - accuracy: 0.9112 - val_loss: 0.7779 - val_accuracy: 0.7922\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1369 - accuracy: 0.9264 - val_loss: 0.6795 - val_accuracy: 0.7792\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1415 - accuracy: 0.9169 - val_loss: 0.6159 - val_accuracy: 0.7792\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1201 - accuracy: 0.9527 - val_loss: 0.4654 - val_accuracy: 0.7987\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1456 - accuracy: 0.9223 - val_loss: 0.2869 - val_accuracy: 0.8506\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1354 - accuracy: 0.9407 - val_loss: 0.2435 - val_accuracy: 0.9026\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1377 - accuracy: 0.9335 - val_loss: 0.2174 - val_accuracy: 0.8506\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1321 - accuracy: 0.9428 - val_loss: 0.1874 - val_accuracy: 0.8701\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1281 - accuracy: 0.9401 - val_loss: 0.2164 - val_accuracy: 0.8442\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1161 - accuracy: 0.9505 - val_loss: 0.6864 - val_accuracy: 0.7987\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1315 - accuracy: 0.9278 - val_loss: 0.3580 - val_accuracy: 0.8247\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1271 - accuracy: 0.9495 - val_loss: 0.2303 - val_accuracy: 0.8377\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1203 - accuracy: 0.9475 - val_loss: 0.1854 - val_accuracy: 0.8506\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1366 - accuracy: 0.9292 - val_loss: 0.1410 - val_accuracy: 0.9286\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0993 - accuracy: 0.9625 - val_loss: 0.1258 - val_accuracy: 0.9870\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1106 - accuracy: 0.9646 - val_loss: 0.1272 - val_accuracy: 0.9221\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1159 - accuracy: 0.9460 - val_loss: 0.8740 - val_accuracy: 0.8052\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1209 - accuracy: 0.9562 - val_loss: 0.1251 - val_accuracy: 0.9351\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1083 - accuracy: 0.9518 - val_loss: 0.1144 - val_accuracy: 0.9870\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1027 - accuracy: 0.9720 - val_loss: 0.1085 - val_accuracy: 0.9740\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0832 - accuracy: 0.9836 - val_loss: 0.1218 - val_accuracy: 0.9156\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0911 - accuracy: 0.9813 - val_loss: 0.2654 - val_accuracy: 0.8247\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0963 - accuracy: 0.9615 - val_loss: 0.1120 - val_accuracy: 0.9935\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0726 - accuracy: 0.9802 - val_loss: 4.5340 - val_accuracy: 0.4286\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1298 - accuracy: 0.9544 - val_loss: 0.4904 - val_accuracy: 0.8117\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0810 - accuracy: 0.9602 - val_loss: 0.7233 - val_accuracy: 0.7727\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0967 - accuracy: 0.9674 - val_loss: 0.1407 - val_accuracy: 0.9286\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0819 - accuracy: 0.9834 - val_loss: 0.1243 - val_accuracy: 0.9870\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0808 - accuracy: 0.9784 - val_loss: 0.1146 - val_accuracy: 0.9870\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0710 - accuracy: 0.9835 - val_loss: 0.0985 - val_accuracy: 0.9870\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0768 - accuracy: 0.9762 - val_loss: 0.1049 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0615 - accuracy: 0.9952 - val_loss: 0.1064 - val_accuracy: 0.9870\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0699 - accuracy: 0.9891 - val_loss: 0.1504 - val_accuracy: 0.9870\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0841 - accuracy: 0.9895 - val_loss: 0.1223 - val_accuracy: 0.9870\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0793 - accuracy: 0.9822 - val_loss: 21.2399 - val_accuracy: 0.0779\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0973 - accuracy: 0.9603 - val_loss: 3.2109 - val_accuracy: 0.4481\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0680 - accuracy: 0.9831 - val_loss: 1.0264 - val_accuracy: 0.7403\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0667 - accuracy: 0.9783 - val_loss: 0.6948 - val_accuracy: 0.7857\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0600 - accuracy: 0.9956 - val_loss: 0.3539 - val_accuracy: 0.8182\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0554 - accuracy: 0.9846 - val_loss: 0.1268 - val_accuracy: 0.9675\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0562 - accuracy: 0.9927 - val_loss: 0.0849 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0487 - accuracy: 0.9920 - val_loss: 0.1070 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0480 - accuracy: 0.9949 - val_loss: 0.0967 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0444 - accuracy: 0.9993 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0525 - accuracy: 0.9936 - val_loss: 0.0732 - val_accuracy: 0.9935\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0377 - accuracy: 0.9986 - val_loss: 0.0854 - val_accuracy: 0.9870\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9610\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9351\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0447 - accuracy: 0.9837 - val_loss: 0.0678 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9870\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 1.0321 - val_accuracy: 0.7013\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0469 - accuracy: 0.9946 - val_loss: 0.0772 - val_accuracy: 0.9610\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0364 - accuracy: 0.9936 - val_loss: 0.0695 - val_accuracy: 0.9870\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9870\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 0.9870\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9870\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0193 - accuracy: 0.9998 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0201 - accuracy: 0.9984 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9870\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9870\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9156\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.9998 - val_loss: 0.0519 - val_accuracy: 0.9870\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9870\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 6.7323 - val_accuracy: 0.4091\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.0170 - val_accuracy: 0.6558\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.8273 - val_accuracy: 0.8442\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.8831\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.8896\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.8961\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9545\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.8896\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.8896\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 158/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.8896\n",
            "Epoch 159/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9545\n",
            "Epoch 160/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
            "Epoch 161/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00161: early stopping\n",
            "\n",
            "Accuracy: 100.00%\n",
            "Loss: 0.03282007947564125 \n",
            "\n",
            "NEXT SET OF HYPERPARAMETERS IS: \n",
            " num_conv_layers: 4 \n",
            " num_conv_nodes: 245 \n",
            " num_dense_layers: 1 \n",
            " num_dense_nodes: 142 \n",
            "\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 2s 33ms/step - loss: 1.7590 - accuracy: 0.5659 - val_loss: 2.7216 - val_accuracy: 0.1623\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.8829 - accuracy: 0.7657 - val_loss: 2.7658 - val_accuracy: 0.1558\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.3849 - accuracy: 0.8381 - val_loss: 2.8519 - val_accuracy: 0.0909\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.3105 - accuracy: 0.8468 - val_loss: 3.0019 - val_accuracy: 0.0909\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.3603 - accuracy: 0.8837 - val_loss: 3.1725 - val_accuracy: 0.0909\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2302 - accuracy: 0.8801 - val_loss: 3.3302 - val_accuracy: 0.0909\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2003 - accuracy: 0.9102 - val_loss: 3.4515 - val_accuracy: 0.0909\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1983 - accuracy: 0.9098 - val_loss: 3.5675 - val_accuracy: 0.0909\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2064 - accuracy: 0.9086 - val_loss: 3.5545 - val_accuracy: 0.1558\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.3471 - accuracy: 0.8563 - val_loss: 3.7009 - val_accuracy: 0.1558\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1764 - accuracy: 0.9210 - val_loss: 3.7376 - val_accuracy: 0.1558\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2082 - accuracy: 0.8778 - val_loss: 3.7345 - val_accuracy: 0.1558\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1843 - accuracy: 0.9018 - val_loss: 3.8666 - val_accuracy: 0.2078\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1864 - accuracy: 0.8803 - val_loss: 3.7994 - val_accuracy: 0.2078\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 24ms/step - loss: 0.1696 - accuracy: 0.9171 - val_loss: 3.7896 - val_accuracy: 0.2078\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1537 - accuracy: 0.9099 - val_loss: 3.7225 - val_accuracy: 0.2143\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1764 - accuracy: 0.9004 - val_loss: 3.7187 - val_accuracy: 0.2273\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2025 - accuracy: 0.8771 - val_loss: 3.5061 - val_accuracy: 0.2208\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1606 - accuracy: 0.9094 - val_loss: 3.4664 - val_accuracy: 0.2208\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1521 - accuracy: 0.9301 - val_loss: 3.3783 - val_accuracy: 0.2338\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1317 - accuracy: 0.9450 - val_loss: 3.2504 - val_accuracy: 0.2403\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1485 - accuracy: 0.9205 - val_loss: 3.0393 - val_accuracy: 0.2403\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1461 - accuracy: 0.9429 - val_loss: 2.9809 - val_accuracy: 0.2468\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1382 - accuracy: 0.9359 - val_loss: 2.7226 - val_accuracy: 0.4026\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1679 - accuracy: 0.9201 - val_loss: 2.6681 - val_accuracy: 0.4286\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1155 - accuracy: 0.9609 - val_loss: 2.4212 - val_accuracy: 0.5130\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1512 - accuracy: 0.9345 - val_loss: 2.1730 - val_accuracy: 0.4805\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1253 - accuracy: 0.9440 - val_loss: 2.1669 - val_accuracy: 0.5130\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.2826 - accuracy: 0.8870 - val_loss: 1.6952 - val_accuracy: 0.6169\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1094 - accuracy: 0.9576 - val_loss: 1.3891 - val_accuracy: 0.5974\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1068 - accuracy: 0.9825 - val_loss: 1.0714 - val_accuracy: 0.6104\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0981 - accuracy: 0.9452 - val_loss: 0.9425 - val_accuracy: 0.6299\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1144 - accuracy: 0.9588 - val_loss: 0.9589 - val_accuracy: 0.6364\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0954 - accuracy: 0.9721 - val_loss: 0.9016 - val_accuracy: 0.7922\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.1180 - accuracy: 0.9502 - val_loss: 0.6083 - val_accuracy: 0.7013\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1383 - accuracy: 0.9590 - val_loss: 0.4702 - val_accuracy: 0.7727\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0825 - accuracy: 0.9833 - val_loss: 0.7939 - val_accuracy: 0.7597\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.1228 - accuracy: 0.9459 - val_loss: 0.3286 - val_accuracy: 0.9286\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0887 - accuracy: 0.9653 - val_loss: 0.2484 - val_accuracy: 0.8636\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0731 - accuracy: 0.9855 - val_loss: 0.9928 - val_accuracy: 0.7727\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.2160 - accuracy: 0.9457 - val_loss: 0.6984 - val_accuracy: 0.8247\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0879 - accuracy: 0.9808 - val_loss: 0.7094 - val_accuracy: 0.8247\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0710 - accuracy: 0.9940 - val_loss: 0.7042 - val_accuracy: 0.8247\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.9026\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0378 - accuracy: 0.9954 - val_loss: 0.4751 - val_accuracy: 0.8896\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0293 - accuracy: 0.9982 - val_loss: 0.2983 - val_accuracy: 0.9026\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0217 - accuracy: 0.9990 - val_loss: 0.5690 - val_accuracy: 0.8896\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0406 - accuracy: 0.9919 - val_loss: 0.1705 - val_accuracy: 0.9675\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0217 - accuracy: 0.9998 - val_loss: 0.1612 - val_accuracy: 0.9026\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9805\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0167 - accuracy: 0.9998 - val_loss: 0.1813 - val_accuracy: 0.9870\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0246 - accuracy: 0.9961 - val_loss: 0.1220 - val_accuracy: 0.9740\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0178 - accuracy: 0.9978 - val_loss: 0.3902 - val_accuracy: 0.8636\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0630 - accuracy: 0.9896 - val_loss: 0.3366 - val_accuracy: 0.8961\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0411 - accuracy: 0.9837 - val_loss: 0.2236 - val_accuracy: 0.8506\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9351\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0375 - accuracy: 0.9912 - val_loss: 0.3120 - val_accuracy: 0.9286\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0296 - accuracy: 0.9921 - val_loss: 0.1887 - val_accuracy: 0.9026\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9221\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0107 - accuracy: 0.9997 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0323 - accuracy: 0.9872 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0105 - accuracy: 0.9982 - val_loss: 0.0442 - val_accuracy: 0.9870\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0085 - accuracy: 0.9998 - val_loss: 0.0792 - val_accuracy: 0.9870\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0102 - accuracy: 0.9990 - val_loss: 0.0640 - val_accuracy: 0.9870\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 0.9973 - val_loss: 0.0378 - val_accuracy: 0.9870\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9935\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9675\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.8896\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9286\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9675\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9545\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9805\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9156\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9675\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9935\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 23ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9935\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.8896\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.8961\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.1529 - val_accuracy: 0.8961\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9610\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9675\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9740\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.8896\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9286\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9221\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9805\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9935\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9221\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9675\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9935\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9935\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9935\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9935\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9286\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9351\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9026\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.8896\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9091\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.8961\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9740\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9481\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9740\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9091\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9675\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9286\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9935\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 0.3434 - val_accuracy: 0.8247\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9221\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9351\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9351\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9351\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9351\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9935\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9610\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9026\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9221\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9545\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9935\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.8896\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9481\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9935\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9935\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 0.0764 - val_accuracy: 0.9740\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9610\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9610\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9675\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9351\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9351\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9610\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 0.9740\n",
            "Epoch 156/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.8896\n",
            "Epoch 157/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.8961\n",
            "Epoch 158/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9935\n",
            "Epoch 159/500\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9935\n",
            "Epoch 160/500\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9935\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00160: early stopping\n",
            "\n",
            "Accuracy: 99.35%\n",
            "Loss: 0.050461653620004654 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWd32Qtz7irF"
      },
      "source": [
        "## 6.6.Second stage results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4a6yHTkAy4m"
      },
      "source": [
        "**Results of the 2nd stage of optimization:**\r\n",
        "*  Convergence plot (visualization of the fitness function after *n* iterations of the optimizer);\r\n",
        "*  Objective plot (visualization of the influence of each search-space dimension on the objective function);\r\n",
        "*  The history of analyzed hyperparameters sets;\r\n",
        "*  The time spent in the optimization process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "BnO2ZKnTsp2c",
        "outputId": "595c9599-602e-4fe7-f970-c7d8bb5f94f5"
      },
      "source": [
        "# Visualização das métricas:\r\n",
        "\r\n",
        "skopt.plots.plot_convergence(result)\r\n",
        "plt.savefig('/content/drive/My Drive/MESTRADO - UFES/optimizer convergence A1_0.png', transparent=True, bbox_inches='tight', dpi=600)\r\n",
        "\r\n",
        "\r\n",
        "skopt.plots.plot_objective(result,\r\n",
        "                           levels=100,\r\n",
        "                           n_points=100,\r\n",
        "                           n_samples=250,\r\n",
        "                           size=2.25,\r\n",
        "                           zscale='linear',\r\n",
        "                           dimensions=None,\r\n",
        "                           sample_source='random',\r\n",
        "                           minimum='result',\r\n",
        "                           n_minimum_search=None,\r\n",
        "                           plot_dims=None,\r\n",
        "                           show_points=True,\r\n",
        "                           cmap='viridis_r')\r\n",
        "plt.savefig('/content/drive/My Drive/MESTRADO - UFES/space exploration A1_0.png', transparent=True, bbox_inches='tight', dpi=600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "37qXlv5MtruV",
        "outputId": "574a3987-0906-479e-c807-56ffc61309e3"
      },
      "source": [
        "# Caso necessário uma superfície de contorno ampliada, comparando a exploração\r\n",
        "# de dois hiperparâmetros específicos com a função de custo: \r\n",
        "\r\n",
        "skopt.plots.plot_objective_2D(result,\r\n",
        "                              dimension_identifier1='num_conv_nodes',\r\n",
        "                              dimension_identifier2='num_dense_nodes',\r\n",
        "                              levels=100)\r\n",
        "#plt.savefig('/content/drive/My Drive/MESTRADO - UFES/objective_2D A1_0.png', transparent=True, bbox_inches='tight', dpi=600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faabcd95978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDTkH37zTVC9"
      },
      "source": [
        "The history of the optimization process is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzz-lNXuSoD0",
        "outputId": "b4b7ae7c-a5ed-4760-bd5c-df96cc9d2f1c"
      },
      "source": [
        "print('Hyperparameters: num_conv_layers / num_conv_nodes / num_dense_layers / num_dense_nodes')\r\n",
        "\r\n",
        "for fitness, x in sorted(zip(result.func_vals, result.x_iters)):\r\n",
        "    print('The fitness was:', fitness, 'with hyperparameters:', x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyperparameters: num_conv_layers / num_conv_nodes / num_dense_layers / num_dense_nodes\n",
            "The fitness was: 0.006251691374927759 with hyperparameters: [3, 72, 3, 256]\n",
            "The fitness was: 0.00643661804497242 with hyperparameters: [4, 87, 3, 256]\n",
            "The fitness was: 0.0065511008724570274 with hyperparameters: [3, 39, 2, 179]\n",
            "The fitness was: 0.007027422543615103 with hyperparameters: [3, 86, 2, 231]\n",
            "The fitness was: 0.00744587043300271 with hyperparameters: [3, 91, 3, 119]\n",
            "The fitness was: 0.007887057028710842 with hyperparameters: [3, 54, 3, 64]\n",
            "The fitness was: 0.007935186848044395 with hyperparameters: [4, 63, 2, 183]\n",
            "The fitness was: 0.008070768788456917 with hyperparameters: [4, 64, 1, 158]\n",
            "The fitness was: 0.00810674112290144 with hyperparameters: [3, 51, 3, 84]\n",
            "The fitness was: 0.008513066917657852 with hyperparameters: [3, 54, 2, 150]\n",
            "The fitness was: 0.00870724767446518 with hyperparameters: [3, 114, 3, 117]\n",
            "The fitness was: 0.008789333514869213 with hyperparameters: [3, 121, 2, 126]\n",
            "The fitness was: 0.009560958482325077 with hyperparameters: [3, 124, 3, 131]\n",
            "The fitness was: 0.010104617103934288 with hyperparameters: [3, 43, 3, 150]\n",
            "The fitness was: 0.010160251520574093 with hyperparameters: [4, 256, 1, 125]\n",
            "The fitness was: 0.010643417946994305 with hyperparameters: [3, 43, 3, 203]\n",
            "The fitness was: 0.010675131343305111 with hyperparameters: [4, 88, 1, 230]\n",
            "The fitness was: 0.010723882354795933 with hyperparameters: [3, 47, 2, 159]\n",
            "The fitness was: 0.01087321899831295 with hyperparameters: [4, 51, 2, 102]\n",
            "The fitness was: 0.011079052463173866 with hyperparameters: [4, 256, 2, 107]\n",
            "The fitness was: 0.01156560517847538 with hyperparameters: [3, 37, 1, 60]\n",
            "The fitness was: 0.011762818321585655 with hyperparameters: [3, 99, 3, 135]\n",
            "The fitness was: 0.012032130733132362 with hyperparameters: [3, 78, 2, 75]\n",
            "The fitness was: 0.01206908468157053 with hyperparameters: [4, 81, 2, 256]\n",
            "The fitness was: 0.012240883894264698 with hyperparameters: [3, 35, 3, 71]\n",
            "The fitness was: 0.013103424571454525 with hyperparameters: [3, 62, 2, 256]\n",
            "The fitness was: 0.013683452270925045 with hyperparameters: [4, 33, 2, 152]\n",
            "The fitness was: 0.013730968348681927 with hyperparameters: [4, 112, 3, 151]\n",
            "The fitness was: 0.013842443004250526 with hyperparameters: [4, 134, 2, 123]\n",
            "The fitness was: 0.013950888067483902 with hyperparameters: [4, 103, 3, 175]\n",
            "The fitness was: 0.014200879260897636 with hyperparameters: [3, 44, 3, 148]\n",
            "The fitness was: 0.015334589406847954 with hyperparameters: [3, 41, 2, 231]\n",
            "The fitness was: 0.01596270687878132 with hyperparameters: [4, 92, 2, 256]\n",
            "The fitness was: 0.01660977490246296 with hyperparameters: [3, 40, 1, 130]\n",
            "The fitness was: 0.01693265326321125 with hyperparameters: [3, 51, 2, 191]\n",
            "The fitness was: 0.017095113173127174 with hyperparameters: [4, 51, 1, 132]\n",
            "The fitness was: 0.018627140671014786 with hyperparameters: [4, 74, 3, 62]\n",
            "The fitness was: 0.018931405618786812 with hyperparameters: [3, 55, 3, 107]\n",
            "The fitness was: 0.01981399580836296 with hyperparameters: [4, 129, 3, 99]\n",
            "The fitness was: 0.019899172708392143 with hyperparameters: [4, 61, 3, 84]\n",
            "The fitness was: 0.020859895274043083 with hyperparameters: [4, 32, 3, 206]\n",
            "The fitness was: 0.021228458732366562 with hyperparameters: [3, 72, 1, 99]\n",
            "The fitness was: 0.022284135222434998 with hyperparameters: [4, 54, 2, 224]\n",
            "The fitness was: 0.022510401904582977 with hyperparameters: [4, 81, 3, 90]\n",
            "The fitness was: 0.023581575602293015 with hyperparameters: [4, 45, 3, 256]\n",
            "The fitness was: 0.02417045086622238 with hyperparameters: [4, 33, 2, 90]\n",
            "The fitness was: 0.02434242144227028 with hyperparameters: [4, 247, 1, 105]\n",
            "The fitness was: 0.02718012034893036 with hyperparameters: [2, 42, 3, 230]\n",
            "The fitness was: 0.027446266263723373 with hyperparameters: [3, 47, 3, 256]\n",
            "The fitness was: 0.028354911133646965 with hyperparameters: [4, 40, 1, 64]\n",
            "The fitness was: 0.02969410829246044 with hyperparameters: [4, 136, 3, 148]\n",
            "The fitness was: 0.029790416359901428 with hyperparameters: [3, 54, 1, 256]\n",
            "The fitness was: 0.029993314296007156 with hyperparameters: [4, 256, 1, 16]\n",
            "The fitness was: 0.031002534553408623 with hyperparameters: [3, 32, 3, 245]\n",
            "The fitness was: 0.031760118901729584 with hyperparameters: [3, 32, 1, 256]\n",
            "The fitness was: 0.03282007947564125 with hyperparameters: [3, 256, 1, 98]\n",
            "The fitness was: 0.03602778911590576 with hyperparameters: [3, 49, 1, 16]\n",
            "The fitness was: 0.03638707101345062 with hyperparameters: [4, 256, 1, 66]\n",
            "The fitness was: 0.03651561215519905 with hyperparameters: [4, 129, 2, 155]\n",
            "The fitness was: 0.03662727400660515 with hyperparameters: [3, 32, 3, 16]\n",
            "The fitness was: 0.03706834092736244 with hyperparameters: [2, 43, 2, 256]\n",
            "The fitness was: 0.03811848163604736 with hyperparameters: [2, 62, 2, 120]\n",
            "The fitness was: 0.0394321046769619 with hyperparameters: [4, 42, 1, 158]\n",
            "The fitness was: 0.041660334914922714 with hyperparameters: [2, 33, 3, 173]\n",
            "The fitness was: 0.04224339500069618 with hyperparameters: [2, 41, 2, 121]\n",
            "The fitness was: 0.04375762492418289 with hyperparameters: [4, 96, 3, 210]\n",
            "The fitness was: 0.04661763086915016 with hyperparameters: [3, 85, 1, 104]\n",
            "The fitness was: 0.04980003461241722 with hyperparameters: [3, 143, 3, 107]\n",
            "The fitness was: 0.050461653620004654 with hyperparameters: [4, 245, 1, 142]\n",
            "The fitness was: 0.05166434124112129 with hyperparameters: [4, 79, 3, 236]\n",
            "The fitness was: 0.056992821395397186 with hyperparameters: [2, 44, 1, 194]\n",
            "The fitness was: 0.058261554688215256 with hyperparameters: [3, 70, 2, 155]\n",
            "The fitness was: 0.059008918702602386 with hyperparameters: [3, 244, 1, 42]\n",
            "The fitness was: 0.0601067841053009 with hyperparameters: [4, 51, 1, 193]\n",
            "The fitness was: 0.06369225680828094 with hyperparameters: [2, 51, 3, 159]\n",
            "The fitness was: 0.07126327604055405 with hyperparameters: [2, 34, 1, 79]\n",
            "The fitness was: 0.07587596029043198 with hyperparameters: [2, 79, 2, 196]\n",
            "The fitness was: 0.07978815585374832 with hyperparameters: [2, 62, 2, 65]\n",
            "The fitness was: 0.08049033582210541 with hyperparameters: [4, 145, 2, 148]\n",
            "The fitness was: 0.08378204703330994 with hyperparameters: [2, 61, 3, 210]\n",
            "The fitness was: 0.08381210267543793 with hyperparameters: [2, 32, 3, 114]\n",
            "The fitness was: 0.09251874685287476 with hyperparameters: [2, 66, 1, 219]\n",
            "The fitness was: 0.10092916339635849 with hyperparameters: [2, 112, 2, 178]\n",
            "The fitness was: 0.10855510085821152 with hyperparameters: [2, 100, 1, 228]\n",
            "The fitness was: 0.12398432195186615 with hyperparameters: [2, 170, 3, 243]\n",
            "The fitness was: 0.1286948323249817 with hyperparameters: [2, 130, 1, 100]\n",
            "The fitness was: 0.13050317764282227 with hyperparameters: [2, 96, 2, 126]\n",
            "The fitness was: 0.1423262357711792 with hyperparameters: [2, 93, 3, 83]\n",
            "The fitness was: 0.14369404315948486 with hyperparameters: [2, 117, 2, 55]\n",
            "The fitness was: 0.1576075255870819 with hyperparameters: [2, 246, 3, 102]\n",
            "The fitness was: 0.16856509447097778 with hyperparameters: [2, 249, 2, 205]\n",
            "The fitness was: 0.18079975247383118 with hyperparameters: [2, 256, 3, 16]\n",
            "The fitness was: 0.19768938422203064 with hyperparameters: [4, 82, 3, 128]\n",
            "The fitness was: 0.20450769364833832 with hyperparameters: [2, 180, 1, 57]\n",
            "The fitness was: 0.2761814594268799 with hyperparameters: [3, 57, 1, 18]\n",
            "The fitness was: 0.2966793477535248 with hyperparameters: [4, 214, 3, 48]\n",
            "The fitness was: 0.31806379556655884 with hyperparameters: [4, 128, 3, 256]\n",
            "The fitness was: 0.42284369468688965 with hyperparameters: [3, 45, 3, 16]\n",
            "The fitness was: 0.5372177362442017 with hyperparameters: [3, 32, 1, 211]\n",
            "The fitness was: 1.3686927556991577 with hyperparameters: [3, 32, 1, 16]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9DIzm_-Oboq"
      },
      "source": [
        "The best hyperparameter set (according to the optimizer) it's shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpETQIxZVVZb",
        "outputId": "eb053b9a-374b-4933-f7f3-a3541cce44dd"
      },
      "source": [
        "# Resumo da busca, segundo o otimizador:\r\n",
        "print('Best fitness: %.4f' % (result.fun))\r\n",
        "print('Best hyperparameters: %s' % (result.x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best fitness: 0.0063\n",
            "Best hyperparameters: [3, 72, 3, 256]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCUX7BCnO4Wo"
      },
      "source": [
        "The amount of time spent in the 2nd stage of optimization it's shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa3cCRDXGVGA",
        "outputId": "b48cbdd4-9f88-4eb3-b2a2-a1dc5722886f"
      },
      "source": [
        "# Atributo \"iter_time\" evidencia o tempo (s) de cada iteração:\r\n",
        "times = TimerCallback.iter_time\r\n",
        "print('The time of each iteration is:', times)\r\n",
        "print('\\nThe total time spent in this optimization was:', sum(times), 'seconds.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The time of each iteration is: [113.57223463058472, 139.73756790161133, 110.67989659309387, 128.61989045143127, 120.44724678993225, 136.8393943309784, 152.36987257003784, 132.76317286491394, 117.91383290290833, 108.65076804161072, 167.4773509502411, 129.90924429893494, 101.64388418197632, 105.4949083328247, 95.34290528297424, 101.41025185585022, 111.50186920166016, 101.0194878578186, 120.33346509933472, 109.18593955039978, 120.62126231193542, 112.61713719367981, 105.69915890693665, 104.58468413352966, 130.4757535457611, 102.79886722564697, 123.77045845985413, 137.0669023990631, 104.83707618713379, 136.22201108932495, 105.75375723838806, 135.37232661247253, 133.14984273910522, 123.54477190971375, 98.95598220825195, 120.83720064163208, 117.39332294464111, 115.13914489746094, 101.52633738517761, 113.09741377830505, 129.40614700317383, 113.23984408378601, 115.5126519203186, 96.0610704421997, 96.58389711380005, 132.51911783218384, 112.8084979057312, 127.33247804641724, 129.8900797367096, 133.46328282356262, 100.64939665794373, 136.31991267204285, 122.62437891960144, 126.81746530532837, 130.37909388542175, 98.45313096046448, 122.90459609031677, 116.89467883110046, 113.07221293449402, 109.92258810997009, 146.60815978050232, 109.79945802688599, 113.70666813850403, 153.78994941711426, 103.10696125030518, 113.49373269081116, 112.26621389389038, 117.08566164970398, 121.70782017707825, 114.70700812339783, 96.21466374397278, 121.45050191879272, 104.68069076538086, 114.8669171333313, 137.54999160766602, 150.13024735450745, 132.67482089996338, 110.83536100387573, 103.22037434577942, 111.89886260032654, 100.58129096031189, 103.91950273513794, 113.06779336929321, 110.59769797325134, 96.53217649459839, 111.76787948608398, 125.40199875831604, 129.40899014472961, 157.2095558643341, 105.69761061668396, 107.34579229354858, 94.87164664268494, 127.13037347793579, 110.74049973487854, 127.88175201416016, 139.01573824882507, 166.43236780166626, 123.05674409866333, 122.94145822525024, 128.72426915168762]\n",
            "\n",
            "The total time spent in this optimization was: 11905.350319385529 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oveqB1fDhyX3"
      },
      "source": [
        "# 7.Independent test with the hyperparameters found set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOAKiXp-m0QR"
      },
      "source": [
        "**This section is dedicated to the execution and analysis (duplicate test) of the solution (set of hyperparameters) found by the 2nd optimizer.**\r\n",
        "\r\n",
        "* Observe that the experiment is based on a stochastic process, which hinders \"perfect\" reproducibility.\r\n",
        "* Accuracy/Loss plots and confusion matrix were implemented to verify the performance of the model found."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT4CoU1ujbsl"
      },
      "source": [
        "# EarlyStopping (O modelo pára o treinamento caso não perceba melhoria):\r\n",
        "earlystopping = EarlyStopping(monitor=\"val_accuracy\", min_delta=0, patience=100,\r\n",
        "                              verbose=1, mode=\"auto\", baseline=None,\r\n",
        "                              restore_best_weights=True)\r\n",
        "\r\n",
        "# TensorDash (acompanhamento das métricas do modelo pelo app Android):\r\n",
        "histories = Tensordash(ModelName = 'AutoML', email = 'viniciuswv@gmail.com',\r\n",
        "                       password = 'admin1')\r\n",
        "\r\n",
        "# Batch size (número de exemplos de treinamento usados em uma iteração/época):\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# Épocas (quantidade de ciclos de treinamento da rede neural):\r\n",
        "epochs = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmM_7fFOnQ23"
      },
      "source": [
        "**Function that creates the final architecture (like optimized on 2nd stage):**\r\n",
        "* (Before running the function, adjust the number of convolutional and dense layers, as well as their respective neurons)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJCDxyZ2jn4o"
      },
      "source": [
        "def final_model():\r\n",
        "  # Criação das camadas com apoio do recurso 'keras.sequential':\r\n",
        "  model = Sequential() # Empilha linearmente as camadas da rede, conforme abaixo:\r\n",
        "  # Camada de alimentação do dataset:\r\n",
        "  model.add(InputLayer(input_shape=(1666,1))) # O tensor de entrada tem o shape (1666, 1).\r\n",
        " \r\n",
        "  # 1ª camada convolucional:\r\n",
        "  model.add(Conv1D(72, kernel_size=4, strides=1, activation='relu', padding='same'))\r\n",
        "  # 1ª camada MaxPooling:\r\n",
        "  model.add(MaxPooling1D(pool_size=3, strides=None, padding='valid'))\r\n",
        "  # 1ª camada de normalização do batch:\r\n",
        "  model.add(BatchNormalization())\r\n",
        "  \r\n",
        "  # 2ª camada convolucional:\r\n",
        "  model.add(Conv1D(72, kernel_size=4, strides=1, activation='relu', padding='same'))\r\n",
        "  # 2ª camada MaxPooling:\r\n",
        "  model.add(MaxPooling1D(pool_size=3, strides=None, padding='valid'))\r\n",
        "  # 2ª camada de normalização do batch:\r\n",
        "  model.add(BatchNormalization())\r\n",
        " \r\n",
        "  # 3ª camada convolucional:\r\n",
        "  model.add(Conv1D(72, kernel_size=4, strides=1, activation='relu', padding='same'))\r\n",
        "  # 3ª camada de MaxPooling:\r\n",
        "  model.add(MaxPooling1D(pool_size=3, strides=None, padding='valid'))\r\n",
        "  # 3ª camada de normalização do batch:\r\n",
        "  model.add(BatchNormalization())\r\n",
        "  \r\n",
        "  # 4ª camada convolucional:\r\n",
        "  #model.add(Conv1D(232, kernel_size=4, strides=1, activation='relu', padding='same'))\r\n",
        "  # 4ª camada de MaxPooling:\r\n",
        "  #model.add(MaxPooling1D(pool_size=3, strides=None, padding='valid'))\r\n",
        "  # 4ª camada de normalização do batch:\r\n",
        "  #model.add(BatchNormalization())\r\n",
        "  \r\n",
        "  # Camada de achatamento (flatten):\r\n",
        "  model.add(Flatten())\r\n",
        "  \r\n",
        "  # 1ª camada densa (fully connected):\r\n",
        "  model.add(Dense(256, activation='relu'))\r\n",
        "  # 2ª camada densa (fully connected):\r\n",
        "  model.add(Dense(256, activation='relu'))\r\n",
        "  #3ª camada densa (fully connected):\r\n",
        "  model.add(Dense(256, activation='relu'))\r\n",
        "  # 4ª camada densa (fully connected):\r\n",
        "  model.add(Dense(16, activation='softmax'))\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "\r\n",
        "  # Programação da Taxa de Aprendizado (decaimento exponencial):\r\n",
        "  lr_schedule = keras.optimizers.schedules.ExponentialDecay(\r\n",
        "  initial_learning_rate=1e-2,\r\n",
        "  decay_steps=50,\r\n",
        "  decay_rate=0.95)\r\n",
        "\r\n",
        "  # Otimizador da rede:\r\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate= lr_schedule, name=\"SGD\")\r\n",
        "\r\n",
        "\r\n",
        "  # Compilação do modelo neural:\r\n",
        "  model.compile(loss='categorical_crossentropy',\r\n",
        "                optimizer= optimizer,\r\n",
        "                metrics=['accuracy'])\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIc9fePVnghI"
      },
      "source": [
        "Passing the necessary functions to subset data, train and evaluate the final model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaXZwntJjA2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de4f3c6c-47f7-4b1a-dacc-592cb98a212d"
      },
      "source": [
        "# Subset - lembrar de usar o mesmo subset usado no 1º estágio de otimização:\r\n",
        "X_train3, Y_train3, X_val3, Y_val3, X_test3, Y_test3, n_cases3 = subsetB(60)\r\n",
        "\r\n",
        "# Quando for rodar uma segunda vez, habilite o código abaixo:\r\n",
        "#del cnn\r\n",
        "#del final_model\r\n",
        "K.clear_session()\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "tf.compat.v1.reset_default_graph()\r\n",
        "\r\n",
        "# Instanciando a nova CNN:\r\n",
        "cnn = final_model()\r\n",
        "\r\n",
        "# Treino e validação:\r\n",
        "final_model, history3, acc_max3, train_time3 = fit_model(cnn,\r\n",
        "                                                         X_train3,\r\n",
        "                                                         Y_train3,\r\n",
        "                                                         X_val3,\r\n",
        "                                                         Y_val3,\r\n",
        "                                                         batch_size,\r\n",
        "                                                         epochs)\r\n",
        "\r\n",
        "# Teste:\r\n",
        "test_accuracy = test_model(X_test3, Y_test3, final_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1666, 72)          360       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 555, 72)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 555, 72)           288       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 555, 72)           20808     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 185, 72)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 185, 72)           288       \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 185, 72)           20808     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 61, 72)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 61, 72)            288       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4392)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               1124608   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                4112      \n",
            "=================================================================\n",
            "Total params: 1,303,144\n",
            "Trainable params: 1,302,712\n",
            "Non-trainable params: 432\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "20/20 [==============================] - 1s 21ms/step - loss: 2.1255 - accuracy: 0.3511 - val_loss: 2.7445 - val_accuracy: 0.1558\n",
            "Epoch 2/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6647 - accuracy: 0.8515 - val_loss: 2.7436 - val_accuracy: 0.1558\n",
            "Epoch 3/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.8589 - val_loss: 2.7364 - val_accuracy: 0.1169\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3492 - accuracy: 0.8687 - val_loss: 2.7346 - val_accuracy: 0.1169\n",
            "Epoch 5/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2729 - accuracy: 0.8876 - val_loss: 2.7422 - val_accuracy: 0.2078\n",
            "Epoch 6/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3667 - accuracy: 0.8266 - val_loss: 2.7463 - val_accuracy: 0.2078\n",
            "Epoch 7/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2315 - accuracy: 0.9083 - val_loss: 2.7772 - val_accuracy: 0.1558\n",
            "Epoch 8/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2729 - accuracy: 0.8733 - val_loss: 2.7863 - val_accuracy: 0.1558\n",
            "Epoch 9/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2085 - accuracy: 0.8859 - val_loss: 2.7931 - val_accuracy: 0.1558\n",
            "Epoch 10/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2016 - accuracy: 0.8849 - val_loss: 2.7852 - val_accuracy: 0.2013\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2044 - accuracy: 0.9061 - val_loss: 2.8095 - val_accuracy: 0.1558\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1775 - accuracy: 0.9065 - val_loss: 2.8239 - val_accuracy: 0.2078\n",
            "Epoch 13/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1884 - accuracy: 0.9180 - val_loss: 2.8364 - val_accuracy: 0.1558\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2528 - accuracy: 0.8643 - val_loss: 2.8174 - val_accuracy: 0.2078\n",
            "Epoch 15/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1698 - accuracy: 0.9099 - val_loss: 2.7517 - val_accuracy: 0.2078\n",
            "Epoch 16/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1714 - accuracy: 0.8984 - val_loss: 2.7142 - val_accuracy: 0.2792\n",
            "Epoch 17/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1531 - accuracy: 0.9222 - val_loss: 2.5763 - val_accuracy: 0.2078\n",
            "Epoch 18/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1757 - accuracy: 0.9030 - val_loss: 2.4794 - val_accuracy: 0.2662\n",
            "Epoch 19/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2128 - accuracy: 0.8921 - val_loss: 2.3575 - val_accuracy: 0.2078\n",
            "Epoch 20/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1433 - accuracy: 0.9330 - val_loss: 2.3569 - val_accuracy: 0.2273\n",
            "Epoch 21/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1419 - accuracy: 0.9421 - val_loss: 2.2049 - val_accuracy: 0.2403\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1850 - accuracy: 0.8953 - val_loss: 2.0677 - val_accuracy: 0.2792\n",
            "Epoch 23/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1727 - accuracy: 0.9201 - val_loss: 2.1932 - val_accuracy: 0.2273\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1856 - accuracy: 0.8984 - val_loss: 2.0807 - val_accuracy: 0.2403\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1799 - accuracy: 0.9081 - val_loss: 1.6589 - val_accuracy: 0.3312\n",
            "Epoch 26/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1439 - accuracy: 0.9283 - val_loss: 1.6339 - val_accuracy: 0.3247\n",
            "Epoch 27/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1294 - accuracy: 0.9341 - val_loss: 1.1741 - val_accuracy: 0.5130\n",
            "Epoch 28/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1129 - accuracy: 0.9505 - val_loss: 1.0492 - val_accuracy: 0.6039\n",
            "Epoch 29/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.1123 - accuracy: 0.9448 - val_loss: 0.6491 - val_accuracy: 0.7922\n",
            "Epoch 30/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0968 - accuracy: 0.9615 - val_loss: 1.2216 - val_accuracy: 0.7403\n",
            "Epoch 31/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1296 - accuracy: 0.9407 - val_loss: 0.7709 - val_accuracy: 0.7662\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1035 - accuracy: 0.9622 - val_loss: 0.3428 - val_accuracy: 0.9286\n",
            "Epoch 33/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0865 - accuracy: 0.9657 - val_loss: 0.5809 - val_accuracy: 0.8831\n",
            "Epoch 34/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0905 - accuracy: 0.9636 - val_loss: 0.4004 - val_accuracy: 0.9156\n",
            "Epoch 35/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0837 - accuracy: 0.9658 - val_loss: 0.4916 - val_accuracy: 0.8766\n",
            "Epoch 36/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0937 - accuracy: 0.9455 - val_loss: 0.7352 - val_accuracy: 0.7468\n",
            "Epoch 37/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1756 - accuracy: 0.9251 - val_loss: 1.3156 - val_accuracy: 0.6688\n",
            "Epoch 38/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1149 - accuracy: 0.9543 - val_loss: 0.8856 - val_accuracy: 0.8117\n",
            "Epoch 39/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0888 - accuracy: 0.9646 - val_loss: 1.0759 - val_accuracy: 0.5844\n",
            "Epoch 40/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.1052 - accuracy: 0.9706 - val_loss: 0.9769 - val_accuracy: 0.6818\n",
            "Epoch 41/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0945 - accuracy: 0.9610 - val_loss: 0.6004 - val_accuracy: 0.8831\n",
            "Epoch 42/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0769 - accuracy: 0.9626 - val_loss: 0.4420 - val_accuracy: 0.8247\n",
            "Epoch 43/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0781 - accuracy: 0.9673 - val_loss: 0.2873 - val_accuracy: 0.9026\n",
            "Epoch 44/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0725 - accuracy: 0.9577 - val_loss: 0.2964 - val_accuracy: 0.9351\n",
            "Epoch 45/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0755 - accuracy: 0.9781 - val_loss: 1.1303 - val_accuracy: 0.6169\n",
            "Epoch 46/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0961 - accuracy: 0.9727 - val_loss: 0.4586 - val_accuracy: 0.8831\n",
            "Epoch 47/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0679 - accuracy: 0.9919 - val_loss: 0.2717 - val_accuracy: 0.9221\n",
            "Epoch 48/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0620 - accuracy: 0.9776 - val_loss: 0.3641 - val_accuracy: 0.9740\n",
            "Epoch 49/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0462 - accuracy: 0.9988 - val_loss: 0.3560 - val_accuracy: 0.9805\n",
            "Epoch 50/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0673 - accuracy: 0.9767 - val_loss: 0.5642 - val_accuracy: 0.8766\n",
            "Epoch 51/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1286 - accuracy: 0.9342 - val_loss: 1.6235 - val_accuracy: 0.6169\n",
            "Epoch 52/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0678 - accuracy: 0.9734 - val_loss: 0.6813 - val_accuracy: 0.8117\n",
            "Epoch 53/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0565 - accuracy: 0.9968 - val_loss: 0.4341 - val_accuracy: 0.8052\n",
            "Epoch 54/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0453 - accuracy: 0.9963 - val_loss: 0.1235 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 0.9929 - val_loss: 0.3552 - val_accuracy: 0.9351\n",
            "Epoch 56/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 0.9991 - val_loss: 0.2235 - val_accuracy: 0.9870\n",
            "Epoch 57/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9968 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9870\n",
            "Epoch 59/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 1.2570 - val_accuracy: 0.5779\n",
            "Epoch 60/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0630 - accuracy: 0.9867 - val_loss: 0.5695 - val_accuracy: 0.7468\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.8442\n",
            "Epoch 62/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9740\n",
            "Epoch 63/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9805\n",
            "Epoch 64/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9805\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0144 - accuracy: 0.9998 - val_loss: 0.8190 - val_accuracy: 0.7143\n",
            "Epoch 66/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9961 - val_loss: 0.2895 - val_accuracy: 0.8377\n",
            "Epoch 67/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9286\n",
            "Epoch 68/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9740\n",
            "Epoch 69/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9935\n",
            "Epoch 74/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9870\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9545\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9286\n",
            "Epoch 79/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9935\n",
            "Epoch 85/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9481\n",
            "Epoch 93/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9416\n",
            "Epoch 101/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9935\n",
            "Epoch 104/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9870\n",
            "Epoch 105/500\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9935\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 0.9998 - val_loss: 0.0631 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9870\n",
            "Epoch 114/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9221\n",
            "Epoch 124/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9091\n",
            "Epoch 126/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9545\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9935\n",
            "Epoch 129/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9935\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9935\n",
            "Epoch 131/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9026\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9221\n",
            "Epoch 135/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9870\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00154: early stopping\n",
            "Training/validation time was: 95.4876 seconds\n",
            "\n",
            " \n",
            "EVALUATING THE MODEL:\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 1.0000\n",
            "Evaluate time was 0.2576 seconds\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKzfgPUwns-u"
      },
      "source": [
        "Plotting the results from the final model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LqT_obUmKbV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afdda508-97db-432b-d3c8-861159ff0ec7"
      },
      "source": [
        "# Acurácia:\r\n",
        "plt.figure(figsize=(8,8))\r\n",
        "plt.plot(history3.history['accuracy'])\r\n",
        "plt.plot(history3.history['val_accuracy'])\r\n",
        "plt.title('Train_acc vs. val_acc', fontsize=20)\r\n",
        "plt.xlabel('Epoch',fontsize=18)\r\n",
        "plt.ylabel('Accuracy',fontsize=18)\r\n",
        "plt.legend(['Train', 'Validation'], loc='best', fontsize=18)\r\n",
        "plt.show()\r\n",
        "#Para salvar no Drive...\r\n",
        "#plt.savefig('/content/drive/My Drive/MESTRADO - UFES/trainacc_vs_valacc.png', transparent=True)\r\n",
        "\r\n",
        "# Perda (loss):\r\n",
        "plt.figure(figsize=(8,8))\r\n",
        "plt.plot(history3.history['loss'])\r\n",
        "plt.plot(history3.history['val_loss'])\r\n",
        "plt.title('Loss vs. epochs', fontsize=20)\r\n",
        "plt.ylabel('Loss',fontsize=18)\r\n",
        "plt.xlabel('Epoch',fontsize=18)\r\n",
        "plt.legend(['Train', 'Validation'], loc='best', fontsize=20)\r\n",
        "plt.show()\r\n",
        "#Para salvar no Drive...\r\n",
        "#plt.savefig('/content/drive/My Drive/MESTRADO - UFES/trainloss_vs_valloss.png', transparent=True)\r\n",
        "\r\n",
        "print('Max val_acc was:',acc_max3)\r\n",
        "print('Eval_acc was:',test_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Max val_acc was: 1.0\n",
            "Eval_acc was: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5csKZiCg_AV"
      },
      "source": [
        "Function that creates the **confusion matrix**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A087XBWugrHd"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\r\n",
        "                          normalize=False,\r\n",
        "                          title='Confusion matrix',\r\n",
        "                          cmap=plt.cm.Blues):\r\n",
        "    \"\"\"\r\n",
        "    This function prints and plots the confusion matrix.\r\n",
        "    Normalization can be applied by setting `normalize=True`.\r\n",
        "    \"\"\"\r\n",
        "    if normalize:\r\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
        "        print(\"Normalized confusion matrix\")\r\n",
        "    else:\r\n",
        "        print('Confusion matrix, without normalization')\r\n",
        "\r\n",
        "    print(cm)\r\n",
        "\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
        "    plt.title(title, fontsize= 20)\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(classes))\r\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\r\n",
        "    plt.yticks(tick_marks, classes)\r\n",
        "\r\n",
        "    fmt = '.2f' if normalize else 'd'\r\n",
        "    thresh = cm.max() / 2.\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\r\n",
        "                 horizontalalignment=\"center\",\r\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.ylabel('Classe Correta', fontsize=18)\r\n",
        "    plt.xlabel('Classe Predita', fontsize=18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxGmq3tMeihJ"
      },
      "source": [
        "The **confusion matrix** of test data it's shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmwLk9GqzsYI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87c04cc0-6996-47a6-fd8f-62ac371ef740"
      },
      "source": [
        "y_test_pred = final_model.predict(X_test3)\r\n",
        "\r\n",
        "# \"Desbinarização\" dos labels:\r\n",
        "# (Labels estão binarizados; matriz de confusão não aceita)\r\n",
        "Y_test_non_category = [np.argmax(t) for t in Y_test3]\r\n",
        "y_test_pred_non_category = [np.argmax(t) for t in y_test_pred]\r\n",
        "\r\n",
        "cnf_matrix = confusion_matrix(Y_test_non_category, y_test_pred_non_category)\r\n",
        "class_names = np.arange(0,16)\r\n",
        "\r\n",
        "# Matriz de confusão não normalizada:\r\n",
        "plt.figure(figsize = (10,7))\r\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names,\r\n",
        "                      title='Non-normalized confusion matrix')\r\n",
        "\r\n",
        "# Matriz de confusão normalizada:\r\n",
        "plt.figure(figsize = (10,7))\r\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\r\n",
        "                      title='Normalized confusion matrix')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[ 8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 12  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14]]\n",
            "Normalized confusion matrix\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAIGCAYAAACyMk4oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdfZwVZf3/8dcH1vUO40ZEZRdUWANZI41FLBJNLEwQu5HAb5ZEiqml/krNtNKy0lAzyqzwXiswvCO8AU1TS1NkRQkhBQVkl7wL8BZcOXx+f8wsHZe9OWd3zpwzs+8nj/PYPTNzrvd1zTm7ezFzzVzm7oiIiIikVZdiV0BERESkkNTZERERkVRTZ0dERERSTZ0dERERSTV1dkRERCTV1NkRERGRVFNnR6RAzGyVma1qsmyymbmZTS5OrT7IzB4ys0Tff8LMPmNmj5nZhnDf3hlD5g1h1t6FzuoszOzCcJ8eVuy6SPqUFbsC0rKsP0IvAYPcfVMz26wC9gK2c/fNMVZPpOjCzsYcYANwHfAm8O8iVqnTMrOHgEPd3YpdF5Gm1NlJhv7AmcAlxa6IdNgdwOPAf4pdkZQ4AtgB+I67/ynG3O8R/DzWx5iZdlcCswj+cycSKXV2St96wIFzzewad3+92BWS9nP3N4A3il2PFOkbfl0bZ6i7/wd1WCMV/m7T7zcpCI3ZKX3vAhcB3YEL8nmhmX3JzB4xszfMbKOZ/cvMvmdm2zez7arwsbOZXWpmL5nZe2a2wsy+a2Z5HZpub3ntrPOHzOwX4ffvm9mFTdZ3M7MrzGxNWObTZva5cJsyMzvfzJab2SYze8HMvtlMVrmZfdPM7jGz1WFb1pnZX83ss3nsl23G7GSN/2jpsaqZco4zs7+F41Q2mdkyM/t+c/sp3H6SmdWG7X/VzG42s77NbZtDGyrN7FfhPtsY7ocFZvaDZrYdZma3hZnvhfvuKjPbs5ltt46DMbOTw/d+k5m9YmYzzKx71raHhad5fxQu+lvW/jos3GabMVNZr292fIiZHWJmc82sLqzvy2b2uJld0GS7FsfstPMz3OGfOwvHX5nZdmb2w/CzvMnMnjOzk7K2+0ZYp41hO39kZtv8LQg/q7eZ2Yvhtm+a2aNmdnyT7fYO34tDw+fZn92HmmlrSz+v27wnZjY9XPaLZur39XDd/c3VXySbjuwkw2+AbwInm9mv3H15Wy8ws58RHGp/HfgT8DbwWeBnwBgz+4y7NzR52XbAfIL/Ld8LbAY+R3C4fgf+94clV3mV1846lwMPAr2A+wjGbKxsUof7w/Vzwu2PA24zs88ApwIjwvq9B0wAfm1mr7n7LVnl9AKmA4+F5b0G7AkcDdxjZie5+zV57p9GdwKrmln+EeALBB3erczsOuBrQB1wG8F4lYMJOsWjzezT2eO3zOz/Ab8It7sp/DombEteR5nMrIbgPe0FPALcDuwEDAEuDOvQuO24sH4G3AqsBoYBpwDHmNkn3T37vWo0LazfXIL39FPASUAVcHi4zSqCz89hBH9kb+R/+7Dxa17M7EjgboLP0F8ITlH1AvYj+Jy0+fkvkZ+7WQSf6XuA94FjgRlm9j4wFDgBuAt4ABgP/JDgM/bzJuX8FniW4H3+D7ArcBRws5kNcvfGzu2GsI6TCcYPZtd3VZMy2/p5beps4JPAmWb2gLvfDWBm1cCvgJeB4919S2s7RAR316NEHwSnr+rC748Nn9/eZJtV4fKyrGUfD5e9BOyRtbyM4A+IA+e1UM49wI5Zy/sQ/DLbQDAIOte651VeB+v8V2DnVuowF9g+a/kh4fJ1wJNAj6x1A4AGYFGTsrYHKpvJ6A4sCcvasZn8VU2WTQ6zJ7ex/yoJOjMbgYObef3tzeRdGK47I2vZ3mF71gF7Zy3vQtAR8eDXQE7vaTnBHyYH/q+5Omd93w34L5ABDmmy3XfDMu5rsvyGrM9A/yafgUfCdQe10ObDWnj/V7XQlm1el7U/PtrM9r1bqGv2Pi3qzx3wUFhWS5/p9eH7V5G1rgdBx+w1sn6HhOsGtvAZeICgE1XRXH4r9Wtsa0s/r82+lwSd3DfDOlYQdK6XhJ+t0bnsGz30KHoF9Gjlzcnq7ITPHwuXfTJrWeMvkOzOztXhsqnNlPnh8JfEi02WN5ZT1cxrbgzX7Z9H3fMqr4N13uaPU5P1zf3SfjFcd3gz6/4W/jLvmmNbvx2WNaqZ/FVNlk2mjc4OsAvwDLAFOLbJukVh3Xo087qu4R+uBVnLzg/zftTM9gPC/eo5tvOLYVlzctj2y+G2f2pmXRn/6zRld2puCJed2Mxrvhau+2aT5RcSfWfnwzm0r7Gue0f0Ge7wzx3/6+xs0wEgOJriwJRm1l0frtsrx5wvhNt/tbn8Vl7X2NaWfl5bey8nheseJrjqzoGf5FJfPfRwd53GSpjvEHR4LiM4bdGSj4VfH2y6wt2fN7M6YB8z6+7BgNlGb7j7imbKWxN+7dm4oPE8exM3uPuq9pTXgTpvAhY3k9Fog7u/0MzytcA+QG0z6+oJ/iDvQdbVNuGh87OBUQSnsHZo8rqKVuqREzPrCvyZ4HTDOe5+a9a6nYCPEnRozmxhOMd7BKddGjXu14ebbujuL5rZGoJTD7lo/Mzdm8O2rb2fm83sEYKjTgey7dU3C5spr7nPTNT+SPCH/Akzu4Wg0/uou9fl+PqC/9zlqLn91ziAu6XPOwRHE1c3LjSz/gRH4UYTXBG6Y5PXtefz3tbPa7PcfZaZjQZOJPj5+wd5jmGUzk2dnQRx93+a2a3AsWY20T84piRb40DOlq4W+Q/BL68efHDMxoYWtm8c/9E1a1lzv2ge4oPn6PMpr711ftXdvYXXQMtjUjbD1qujWqrfdo0LzOxggj9iZQSH8f9CcGh9C3AAcAzBqa6O+g1wJPB7d7+0ybqeBONfdiP3X/SN+/WVFta/TO6dnR7h11wut87l/cwuM1tzn5vmPjORcvfbw3FG3wGmACcDmFkt8D13v7+NIuL4uWtTG5/pXD/vA4AFBJ+5vxOMr3mD4OjU3gTjftrzeW/r57U1txJ0dgB+7e6ZdpYjnZA6O8nzPYI/rBeb2R0tbNP4C20PoLmjGns22S5vHv2Nw9pb5/b+4szX9wn+Z/spd38oe4WZNb4nHWJm5xD8gb0XOK2ZTRrbvsjdP9bM+uY0vmZ3gsGmTe2RRxUb/yjn8j/67PezOR3+DOZgC8EYk+Y018nCgwGwd5vZzgSDfMcRDKi+y8wOdPelreQV/OcuRt8mGJD8NXe/IXuFmR1H0Nlpj3b9vJpZb+Ba/jdY/woz+5u7v9bOekgno8v1EiY83H0VwSmYb7Ww2aLw62FNV5hZFcHh6pXu3tL/KIuh1OtcBaxr2tEJHdrRws3sWIKrb54BJjb3v1Z3f5ugw1JtZr1yLPqpluoY/u+9Xx7VfDz8msul9q29n2UEg8Sz61cI64HdzWy7ZtbVtPZCd3/H3R90928TXElVTtvtLvXPcD6qwq+3NbOupc97Braeio1MePn9jQSd7DPCR1/gpnwuzZfOTZ2dZPoxwf+yzye46qWp68Kv3zez3RoXhr+ELiN4368tdCXzVOp1XgX0MrOh2QvN7OsEl0m3m5l9HLiZYFzFWHd/q5XNf0Hwh/c6M9vm6ISZ9TSz7KM+fyQY0Pwty7onTHhfkkvJ73fAXIL9MD78333T7Mqsp3cSXAF2XHgKMNuZBJ31v7p7Ie+Wu4Dg6PXXmtRzMjCy6cZmNirsiDW1e/j13WbWZSv1z3A+VoVfD8teaGZj+N+ppKb+G37tH3Fdvk1wyfst7n6NB7d4uIXgdO/ZEWdJSuk0VgK5+7rwfh7TWlj/mJlNA84BloTjfN4h+J/p/gSD+5qOBymqBNT5lwSdmn+Y2Z8JTkXUENwD5FaCWwO017UEg52fAE5q5j+rG9z9lwDufp2ZDSO478sLZjafYIBvL4IOxCiCq2u+EW6/yszOBS4HFoUDb98I29KDYLDoUHLg7g1mNoFg/MafzOxkgqM9OxAMih5N+DvF3d82synAbOBhM5sd1nMY8BmCsUIn57OT2uHXBB2d34aDW9cQjK/6OMF9ZsY12f5XQIWZPUrwx74hrO/hBAN3Z7UWloDPcD6uIth3s8N2rCVow5EEA+gnNvOaBwjuU3W7md1DcNuE1e5+c3srYWbDgYsJrt7L/rxMBYYDPzWzR9z98eZeL9JInZ3k+hXBH7y9m1vp7t81s0UENyP8KsHgwxcIxp5c7tve2KzoSrnO7j7PzI4O6zKR4JD9AoIb3g2gY52dncKvXwgfTa0m6Gw11uU0M7uXoENzBEGnZR1BZ+JS4A9N6v4LM/sPwf+CJwNvEdzE7hyCG9/lzN0XmtkBwLkEf8Q/EZa3guDmdNnbzjGzkcB5BJ2r7gSdnN8BF7l7Qad4cPelZnYEwWmoowkG4v6doLPzBbbt7PwM+DxBJ/YIgjE/L4XLf+nu63PILNnPcD7cfbGZfQr4CTCW4G/FMwT7bQPNd3auIRjsPongs1VGcBVguzo7Ftwxu/EijEnZA6/d/U0zmwg8CswMx1Ml4fSgFIm1f2C8iIiISOnTmB0RERFJNXV2REREpOSY2XUWTCK8pMnyb5nZv83s2XCcXJvU2REREZFSdAPBoPitwrFkxxBMO1JNcKVjm9TZERERkZLj7o8QXHyR7RTgEnd/L9zm1VzKSsXVWDt+qKfv0qfD0xLlpF/3ptMhiYiIRGv16lW8/vrrJXHTxK4f2st988bIy/WNrz1LMF9aoxnuPqONl30YOMTMfhq+9ix3f7KtrFR0dnbpU8GEaX+OJevy8UNiyRERkc5r5IhWb/IdK9+8ke0HfSnycjc9/ZtN7p5vQ8sI7it2MMG9lv5sZgPamnNNp7FEREQkKeqA2z2wgOB+WL3bepE6OyIiItIKA+sS/aN97iS4mStm9mGC6XNeb+tFqTiNJSIiIgViQBHmXDWzmQTzs/U2szrgAoI56K4LL0dvAE5o6xQWqLMjIiIiJcjdt5lwOHR8vmWpsyMiIiKta/9pp5KQ7Nq30zNzb2TmGeOZdeYx3PeLs9jc8F5B8+6bP4+h1YOoHlzFpdMuUVYC8tS25GXFnZfWrLjz1DaJQ6fr7Lz931dYfM8fmTDtz0z65Rx8yxZW/OOeguVlMhnOPP005sy9l0WLlzJ71kyWLV2qrBLOU9uSlxV3Xlqz4s5T2xLELPpHjDpdZwdgSybD5oZNbMlsZnPDJnbq1adgWU8uWMDAgVXsM2AA5eXlTJg4ibvmzlFWCeepbcnLijsvrVlx56ltSVFSV2O1S6fr7HTbdXcOGD+Zm75xBDeceBjlO3Wj/wEjC5a3dm09lZX9tj6vqKikvr5eWSWcp7YlLyvuvLRmxZ2ntklcSrKzY2ZHmtlzZrbCzM6NsuxNb7/Bqicf5CtX3ccJV/+NzZs28tzDc6OMEBERSRedxoqWmXUFfgN8FhgCHGdmkc3RULf4cXbpU8mO3XvRtWw79jn4CF5+blFUxW+jb98K6urWbH1eX19HRUVh5vFKa1bceWpb8rLizktrVtx5apvEpeQ6O8BBwAp3f9HdG4BZBNO5R2KX3nvyyvPP8P57G3F36v/1OD0rB0ZV/DZqhg9nxYrlrFq5koaGBmbfMoux48Yrq4Tz1LbkZcWdl9asuPPUtoQwEj9mpxTvs1MBrMl6XgeMaLqRmU0FpgJ0671nzoXv/uGhDPz4Z5h91gS6dO1K7332o/rTEzpY5ZaVlZVxxfQrOXrsGDKZDCdMnsKQ6mpllXCe2pa8rLjz0poVd57aJnGxHO6yHCszOxY40t1PDJ9/BRjh7t9s6TV9qvZ3zXouIiJpMXJEDbW1C+Ofo6EZXbrt6dt/5ITIy930+M9r2zHrebuU4pGdeqBf1vPKcJmIiIgUg+6gHLkngX3NbB8zKwcmAX8pcp1EREQkoUruyI67bzazbwLzga7Ade7+bJGrJSIi0nkVYdbzKJVcZwfA3e8BCjeHg4iIiHQaJdnZERERkVJhiR+zo86OiIiItMxI/GmsZHfVRERERNqgIzsiIiLSuoSfxkp27UVERETaoCM7IiIi0orkD1BOdu1FRERE2pCKIzv9uu8Q25xVPSdcHUtOo/WzT4o1T0REZBtdkn01Vio6OyIiIlIghk5jiYiIiJQyHdkRERGR1ummgiIiIiKlS0d2REREpBXJv/RcnR0RERFpnU5jJc998+cxtHoQ1YOruHTaJZGX/7tvjmL1DcezcPoXt1l3xviPsPGOk9h1l+0jz4XCt61YWXHnqW3Jy4o7L61ZceepbRKHTtfZyWQynHn6acyZey+LFi9l9qyZLFu6NNKMmx98nmN+fO82yyt33ZnRB1Ty0qtvRZrXKI62FSMr7jy1LXlZceelNSvuPLUtQaxL9I8YdbrOzpMLFjBwYBX7DBhAeXk5EyZO4q65cyLNeHTpy6x7671tlk+bcjDn3/QEHmna/8TRtmJkxZ2ntiUvK+68tGbFnae2SVw6XWdn7dp6Kiv7bX1eUVFJfX19wXPHHbQXa9e9y79WrStYRpxti3s/qm3KKqW8tGbFnae2JYRZYR4xKsnOjpldZ2avmtmSYtclCjuWd+WcLx7Aj2cuLHZVREREOp2S7OwANwBHFqLgvn0rqKtbs/V5fX0dFRUVhYjaasAeH2Kv3XdhwRVf5N+/n0TFrjvzz8u/wO49dow0J862xb0f1TZllVJeWrPizlPbEkRjdqLn7o8ABTnfUzN8OCtWLGfVypU0NDQw+5ZZjB03vhBRWz370nr2mvwHBp88i8Enz6L+v+/w8e/czisbNkaaE2fb4t6PapuySikvrVlx56ltCZLw01iJvc+OmU0FpgL0698/59eVlZVxxfQrOXrsGDKZDCdMnsKQ6upI63bjtz/FIdV96f2hHVhx9XFcNOspbnzguUgzmhNH24qRFXee2pa8rLjz0poVd57aJnEx90JdG9QxZrY3cJe779/WtsOG1fijT8QzHqbnhKtjyWm0fvZJseaJiEjxjRxRQ23twpK4k1+X7v19+5HfibzcTfeeWevuNZEX3IySPI0lIiIiEpXEnsYSERGRmGi6iOiZ2Uzgn8AgM6szs68Xu04iIiKdkpH4q7FK8siOux9X7DqIiIhIOpRkZ0dERERKhcV+JCZqya69iIiISBt0ZEdERERapwHKIiIiIqVLR3ZERESkdRqzIyIiIqlWhLmxzOw6M3vVzJY0s+47ZuZm1juX6quzIyIiIqXoBuDIpgvNrB/wGeClXAtSZ0dERERaZlaUmwq6+yPAumZWXQGcA+Q8uafG7OQp7ok5v/qHp2LLuun4j8WWJSIinV5vM8uexXuGu89o7QVmdgxQ7+7PWB5XiKmzIyIiIq0rzKXnr+cz67mZ7QScR3AKKy/q7IiIiEir8jmKUkADgX2AxqM6lcBTZnaQu7/c2gvV2REREZGS5+7/Avo0PjezVUCNu7/e1ms1QFlERERaZARHdqJ+tJlrNhP4JzDIzOrM7OvtbYOO7IiIiEjJcffj2li/d65lqbMjIiIiLbPwkWCd8jTWffPnMbR6ENWDq7h02iWpyvvsfrtx2TH7cfkx+3HUkN0KmpXm/ai2JS8r7ry0ZsWdp7ZJHDpdZyeTyXDm6acxZ+69LFq8lNmzZrJs6dJU5PXrsQOjP9yb8+76N2f/ZRkfq+zO7rtsX5CsNO9HtS15WXHnpTUr7jy1LSmiH68T99Vdna6z8+SCBQwcWMU+AwZQXl7OhImTuGvunFTkVXTfgRWvvUNDxtnisOzltxmxV4+CZKV5P6ptycuKOy+tWXHnqW3Joc5OwqxdW09lZb+tzysqKqmvr09F3poNmxi8eze6bd+V8q7GgZUfYtedtytIVpr3o9qWvKy489KaFXee2iZxKbkByuEEXzcBuxPMezHD3acXt1bJUP/GJuYseYXvf3pfNm3OsGrdRrbkPHOIiIhI80rkpoLtVnKdHWAz8B13f8rMdgFqzex+d4/kZGffvhXU1a3Z+ry+vo6Kioooii6JvL8t/y9/W/5fAI77WF/++05DQXLSvB/VtuRlxZ2X1qy489Q2iUvJncZy9/+4+1Ph928By4DIPiE1w4ezYsVyVq1cSUNDA7NvmcXYceOjKr7oeR/aIei/7rrzdhy0Vw/+sXJ9QXLSvB/VtuRlxZ2X1qy489S25Ej6mJ1SPLKzlZntDRwIPNHMuqnAVIB+/fvnXGZZWRlXTL+So8eOIZPJcMLkKQypro6mwiWQ951PDWCX7buyeYtz7eNreLchU5CcNO9HtS15WXHnpTUr7jy1LSFScJ8dcy/NQR1m1g14GPipu9/e2rbDhtX4o08sbG2TxPrqH56KLeum4z8WW5aIiLRs5IgaamsXlkQXo+uu+3i3MT+OvNw3Z361Np9ZzzuiJI/smNl2wG3AH9vq6IiIiEjhGPGfdopayY3ZsWCPXgssc/dfFLs+IiIikmyleGRnJPAV4F9m9nS47Dx3v6eIdRIREem0kn5kp+Q6O+7+DxI/FEpERERKRcl1dkRERKS06MiOiIiIpFrSOzslN0BZREREJEo6siMiIiItS8FNBXVkR0RERFJNR3ZERESkVUkfs6POjoiIiLQoDXdQVmenxMU5X9VRVz0WWxbAPad+ItY8ERHpnNTZERERkVYl/ciOBiiLiIhIqunIjoiIiLQu2Qd2dGRHRERE0k1HdkRERKRllvwxO+rsiIiISKuS3tnplKex7ps/j6HVg6geXMWl0y5JVV6hs84ePZDbThzOtV8+YOuyXbYvY9rnhnDTVw9k2ueG0G37rpHnQrr2YzHz0poVd15as+LOU9skDp2us5PJZDjz9NOYM/deFi1eyuxZM1m2dGkq8uLImr/sNc6d88Eyj6upYNGaN/jqTYtYtOYNjhtWGWkmpG8/FisvrVlx56U1K+48tS05zCzyR5w6XWfnyQULGDiwin0GDKC8vJwJEydx19w5qciLI2vx2jd5c9PmDywbOaAX85e9CsD8Za/yyYG9Is2E9O3HYuWlNSvuvLRmxZ2ntklcOl1nZ+3aeior+219XlFRSX19fSry4m5bo547bce6d98HYN2779Nzp+0iz0jzfkxr27Qfk5cVd57algyN00Uk+chOyQ1QNrMdgEeA7Qnqd6u7X1DcWkk+3ItdAxERiVSyxyeX5JGd94DD3f2jwAHAkWZ2cFSF9+1bQV3dmq3P6+vrqKioiKr4oubF3bZG6999n17h0ZxeO23Hho3vR56R5v2Y1rZpPyYvK+48tU3iUnKdHQ+8HT7dLnxEdqygZvhwVqxYzqqVK2loaGD2LbMYO258VMUXNS/utjV67MV1jNmvDwBj9uvDoy+uizwjzfsxrW3TfkxeVtx5altCWPIHKJfcaSwAM+sK1AJVwG/c/YlmtpkKTAXo179/zmWXlZVxxfQrOXrsGDKZDCdMnsKQ6uqIal7cvDiyvj9mXz5a2Z3uO5Rxy5Rh3PD4GmbW1vPDz36Yz1b34ZU33+PH9z4faSakbz8WKy+tWXHnpTUr7jy1TeJiXsIDLMysB3AH8C13X9LSdsOG1fijTyyMr2IpddRVj8Wad8+pn4g1T0QkKUaOqKG2dmFJjJQp71PlfY69LPJy63/7+Vp3r4m84GaU5JGdRu6+wcz+BhwJtNjZERERkcLRHZQjZma7hUd0MLMdgU8D/y5urURERCSpSvHIzp7AjeG4nS7An939riLXSUREpPNK9oGd0uvsuPti4MBi10NERETSoeQ6OyIiIlJaNGZHREREpITpyI6IiIi0qBg3AYyaOjsiIiLSqqR3dnQaS0RERFJNnR0RERFpVTHmxjKz68zsVTNbkrXsUjP7t5ktNrM7Gu/L1xZ1dkRERKQU3UAwg0K2+4H93X0o8DzwvVwKUmdHREREWmcFeLTB3R8B1jVZdp+7bw6fPg5U5lJ9DVCWreKemLPnERfFlrX+rz+ILUtEJG0KNEC5t5llz+I9w91n5PH6KcAtuWyozo6IiIgUw+vtnfXczM4HNgN/zGV7dXZERESkZVZal56b2WRgHDDa3T2X16izIyIiIolgZkcC5wCHuvu7ub5OnR0RERFpkQHFOLBjZjOBwwjG9tQBFxBcfbU9cH94tOlxd/9GW2WpsyMiIiIlx92Pa2bxte0pq1Neen7f/HkMrR5E9eAqLp12Sary0pT1u3OOZvUd32bh9SdvXXb+5FG8MPsMHr/mJB6/5iTGjKiKPBf0GUliVtx5ac2KO09tS4LobygY9xigTtfZyWQynHn6acyZey+LFi9l9qyZLFu6NBV5acu6ed4zHHPOn7ZZ/utbn+DgE6/m4BOvZv4TKyLNBH1GkpgVd15as+LOU9uSwyz6R5w6XWfnyQULGDiwin0GDKC8vJwJEydx19w5qchLW9aji19i3VsbIy0zF/qMJC8r7ry0ZsWdp7ZJXDpdZ2ft2noqK/ttfV5RUUl9fX0q8tKa1dQ3Pj+cBddO5XfnHE2PbjtEXr4+I8nLijsvrVlx56ltyaHTWAViZl3NbJGZ3VXsukjpuHpOLUP+70pGnDiDl//7Npec+uliV0lEREpcyXZ2gDOAZVEX2rdvBXV1a7Y+r6+vo6KiIuqYouSlNSvbq+vfYcsWxx2uu/spavbrG3mGPiPJy4o7L61ZceepbQlRgPE6GrMDmFklMBa4Juqya4YPZ8WK5axauZKGhgZm3zKLsePGRx1TlLy0ZmXbo1e3rd8f88nBLF35WuQZ+owkLyvuvLRmxZ2ntiWDAV26WOSPOJXqfXZ+SXCHxF2iLrisrIwrpl/J0WPHkMlkOGHyFIZUV0cdU5S8tGXd+IPPc8gBe9G7+06smH0GF13/MKMO2IuhVXvg7qx++Q2+dfndkWaCPiNJzIo7L61ZceepbRIXy3FaidiY2TjgKHc/1cwOA85y93HNbDcVmArQr3//Yc+/sDreikqHadZzEZHmjRxRQ23twpKYkGrHPT/sA6ZcGXm5S382pra9E4HmqxRPY40ExpvZKmAWcLiZ/aHpRu4+w91r3L1mt967xV1HERERSYiS6+y4+/fcvdLd9wYmAQ+6+/FFrpaIiEinpUvPRURERDBhaGwAACAASURBVEpYqQ5QBsDdHwIeKnI1REREOq8iXCoetZLu7IiIiEhxGcR+2ilqOo0lIiIiqaYjOyIiItKK+AcUR01HdkRERCTVdGRHREREWpXwAzvq7IiIiEjrdBpLREREpITpyI6IiIi0TPfZEWm/OCfn3O/s6GdHb82yS8fGmiciIi1TZ0dERERapJsKioiIiJQ4HdkRERGRViX8wI46OyIiItI6ncYSERERKWE6siMiIiKtSviBnc55ZOe++fMYWj2I6sFVXDrtklTlpTWr0Hk/nzSUJ398BPPOGbV12feOHsxfzz2Ue88+hN99bRi77FC4/xuk9X1L02eks2TFnae2SRw6XWcnk8lw5umnMWfuvSxavJTZs2aybOnSVOSlNSuOvNsW1DF5xoIPLPvH868zZtojfPbSv7PytXc49YiqyPKypfV9S9tnpDNkxZ2ntiWEBWN2on7EqdN1dp5csICBA6vYZ8AAysvLmTBxEnfNnZOKvLRmxZG34MV1bHjn/Q8s+/tzr5PZ4gAsWr2ePXrsEFletrS+b2n7jHSGrLjz1LZkCO6zE/0jTp2us7N2bT2Vlf22Pq+oqKS+vj4VeWnNKkZeU18a0Y+Hl71WkLLT+r6l+TOS1qy489Q2iUtJDlA2s1XAW0AG2OzuNcWtkXRmpx1RxeaMc2etflGJSGcU/2mnqJVkZyf0KXd/PepC+/atoK5uzdbn9fV1VFRURB1TlLy0ZhUjr9EXh1dyeHUfvnzV4wXLSOv7lubPSFqz4s5T2yQune40Vs3w4axYsZxVK1fS0NDA7FtmMXbc+FTkpTWrGHkAowbvxsmHD+Ckaxay6f0tBctJ6/uW5s9IWrPizlPbkiPpY3ZK9ciOA/eZmQO/d/cZTTcws6nAVIB+/fvnXHBZWRlXTL+So8eOIZPJcMLkKQypro6q3kXNS2tWHHnTv3IAB1ftSs+dy3nsgsP55bzlnDJ6IOVlXbj5lIMAWLR6A9+fvSSyzEZpfd/S9hnpDFlx56ltEhdz92LXYRtmVuHu9WbWB7gf+Ja7P9LS9sOG1fijTyyMr4KSOPudfXesecsuHRtrnoiky8gRNdTWLiyJgTLdKgf7R8+4OvJyHztnVG1cY3JL8jSWu9eHX18F7gAOKm6NREREOqkCnMLq9Jeem9nOZrZL4/fAZ4Dozx2IiIhIp1CKY3Z2B+4IL3MrA/7k7vOKWyUREZHOKbipYEmcUWu3kuvsuPuLwEeLXQ8RERFJh7w6O2bWE/g6MALoybanwdzdR0dUNxERESkBnebIjpntBTwK9AXeAD4ErON/nZ7XgXcKUEcREREpooT3dfIaoPwToAcwGtiX4DTeRIJOz8UE0zscEnUFRURERDoin87OaOBqd/8bwU3/ILhPz7vufj7wL+DnUVdQREREisvMIn/EKZ/Ozq787xLw98OvO2atvx/4dBSVEhEREYlKPp2d14Be4fdvAZuAvbPWl/PBzo+IiIgkXZFuKmhm15nZq2a2JGtZLzO738yWh1975tKEfDo7zxJeEu7BHBMLgFPNrL+Z7U0wT9W/8yhPREREpCU3AEc2WXYu8IC77ws8ED5vUz6dnTnAx82s8ejNjwkGKq8EXgi/vyiP8kRERKTEGdGP18llzE44J+a6JouPAW4Mv78R+Fwubcj50nN3vwq4Kuv5g2b2ceD/gAxwh7s/lmt5InGKe2LOPz21Oras//vYXrFliUjnVKDxxL3NLHsW7xnuPqON1+zu7v8Jv3+ZYNaFNnXoDsruvhDQdOMiIiKSr9c7Muu5u7uZedtb5nEay8xeNLPxrawfZ2Yv5lqeiIiIJEMXs8gf7fSKme0JEH59Naf65xGwN9CtlfU7AzqeLiIiIoXyF+CE8PsTCMYTtynKiUB3B96NsDwREREpAcWYLsLMZgKHEYztqQMuAC4B/mxmXwdWA1/KpaxWOztmNioMavQFM6tqZtNewCTg6VxCRUREJBmC++LE39tx9+NaWJX3hONtncb6FHBh+HDgC1nPsx+nA28C/y/fChTDffPnMbR6ENWDq7h02iWpyktrVtx5cbft3bfe4KpzT+H8Lx3O9yeOZsW/aguWleb9mNa2aT8mMy/utknLLLg/YAsrzboTTP5pwIvAmWx7fsyBt9296bXwsRk2rMYffSK3i8IymQwfGfJh7r73fioqK/nkwcO58Q8z2W/IkILULc68tGbFnRdFVr6Xnl/7o2+z7wEHMeqYSWx+v4GGTRvZaZfuOb02n0vPk7YfSzUvrVlx56ltLRs5ooba2oUlMdd4973280+ce0Pk5c479eDajlyNlY9Wj+y4+xvuvtrdVxEc5ZkVPs9+vFTMjk6+nlywgIEDq9hnwADKy8uZMHESd83NaXxTyeelNSvuvLjb9u7bb/L8ogUcMn4iAGXblefc0clXmvdjWtum/ZjMvLjbJq3L+Wosd3/Y3V8FMLMqMxsZHvlJlLVr66ms7Lf1eUVFJfX19anIS2tW3Hlxt+31tWvYpeeuXHfRWVz4laO44aff5b2NhRnrn+b9mNa2aT8mMy/uthVaZ5r1vPFeOi8AzwGPAMPC5X3MbIWZHRtFpcysh5ndamb/NrNl4Z2aRVJpSybD6ueW8KkvHM+FN99D+Q47cs+Nvy12tUREUiOfmwoeBtxBME/FjwjG8QAQHvF5geCKrChMB+a5+2CCyUeXRVQufftWUFe3Zuvz+vo6Kioqoiq+qHlpzYo7L+629eyzBz377MGA/Q8EoObwo1j93JI2XtU+ad6PaW2b9mMy8+JuW6EVY9bzKOVzZOeHwDPACOA3zaz/J/CxjlYoPDU2CrgWwN0b3H1DR8ttVDN8OCtWLGfVypU0NDQw+5ZZjB3X4o2hE5WX1qy48+JuW/dd+9CrT19eXv0CAMsWPkrfffYtSFaa92Na26b9mMy8uNtWSEY4GWjE/+KUz00FhwM/dPctLZxrqwP2iKBO+wCvAdeb2UeBWuAMd38neyMzmwpMBejXv3/OhZeVlXHF9Cs5euwYMpkMJ0yewpDq6giqXfy8tGbFnRd32wD+76wLmfHDM8lsfp/effsx5QeXFSQnzfsxrW3TfkxmXjF+j0jLWr30/AMbmr0DnO3uV5nZrgQdkiPc/cFw/bnAue7eo0MVMqsBHgdGuvsTZjYdeNPdf9DSa/K59FwkDpr1XEQ6opQuPe+x134+6vybIi937skHlcal500sAw5pZf04gtNcHVUH1Ln7E+HzW4ng9JiIiIh0Tvl0dq4Fjg3no2h8nZvZTmb2K+DjwIyOVsjdXwbWmNmgcNFoYGlHyxUREZF2KMBl53Ffep7zmB13/62ZjQSuBi4nuHPyTGBXoCtwvbv/MaJ6fQv4o5mVE9y5+WsRlSsiIiJ5KsZEoFHKa9Zzdz/ezG4DjgcGEwzSfgK4yd1vi6pS7v40EMt5PBEREUm3nDo7ZrYjMAF4zt3vILjfjoiIiKScAV0Sfmgn1zE77xGcvjqwgHURERERiVxOR3bCe+usAT5U4PqIiIhIiUn4gZ28rsa6EfiKmW1fqMqIiIiIRC2fAcqPAV8Anjazq4DlwDZTM7v7IxHVTUREREpA3JeKRy2fzs79Wd9PJ7j0PJuFy7p2tFIiIiJSGooxcWfU8uns6F43IiIikji5Xnq+PbAS+I+7Ly9slURERKSUJP3S81yP7GSAB4DvEIzVEZFWxDk5535n3x1b1rJLx8aWJSISlVwvPd9sZi8TjMsRERGRTiTpf/zzufR8NvAlM8vnNSIiIpJwnWYiUOAa4FPA/Wb2S1q+9PyliOomIiIi0mH5dHaWEFxabsBhrWynS89FRERSIpgbq9i16Jh8Ojs/Ztt764iIiIiUtJw7O+5+YQHrISIiIqWoCGNsotYpBxvfN38eQ6sHUT24ikunXZKqvLRmxZ2Xprb9fNJQnvzxEcw7Z9TWZd87ejB/PfdQ7j37EH73tWHsskM+B3lzl6b92Fmy4s5T2yQOeXV2zKyLmX3NzP5iZkvCx1/MbHJSrtLKZDKcefppzJl7L4sWL2X2rJksW7o0FXlpzYo7L21tu21BHZNnLPjAsn88/zpjpj3CZy/9Oytfe4dTj6iKLK9R2vZjZ8iKO09tS47GKSOifMQp5w6Kme1IcGPBa4CjgO7h4yjgWuCvZrZDISoZpScXLGDgwCr2GTCA8vJyJkycxF1z56QiL61ZceelrW0LXlzHhnfe/8Cyvz/3OpktwRC8RavXs0eP6H9007YfO0NW3HlqW3Ik/dLzfI7GfB84FLgc2M3d+7l7P6A3cBnBFVrnR17DiK1dW09lZb+tzysqKqmvr09FXlqz4s5Lc9ua86UR/Xh42WuRl5vm/ZjWrLjz1DaJSz6dnYnAn939HHdf37jQ3Te4+3eBPwPHdbRCZjbIzJ7OerxpZmd2tFwR2dZpR1SxOePcWatfwiLSvMZLz6N+xCmfzk4l8FAr6x8Ot+kQd3/O3Q9w9wOAYQQ3Lryjo+U26tu3grq6NVuf19fXUVFREVXxRc1La1bceWluW7YvDq/k8Oo+nPmHRQUpP837Ma1ZceepbRKXfDo7G4DWRjFWhdtEaTTwgruvjqrAmuHDWbFiOatWrqShoYHZt8xi7LjxURVf1Ly0ZsWdl+a2NRo1eDdOPnwAJ12zkE3vbylIRpr3Y1qz4s5T25Ij6WN28rne9H7gNDO7393nZ68ws88ApxDMnxWlScDM5laY2VRgKkC//v1zLrCsrIwrpl/J0WPHkMlkOGHyFIZUV0dS2WLnpTUr7ry0tW36Vw7g4Kpd6blzOY9dcDi/nLecU0YPpLysCzefchAAi1Zv4Puzl0SWCenbj50hK+48tS05kn2XHTD33G6KbGZ7AU8CuwKLgGfDVdXAgcDrwEFRHYUxs3JgLVDt7q+0tu2wYTX+6BMLo4gVSZz9zr47tqxll46NLUukMxs5ooba2oUl0cfoPaDax/9sVuTlXn/c0Fp3r4m84Gbkcwfl1WZWA1wMHA18LFz1FsHRl/MingT0s8BTbXV0REREpHDMoEvC76Cc121Tw87Mly042bZbuPg1z/XwUH6Oo4VTWCIiIiK5atc94sPOzasR12UrM9sZ+DRwcqEyREREJDcJP7DT+tVYZlZhZi+b2eVtbPcLM1trZrtHUSl3f8fdd3X3N6IoT0RERNov6VdjtXXp+SlAOfCjNra7ENg+3F5ERESkZLTV2TkSuM3d32xto3D9bECXaoiIiKRM2icC/TBQm2NZT4fbi4iIiJSMtgYolwMNOZbVQHAqS0RERFLCsMRfet7WkZ1XgX1zLKuKAl6hJSIiIp2Lmf0/M3vWzJaY2Uwz26E95bTV2XkcmGhmrR4BMrPtCKZ2+Gd7KiEiIiIlqgDjdXI5UGRmFcDpQI277w90Jehr5K2tzs7vgb2B68PpG5qrzHbAtcBe4fYiIiKSIkW89LwM2DE86LITwTRSeWv1iI27P2Bm1wJfBz5hZjcBzwBvArsQzIn1FYIO0TXu/mB7KiEi7RfnfFU9j7gotiyA9X/9Qax5IlI63L3ezC4DXgI2Ave5+33tKSuXOyhPBf4DnAVcAGRPDWHAJuAnBPfaERERkZRp6zRQO/U2s+xZvGe4+4zGJ2bWEzgG2AfYAMw2s+Pd/Q/5BrXZ2Qmnhvihmf2a4D46+wMfIji6swS4291fyzdYREREOrXX25j1/AhgZWMfw8xuBz4BRN/ZaRSG3ZBvgIiIiCSXQezTO4ReAg42s50ITmONBha2/pLmtWsiUBEREek8uhShr+PuT5jZrcBTwGZgETCj9Vc1T50dERERKUnufgHBeOEOUWdHREREWlWMIztRKtAA69J23/x5DK0eRPXgKi6ddkmq8tKaFXee2tZ+vzvnaFbf8W0WXn/y1mXnTx7FC7PP4PFrTuLxa05izIiqyHMhXfuxWFlx56ltEodO19nJZDKcefppzJl7L4sWL2X2rJksW7o0FXlpzYo7T23rmJvnPcMx5/xpm+W/vvUJDj7xag4+8WrmP7Ei0kxI334sRlbceWpbMgR3PC7aTQUj0ek6O08uWMDAgVXsM2AA5eXlTJg4ibvmzklFXlqz4s5T2zrm0cUvse6tjZGWmYu07cdiZMWdp7ZJXPLu7JjZKDP7iZldbWaDw2XdwuU9oq9itNauraeyst/W5xUVldTX16ciL61ZceepbYXxjc8PZ8G1U/ndOUfTo1u75vJrVVr3oz6Pycwr5s9aIXSx6B+x1j/XDc2sq5ndAvwNOA+YAvQNV28G7gROjaJSUc1yKiKl4eo5tQz5vysZceIMXv7v21xy6qeLXSURyUMxJgKNUj5Hdr4LfBH4NrAfwX2GAHD3TcAdwFEdrVCUs5w2p2/fCurq1mx9Xl9fR0VFRVTFFzUvrVlx56lt0Xt1/Tts2eK4w3V3P0XNfn3bflGe0rof9XlMZl6xftakefl0dr4K3OTu04HXm1m/DBgYSa0imuW0OTXDh7NixXJWrVxJQ0MDs2+Zxdhx46Mqvqh5ac2KO09ti94evbpt/f6YTw5m6croZ5hJ637U5zGZecX6WSsEA7qYRf6IUz732dkbuLyV9RuAnh2qDbnPcmpmUwkmKaVf//45l19WVsYV06/k6LFjyGQynDB5CkOqqzta7ZLIS2tW3HlqW8fc+IPPc8gBe9G7+06smH0GF13/MKMO2IuhVXvg7qx++Q2+dfndkWZC+vZjMbLizlPbJC4WzPOZw4ZmrwGXufvPzWxX4DXgCHd/MFx/CfBld+/XWjk55PQEbgMmEs5yCtza2iynw4bV+KNPtGu6DBHJQ88jLoo1b/1ffxBrnkipGDmihtrahSVxK789993fvzb99sjLvXjsoNo2JgKNTD6nsf4BHG/NXBwfdlCmEAxe7qits5y6+/tA4yynIiIiUgSdaYDyT4F9gQeBceGyj5rZyQSTdO0MRHGLyK2znIYdq9EE44FERERE8pbzmB13X2hmXwSuAa4PF19GMHbpVeDz7t7h20NGOcupiIiIdIwVYUBx1PKaCNTd7zazvYFP87/Lz5cD89393agqFdUspyIiIiJ5z3ru7u8Bd4UPERERSbmEH9jJvbNjZl2B7bOP4ITTQ3wd6AXMcvd/RV9FERERkfbL58jO74GDgf0BzGw74FGC01kA3zazj7v709FWUURERIop7rmsopbP1VifBP6S9fxYgo7OaQSXhr8CnBtd1URERKTYOtsdlPcEVmY9Hws86+6/BTCzGcDJEdZNREREpMPy6ewYwaScjQ4juOFfo/8AfSKok4iIiJSQpA9Qzuc01kpgDICZjSQ40pN9x+S+wBvRVU1ERESk4/I5snM98AszWwJUENxIcH7W+hHAvyOsm4iIiBSbJX+Acj6dnenALsDnCO5qfF7jZejhxKAHE9xRWURSKu6JOXsO/2ZsWeufvDK2LJGkMZLd28lnuggHLgofTdf9F43XERERkRKU9x2UmzKz3kBPd18eQX1ERESkhASXnhe7Fh2T8wBlM/tqeHl59rKLCe6v828ze9TMdom6giIiIiIdkc/VWCeTdSTIzGqA7wJ/B64GDgK+HWntREREpOi6WPSPOOVzGqsKmJ31fAKwDviMuzeYmQNfAn4UYf1EREREOiSfIzvd+eB9dEYDf3X3hvD5QqB/VBUrpPvmz2No9SCqB1dx6bRLUpWX1qy489S2ZGT97oIvs/qBi1k4+7wPLD9l0qE8ffv3qb31fH56xjGR50K69mMx89S2ZDCzyB9xyqez8zKwL4CZ7QYcQHAKq1E3IBNd1Qojk8lw5umnMWfuvSxavJTZs2aybOnSVOSlNSvuPLUtOVk3z32cY077zQeWjarZl3GHfYSDJl7CsGN/yi9veiDSTEjffixWntqWDI0DlJN8Giufzs6DwGlmdhZwA+DA3VnrBwH10VWtMJ5csICBA6vYZ8AAysvLmTBxEnfNnZOKvLRmxZ2ntiUn69GnXmDdG+9+YNnUCYdw2fX30/D+ZgBeW/92pJmQvv1YrDy1TeKST2fnhwTzX00DPgtc7O6rAMysDPgi8HDUFYza2rX1VFb22/q8oqKS+vrC9dHizEtrVtx5alvysrJV7dWHkQcO5JGbzuK+a85g2JDoz66neT+qbcnLKjgL5saK+hGnfG4qWGdm1cAQ4A13fylr9U7AVOCZKCplZmcAJxEcPbva3X8ZRbkikn5lXbvQq/vOjPrqZdRU78Ufpk1hv3EXFrtaIlJEed1U0N0zwL+aWf4mEMnxOTPbn6CjcxDQAMwzs7vcfUUU5fftW0Fd3Zqtz+vr66ioqIii6KLnpTUr7jy1LXlZ2epf2cCdDzwNwMJnV7Nli9O7Zzdej/B0Vpr3o9qWvKw4dEn4tOf5nMbaysy6mVmlmfVv+oigTvsBT7j7u+6+meDU2BciKBeAmuHDWbFiOatWrqShoYHZt8xi7LjxURVf1Ly0ZsWdp7YlLyvb3IcWc+jwDwNQ1b8P5duVRdrRgXTvR7UteVmFloYBynkd2TGzScD3CTokLenaoRrBEuCn4eSiG4GjCC5rj0RZWRlXTL+So8eOIZPJcMLkKQypro6q+KLmpTUr7jy1LTlZN148mUOG7UvvHt1YMe8iLvrdPdx45z/5/YVfZuHs82h4P8OJP7w50kxI334sVp7aJnGxYH7PHDY0+xxwO/A8wZVZ3wD+RNBh+hywGLjb3Tt8U0Ez+zpwKvAO8Czwnruf2WSbqQTjhOjXv/+w519Y3dFYESkxmvVcOquRI2qorV1YEueO+g/+iJ997V8iL/f0Tw6odfeayAtuRj6nsc4ClhHcX+eH4bLr3H0SUENw6fnTUVTK3a9192HuPgpYT9DBarrNDHevcfea3XrvFkWsiIiIpFA+nZ2hwI3uvgnYEi7rCuDuS4AZwPeiqJSZ9Qm/9icYr/OnKMoVERGRfBldCvCIUz5jdroC/w2/3xh+7Z61/jnglCgqBdwWjtl5HzjN3TdEVK6IiIh0Mvl0duqAvQDcfaOZvQoMA24N1w8iGGPTYe5+SBTliIiISMcY8d8EMGr5dHYeA47gf+N1/gKcaWYbCU6HnQbMjbZ6IiIiUlRFuFQ8avl0dq4CPm9mO7r7RuB8ghv/XRiuf5ZgELOIiIhIychnuogngSeznr8GHGBmQwlmO1/m7ltaer2IiIgkU9LvoJzXTQWb4+6Lo6iIiIiISCF0uLMjIiIi6ZXqAcpm9mI7ynN3H9iB+oiIiEiJKdZpLDPrAVwD7A84MMXd/5lvOa0d2XkpLFhERESkGKYD89z9WDMrB3ZqTyEtdnbc/bB2VkxERERSpBgHdsysOzAKmAzg7g1AQ3vK0pgdESlZcU7OWXnSrNiyAOqunhRrnkgJ6m1mC7Oez3D3GVnP9wFeA643s48CtcAZ7p73DYxbnRvLzLqa2SVm9o02tjvFzH5mlvQhTCIiIpLNCDoLUT+A1xsn9A4f2R0dCA7IfAz4rbsfSDBLw7ntaUNbE4EeD5xN1v11WrAA+C5wXHsqISIiItJEHVDn7k+Ez28l6Pzkra3OzpeAv7p7bWsbhevno86OiIhIuhiYWeSPtrj7y8AaMxsULhoNLG1PE9rq7AwD/ppjWX8DatpTCRERESldVoBHjr4F/NHMFgMHAD9rT/3bGqDcC3g1x7JeC7cXERER6TB3f5oIDqS01dl5C+idY1m7Am93rDoiIiJSSozkz43V1mmsZ4HP5FjWp8PtS9598+cxtHoQ1YOruHTaJanKS2tW3HlqW/KyCp03fcpBLJv+Of5+0ZFbl537+Y/w8I+P5G8/GsPs7xzGHj12iDSzUZr2YzGz4s6Lu23SsrY6O7cDR5jZMa1tZGbjCTo7t0VVsULJZDKcefppzJl7L4sWL2X2rJksW9qu8U4ll5fWrLjz1LbkZcWRN+sfK5n4i4c/sOzKe5dx6A/n8akL5nPfM/WcNX7/yPIapW0/Fisr7ry421ZoRRyzE4m2Oju/B1YAfzazn5rZ3tkrzWxvM/sJ8Gfg+XD7kvbkggUMHFjFPgMGUF5ezoSJk7hr7pxU5KU1K+48tS15WXHk/fP511j/9gdv3vr2ps1bv99p+zLco59hJ237sVhZcefF3bZCM4v+EadWOzvuvhEYC6wEvge8YGbrzewlM1sPvACcF64f5+6bCl3hjlq7tp7Kyn5bn1dUVFJfX5+KvLRmxZ2ntiUvqxh5jc77wkd45vLxHHvwXlxy55LIy0/zflTbJC5tHdnB3VcQXO51BvAPIAPsEX79e7j8Y+7+Qj7BZnadmb1qZkuylvUys/vNbHn4tWc+ZYqIxO1nt/+Lj37nL9z6+GpOHL1vsasjUgDR32Mn7gkX2uzsALj7Jnf/tbsf6u693b08/HpYuHxjO7JvAI5ssuxc4AF33xd4gHbeFro1fftWUFe3Zuvz+vo6Kioqoo4pSl5as+LOU9uSl1WMvKZu/edqxg2rjLzcNO9HtU3iklNnpxDc/RFgXZPFxwA3ht/fCHwu6tya4cNZsWI5q1aupKGhgdm3zGLsuPFRxxQlL61ZceepbcnLKkYewIDdu239/rMHVrD8P29FnpHm/ai2JUMB58aKTanNer67u/8n/P5lYPeWNjSzqcBUgH79++ccUFZWxhXTr+TosWPIZDKcMHkKQ6qrO1LnkslLa1bceWpb8rLiyJtx8scZObgPvbptz+LLx/PzO5dwxNA9qdpjF7Y41P33Hb5z48K2C8pT2vZjsbLizou7bdI6K8TVAzmHB1d33eXu+4fPN7h7j6z16929zXE7w4bV+KNPRP9LRkQ6j8qTZsWaV3f1pFjzJFlGjqihtnZhSdzJb+CQj/rFf7o38nInHlhR6+6xTDNVtNNYLXjFzPYECL/mOlWFiIiIFEja77MTt78AJ4TfnwAk96YEIiIiUhKKNmbHzGYChwG9zawOuAC4hOAGhl8HVgNfKlb9REREBDBiR4mApQAAIABJREFUv1Q8akXr7Lj7cS2sGh1rRURERCTVSu1qLBERESkhjZeeJ5k6OyIiItKqpJ/GSnpnTURERKRVOrIjIiIirUr2cR0d2REREZGU05EdERERaVXCh+zoyI6IiIikm47siIiISIuCS8+TfWhHnR0REeKfmLPn8G/GlrX+yStjy5J00mksERERkRKmIzsiIiLSCsMSfhpLR3ZEREQk1XRkR0RERFqV9DE76uyIiIhIi9JwNVanPI113/x5DK0eRPXgKi6ddkmq8tKaFXee2pa8rLjzCp31uwu+zOoHLmbh7PM+sPyUSYfy9O3fp/bW8/npGcdEngvp2o/FzIu7bdKyTtfZyWQynHn6acyZey+LFi9l9qyZLFu6NBV5ac2KO09tS15W3HlxZN0893GOOe03H1g2qmZfxh32EQ6aeAnDjv0pv7zpgUgzIX37sVh5cbetoCw4jRX1I06drrPz5IIFDBxYxT4DBlBeXs6EiZO4a+6cVOSlNSvuPLUteVlx58WR9ehTL7DujXc/sGzqhEO47Pr7aXh/MwCvrX870kxI334sVl7cbZPWdbrOztq19VRW9tv6vKKikvr6+lTkpTUr7jy1LXlZcefF3bZGVXv1YeSBA3nkprO475ozGDakf+QZad6PaW5boenITjuZ2XVm9qqZLclaNsHMnjWzLWZWU6y6iYiUorKuXejVfWdGffUyzrviTv4wbUqxqySSCMU8snMDcGSTZUuALwCPFCq0b98K6urWbH1eX19HRUVFoeJizUtrVtx5alvysuLOi7ttW3Ne2cCdDzwNwMJnV7Nli9O7Z7dIM9K8H9PctkKzAvyLU9E6O+7+CLCuybJl7v5cIXNrhg9nxYrlrFq5koaGBmbfMoux48anIi+tWXHnqW3Jy4o7L+62NZr70GIOHf5hAKr696F8uzJej3jcTpr3Y5rbVkgGdLHoH3FK7H12zGwqMBWgX//cz1uXlZVxxfQrOXrsGDKZDCdMnsKQ6upCVTPWvLRmxZ2ntiUvK+68OLJuvHgyhwzbl949urFi3kVc9Lt7uPHOf/L7C7/Mwtnn0fB+hhN/eHOkmZC+/VisvLjbJq0zdy9euNnewF3uvn+T5Q8BZ7n7wlzKGTasxh99IqdNRURKgmY9l9aMHFFDbe3CkriT36D9D/Df3hr9bQ5G79e71t1jGZ/b6a7GEhERkc4lsaexREREJB5JnxurmJeezwT+CQwyszoz+7qZfd7M6oCPA3eb2fxi1U9EREQCSb8aq2hHdtz9uBZW3RFrRURERCTVdBpLREREWtR46XmSaYCyiIiIpJqO7IiIiEgr4h9jEzV1dkRERKRlRZi4M2o6jSUiIiKpps6OiIiItMoK8Mg526yrmS0ys7vaW391dkRERKSUnQEs60gB6uyIiIhIi4JLzy3yR07ZZpXAWOCajrRBA5RFRIogzsk5j7rqsdiyAO459ROx5kli9Taz7Fm8Z7j7jCbb/BI4B9ilI0Hq7IiIiEirCnQx1uutzXpuZuOAV9291swO60iQOjsiIiLSuuJcej4SGG9mRwE7AB8ysz+4+/H5FqQxOyIiIlJy3P177l7p7nsDk4AH29PRAR3ZERERkTboDsoiIiIiBeTuDwEPtff16uyIiIhIqzRdRALdN38eQ6sHUT24ikunXZKqvLRmxZ2ntiUvK+68NGWdPXogt504nGu/fMDWZbtsX8a0zw3hpq8eyLTPDaHb9l0jzwV9RpKimHdQjkKn6+xkMhnOPP005vz/9u48Tqu67v/46y2L4gKiuDHgAqgISiig5gqVO0pq/lwy8XYBf+VdluVdWdmtdWeamj+1XFHLAm/SIjFFS21xY3EhxQ0RlUElxcQt0fHz++OcoctxGGaGc84115n3k8f1mOuc68x5n+91XVzXZ77fs9xyGw/PncfUKZN5Yt68UuSVNavoPLet9rKKzitb1own/sE3p310nUePrOPhF9/guF88zMMvvsHRI/plmgl+j1hxOl2xM2vmTAYOHMRWAwbQvXt3jjjyKKbfMq0UeWXNKjrPbau9rKLzypY1d/Eylv3rg4/M233ABsx4YgkAM55Ywh4DN8g0E/weqSk13rXT6YqdxYvr6dev/4rpurp+1NfXlyKvrFlF57lttZdVdF5Zsyr1XrsbS995H4Cl77xP77W7ZZ7h94gVpWrFjqRJkpZIeqxi3vmSnpQ0V9JvJa1fre0zM7N/i6j2Fli1JB0x2f8rUjV7dq4D9m8y705g+4gYBjwNfCvr0L5961i06MUV0/X1i6irq8s6pip5Zc0qOs9tq72sovPKmlXp9XfeZ4O0N2eDtbvxz3ffzzzD7xErStWKnYj4C7C0ybw7IqJx4PgBIPM94kaOGsX8+c+w8LnnWL58OVNvnMJBYw/JOqYqeWXNKjrPbau9rKLzyppV6b4FS9lvu40B2G+7jbl3wdJV/Ebb+T1SI5Qcep71rUgd+Tw7JwA3ruxBSROACQD9N9+81Svt2rUrF118KQcftB8NDQ2MP/4Ehgwdutob2xHyyppVdJ7bVntZReeVLes7+23NJ/r1otdaXbnxhBFc98CLTJ5Tz/cO2IYDhm7MK8ve4+zbns40E/weqSU1fpodFFUciJW0JTA9IrZvMv9MYCRwWLRiA0eMGBn3Pjh7VYuZmXVKB/7svkLz/vDF3QrNK6PddxnJnDmzO0SNMWTYjnHD7/+c+XpHbNVrTktXPc9Sh+vZkXQ8MBb4dGsKHTMzM8tZhyi72q9DFTuS9gfOAPaOiHeqvT1mZmZW+6pW7EiaDIwG+khaBJxFcvTVmsCdSvZeeiAiTqnWNpqZmVnxh4pnrWrFTkQc3czsawrfEDMzM2uRLwRqZmZm1oF1qH12zMzMrGOpxlXKs+aeHTMzMys19+yYmZlZy2q8a8c9O2ZmZlZq7tkxMzOzFvnQczMzMys1H3puZmZm1oG5Z8fMrOSKvjDnT+6ZX1jW10cPKiyrM6vxjh337JiZmVm5uWfHzMzMVq4EZxV0sWNmZmYtqvWjsTyMZWZmZqXmnh0zMzNbKeFDz2vSHTNuZ9jQbRk6eBDnn3duqfLKmlV0nttWe1lF55U1q8i8f7y4gMsmHrzi9oNxw7nv5mtzy4Nyv262coqIam/DahsxYmTc++DsVi3b0NDADkO24dbb7qSuXz/22HUU198wme2GDMll24rMK2tW0XluW+1lFZ1X1qys8tpz6PmHDQ2cf/QeTLzkN6y/SV2rf68th57X0uu2+y4jmTNndofoT9n+EzvF1Nv+mvl6h9StOyciRma+4mZ0up6dWTNnMnDgILYaMIDu3btzxJFHMf2WaaXIK2tW0XluW+1lFZ1X1qxq5DVa8PB9bLDZ5m0qdNqqzK+btazTFTuLF9fTr1//FdN1df2or68vRV5Zs4rOc9tqL6vovLJmVSOv0d/vuZUdxozNNaPMr1vulMOtQFUrdiRNkrRE0mMV886RNFfSI5LukNS3WttnZmbF+OD95Tx5/11sv/cB1d4UWwnl8K9I1ezZuQ7Yv8m88yNiWEQMB6YD38s6tG/fOhYtenHFdH39Iurq8us2LTKvrFlF57lttZdVdF5Zs6qRB/DMrL+w2aAhrNu7T645ZX7drGVVK3Yi4i/A0ibzllVMrgNkvvf0yFGjmD//GRY+9xzLly9n6o1TOGjsIVnHVCWvrFlF57lttZdVdF5Zs6qRBzD37ukMy3kIC8r9uuVNyv5WpA53nh1JPwSOA94AxrSw3ARgAkD/zTdv9fq7du3KRRdfysEH7UdDQwPjjz+BIUOHruZWd4y8smYVnee21V5W0XllzapG3vJ33+HZOfcy7rRzcstoVObXzVpW1UPPJW0JTI+I7Zt57FvAWhFx1qrW05ZDz83MLF++6vnq62iHnt8842+Zr3fbzdbxoefAr4DDq70RZmZmnZ6PxsqOpK0rJscBT1ZrW8zMzKwcqrbPjqTJwGigj6RFwFnAgZK2BT4EngdOqdb2mZmZWWNHTIcYUWu3qhU7EXF0M7OvKXxDzMzMrNQ63NFYZmZm1oFU4VDxrHWofXbMzMzMsuaeHTMzM2tRjXfsuNgxMzOzVajxasfDWGZmZlZqLnbMzMysBXlc83zVXUWS+ku6W9I8SY9L+kp7W+BhLDMzM+uIPgBOj4iHJK0HzJF0Z0TMa+uKXOyYmZlZi6px6HlEvAS8lN5/U9ITQB3gYsfMzKqryItz9v5M/ldLb/T6H79bWFZHkuOlrPpIqryK95URcWWz25BcOHxH4MH2BLnYMTMzs2p4tTVXPZe0LnATcFpELGtPkIsdMzMza1mVDj2X1I2k0PlVRNzc3vX4aCwzMzPrcCSJ5JqZT0TEhauzLhc7ZmZm1qJqHHoO7A58AfiUpEfS24Ht2X4PY5mZmVmHExF/I6MBtE7Zs3PHjNsZNnRbhg4exPnnnVuqvLJmFZ3nttVeVtF5Zc0qOi/vrMvPOJjnf/s1Zl87ccW8M4/fi2enfoUHrj6ZB64+mf12yefosaJftzxJ2d+K1OmKnYaGBk778peYdsttPDx3HlOnTOaJeW0+ZL9D5pU1q+g8t632sorOK2tW0XlFZP3y9kcZd8avPzb/kt88yK4nXcWuJ13FjAfnZ5oJxb9ueVMOtyJ1umJn1syZDBw4iK0GDKB79+4cceRRTL9lWinyyppVdJ7bVntZReeVNavovCKy7p37AkvffDfTdbZG0a+btazTFTuLF9fTr1//FdN1df2or68vRV5Zs4rOc9tqL6vovLJmFZ1XdNsqnXLoKGZeM4HLzziY9dddK/P1V7NtmcthCKvTDGNJmiRpiaTHmnnsdEkhqU81ts3MzMrrqmlzGHLMpexy0pW8/NpbnPvFfaq9SZazavbsXAfs33SmpP7AvsALeYT27VvHokUvrpiur19EXV1dHlGF55U1q+g8t632sorOK2tW0XlFt63Rktff5sMPgwiYdOtDjNyub+YZ1Wpbfmp7r52qFTsR8RdgaTMPXQScAUQeuSNHjWL+/GdY+NxzLF++nKk3TuGgsYfkEVV4Xlmzis5z22ovq+i8smYVnVd02xptusG6K+6P22Mw8577R+YZ1WpbHkTtD2N1qPPsSBoH1EfEo8rpmejatSsXXXwpBx+0Hw0NDYw//gSGDB2aS1bReWXNKjrPbau9rKLzyppVdF4RWdd/91D2HL4FfXqtzfypX+Gca//MXsO3YNigTYkInn/5Df7zglszzYTiXzdrmSJy6UBpXXhyFdPpEbG9pLWBu4F9I+INSQuBkRHx6kp+dwIwAaD/5puPePrZ54vZaDMz6zDKetXz3XcZyZw5s6t0RaqP+sSOI+K2u+/PfL11vdec05oLgWahIx2NNRDYCng0LXT6AQ9J2rS5hSPiyogYGREjN+qzUYGbaWZmZrWkwwxjRcTfgY0bp1fVs2NmZmbFKHofm6xV89DzycD9wLaSFkk6sVrbYmZmZuVVtZ6diDh6FY9vWdCmmJmZWQtaeZXyDqvDDGOZmZlZB1XbtU6H2kHZzMzMLHPu2TEzM7MW1XjHjnt2zMzMrNzcs2NmZmYrVY3LO2TNxY6ZmZm1qNaPxvIwlpmZmZWae3bMzMysZbXdseOeHTMzMys39+yYmVnNKvJK5L2PuKqwrPcWdKzLQtZ4x457dszMzKzc3LNjZmZmLfKh52ZmZlZi8qHnZmZmZh2Ze3bMzMxspUTtD2N1yp6dO2bczrCh2zJ08CDOP+/cUuWVNavoPLet9rKKzitrVtF5ZWrb5afuxfPXHcvsiw//2GNfOWQH3v3tyWy43pqZZlrrdLpip6GhgdO+/CWm3XIbD8+dx9Qpk3li3rxS5JU1q+g8t632sorOK2tW0Xlla9sv73qacWff9rH5/TZch08P78cLS97MLMvaptMVO7NmzmTgwEFsNWAA3bt354gjj2L6LdNKkVfWrKLz3Lbayyo6r6xZReeVrW33znuZpW++97H5552wK2f+4kEis6TiNV4MNMtbkTpdsbN4cT39+vVfMV1X14/6+vpS5JU1q+g8t632sorOK2tW0XllblujsTtvweKl7/D3hUtzzbGWVa3YkTRJ0hJJj1XM+76kekmPpLcDq7V9ZmZmq6NH9y6ccfhwzp48u9qbstqUw78iVbNn5zpg/2bmXxQRw9PbH7IO7du3jkWLXlwxXV+/iLq6uqxjqpJX1qyi89y22ssqOq+sWUXnlbltAAM27ckWm6zHzIsO58krjqJuw3W4/4LD2GT9HrllWvOqVuxExF+Awvv1Ro4axfz5z7DwuedYvnw5U2+cwkFjDylFXlmzis5z22ovq+i8smYVnVfmtgE8/sLrbHH8DQyeOIXBE6dQ/9rbfPL0m3nln+/mlpmLHPbXKXqfnY54np1TJR0HzAZOj4jXm1tI0gRgAkD/zTdv9cq7du3KRRdfysEH7UdDQwPjjz+BIUOHZrHdVc8ra1bReW5b7WUVnVfWrKLzyta26782hj2H9qVPz7WYf9XRnDPlIa7/01OZrd/aTxHV2z9c0pbA9IjYPp3eBHgVCOAcYLOIOGFV6xkxYmTc+2Dtj4mamVnHVehVz+/5IR++vrBDnMpvpxEj48/3zsx8vT17dJkTESMzX3EzOlTPTkS80nhf0lXA9CpujpmZmQE1fmmsjnXouaTNKiYPBR5b2bJmZmZmrVG1nh1Jk4HRQB9Ji4CzgNGShpMMYy0EJlZr+8zMzCxR61c9r1qxExFHNzP7msI3xMzMzEqtQ+2zY2ZmZh1PrV/13MWOmZmZtajGa52OtYOymZmZWdbcs2NmZmYtq/GuHffsmJmZWam52DEzM7MWVeuq55L2l/SUpPmSvtne7fcwlpmZma2UqM7RWJK6AJcB+wCLgFmSfh8R89q6LvfsmJmZWUe0MzA/IhZExHJgCjCuPSsqRc/OQw/NebVHNz3fjl/tQ3Lh0SKUNavoPLet9rKKznPbai+r6LxaaNsWeWxIezz00JwZPbqpTw6rXktS5VW8r4yIKyum64AXK6YXAbu0J6gUxU5EbNSe35M0u6grrpY1q+g8t632sorOc9tqL6vovDK3LQ8RsX+1t2F1eRjLzMzMOqJ6oH/FdL90Xpu52DEzM7OOaBawtaStJHUHjgJ+354VlWIYazVcuepFnNXB8ty22ssqOs9tq72sovPK3LbSiIgPJJ0KzAC6AJMi4vH2rEsRkenGmZmZmXUkHsYyMzOzUnOxY2ZmZqXmYsdqilSN83jmS9I6BWZtWsbn0MysJZ2q2JG0raRPSuqWnoa6iMyicgZJGilpzQKyhkraW9KGeWeleXtI+gJARESeX9aSDpb0lbzW30zeOODHkjYuIGs/4Ld89FDOvLJ2lfSF9Gf3AvK2Tt//axT1f65JfmkLyKLbVqbnUlKPam+DJTrN0ViSDgP+h+QY/XpgtqTrImJZTnnbRMTTEdEgqUtENOSRk2aNJWnba8DLks6KiKdzyjoA+DGwAOgm6cSIeDmnrDWAtYErkkmtExGXpwXPGhHxYcZ5+wLnAN/Icr0t5O1N8lz+Z0QsyTlr3zRrfeB0ILeCTtIhwA+Ah0lO7f4t4Jkc8z4L/Dcwn+Rsq09Luj4i3s4xcxdgLeCdiJjVWIRHTkd8SOqZ12dVM1k7kfy/Wx4RM/NqU0XeJ4FeQENE3JlnXvr5tVFE/CKvjIqs/YBhki6JiH/lnWct6xQ9O5K6AUcCJ0bEp4FpJH/d/peknjnkjQUekfRrgMaCJ+ucNGs34HxgfESMAV4H2n1l2FVkjQYuBk6KiM8Cy4Ht88gCiIgPI+It4HrgGmA3SV9tfCzLrPR5/CUwISLulNRL0haS1s4yp4kRwNVpXl9J+0jaRVKvLEMkfQb4GfB5YGtgO0l7ZZlRkbUh8CXgmIgYDywDhkvaWNJaOeVNBI6OiMOBucB/AF+TtF7WeWnmAcANJM/ntyVdA/n1OqZ/qP01fW/k+pmdfnZdA0wAvi5pYs55BwKXA58CTksL5cbHMn0u017vU4Ar0h7V3KTvkfOAWU0LnTL1XNWSTlHspHqSfNBD0pU/HegGHJPlmy/d/+JU4DRguaQbIN+CB/hxRDyc3j8L2CCn4axXgIkRMVPSpiTXKDlV0hWSPpfjf+IPSIrT64GdJV0o6UdKZPUefg14H9gs/QL9HfBz4Loc2/ZBxf3fACeQvHcuk9Q7w5wuwHHp+SnWAZ4ChkIuH7wfAD2AwekfEqOB44CfAt9R9vsnfQCsC2wKEBGTgIUk1yIam3FW47D0eODsiJiQ3h8s6TdpfqYFj6Qtga8BS4CvAjvl9f9M0o4kPcTHR8RxwFRgcB5Zad5OwNnAKRFxBklPII1Dulk/lxHxHsnn/jTgp5LGp3mZfg9KGkLyx8VlEXGPpA2V7EKxQ7oduQ7FW/M6RbETEe8DFwKHSdoz7RX4G/AIsEfGWW+TfGn9Gvg6yYXOVhQ8WWalHgRuhhUfxGuSXECuZzovs/1qIuKJiLg7nTwR+Fnaw3M/8DmSL5g8TANejog/AbNJ/jrrGYlMengi4ingIOAi4FGS128scDtwOJBl8dHobuBkSVOAqyLiaJJi9S2Sq/1mIiJmRMR96dDfP4FbgbMk7ZD1kEFEvAH8P5KhqzuAayPiYOBqklO9D8oh71fACUr2Efoh8B4wD/hMlllpXgPpl3I6vSwidgc2kXRFOi/L5/RD4MyI2IekTd8DRkj6yC4IGX159iD5P/1oOv0wsLuk/jl9OXcFTo2I+yVtQPK5eTJwgaRLILvnMu3dh6RovInk8+o7kn4MXJTxH6I9gNuADyXtD9xIUtRdmHW7rA0iolPcSMbXTyU5k+VeFfPvAobnmLshyX+uG9LpnYDBOWV1Jfkr90/p9OdJeid6FPD8/gHYKad19wWuJfkgfIbkA/8Wkl6mrLOGkHwAV867Pa/3CHAw8BxJT0HjvKuAY3N+vc4mKUgErJHD+nuTDK+OrZh3E3BIDlm90vf6JODCivnTSYriLDK2qbh/LPAYsHnFvD4kvXNDc8jrVXH/u+l7f1Q6vUPGWRulP7uQ7LdzS+NzCGydQ9u6kPzR/SWSoXhIrnR9NzA6y6x0eitgcnr/6yRD8Zfl0K7dSf5wepbkjzOR9E7/Edgzizzf2vj6VHsDCm1s8gH8JZKqu7EL+nFgk5xz+6Rf1k+mX9b9cs67DvgRMCeLD8Nm1q8m04enWZvm2KazgReAg9PpMUD/At4zjW3L5T1CUqAeR7LD94npbTYwsIB2/Q3okmPGAen7fl/gEOAhYMsc89aouH8ccB+wTgbrHQu8A0ypmHcOyc7QlQXPFGDnDPMmV8zrXnH/uyQ9j+eS7KO0ccZtW6PxZ/pZ2RP4Ask1iXpn3bZ0/ppNpq8Bdsso69cV83qT9Dz+H5Kesu+QDGEfmcN7ZGfg0CbLXQfsurrvEd/a8RpVewMKbzB0T78op6RvvB0Lyv0q8HIexUdFhtL2PZsWBpn8JdZC3prpl/PjwPY5Z/UHRlRMZ94b0cxzeUL6gZjJX+uryNuJZH+JC/J8jzTJ/N+ci4/1gS8Dfya5ts0nCmpX4+uWRa/HOiQ9exPSz4vKAuQckiHPicCZaeZWGefdUPHYmhX37wEWr04bV5HVhWSfxqkkQ5CzgSE5tq1rxf3DSC4AuUVOWeeSDHUenk7vDQzKMKuyuOpRcf/w1W2Xb+2/ddprY6VjtBEZH9WzkqzeJF8sp0fE3ALyjic5CqBdF0xrQ043YB/g2Uj2ecldnof3Ns0h+RB8OSKezDuvSEU9hxV565H0BhZ16PQWQLeImJ/R+vqSHFW2FsmRQ+9Hsn8Vkg4l2Tl6BPDTiHgsh7x/RcSxFY9vQ7IfyPHx7/1r8sr6HbANSQ/Fav8fbykv/TyZQFKsjl/d57KZrOURcUy6Q/KgiHg6q/8LzWS9FxGfr3h8PMluFP+RxXvE2q7TFjtFk7RWFHSuhaK/zMw6i3SH/ytJvjiPljQUeCsins85792IOFbScJJhpXkR8WrOWVuTHMZ/Q0TMyzJrJXmDgf2AW7MqVFvIGk5SkDyRZc5KsrYjGU24PSIWZJ1nreNix8ysDST1Idn5ejeS4Z7REbGogLxPpnl7R8TinLN2T2ftGRGv5JHVJG83kqHjvSK/k5Q2fR7H5PW6NdOuvSPipTyyrHU6xaHnZmZZSXtU5pIcBXZonoVOk7z1gcPyKnSaZPUk2aclt0KnSV6vNC+XQqdJVuPzmNvr1ky7XOhUmYsdM7M2SPfBOxDYNyL+XqY8t632sqx1PIxlZtZGRe6DV3Se21Z7WbZqLnbMzMys1DyMZWZmZqXmYsfMzMxKzcWOmZmZlZqLHTMzMys1FztmBZB0j6SF1d6OMmruufXzbWaVXOyYtZOktSWdJumvkpZKel/SK5L+IOl4SV2rvY15kbRQUlTclqfzrpbUv9rb15z0NTmt2tthZsUr7YexWZ4kDQJuJblI4h+BHwGvAhsDnwGuBYYAZ1RrGwuwCPhWen89YDTJRRwPlDQs62s3tdG+JKfpr3Q8sCXw06I3xsyqy8WOWRtJ6gFMBwaQnAr+5iaL/FjSKGBU4RtXrDci4oaK6Z9LWkJ6dWeSawN9THp16y55nnAtIpbntW4zqz0exjJru5OAbYELmil0AIiIWRHxs5ZWImlnSddJelrSO5LelHSvpEObWba/pEmSnpf0nqQlku6TNL5imTXSYbW56bqWSXpK0jVpgVG5vpGSfivp1XR9T0k6M4Ohtxnpz0FpzvfTYa6hki6UtAj4F7Br+viakr4t6XFJ/5L0T0m3SNqxmeegt6Sr0m1+O90vZ0RzG9F0n530/t7AFk2G30anj7f6tTCz2uOeHbO2+1z688rVXM+hwGDgf4HngQ2B8cDNkj4fEb8GSAuQO4E64GfA0yQXGBwG7Alcn67vTOBs4BbgcqAB2Ao4BFgTeD9d30HAzcB84AJWx0pCAAAE9klEQVRgKcmVoM8GhgNHrEabtk5/Nh3C+hXwbpoXwEtpAXY7yZWhfwlcmrbrZOBeSXtFxOx0m7uRFFKj0mUfSLf1j8Brrdiu00iGGvsAX62Y/0T6s1WvhZnVJl8uwqyNJL0GdI2IXm34nXuALSNiy4p560TE202WWxt4GGiIiCHpvGHAo8B/RcR5LWQ8BKzV+HsrWWYtYCFJwfSpiPig4rGvAhcCYyLinlW0ZyFJ8bJnOqtxn52LgHWAHSPiMUnfB84C/gx8ZiV5+0fEjIr5PYHHgAURMTqdNwG4Ajg7Is6qWPa0NPP5Js/tPXz8+f7YvIrHWvVamFlt8jCWWdv1BN5c3ZVUfrmmR3ZtCKwN3AVsl37pA7yR/hwjaeMWVvkGUCdpjxaW2QfYhGQH6vUl9Wm8AX9Il9m3lU0YDPwjvS0AJpH06IyLiMeaLPvTykIndSzwJDCnyXZ0J+nJ2iPdPwrgsyQ9VRc0WcfPgWWt3N6VasNrYWY1yMNYZm23jKQnY7WkhcsPgHEkR3E1tT6wLCKel/RDkiOfXpL0CPAnYGpEzKpY/tvA74C/SloM3ENyxNhvKnbY3S79OamFTduklU1YSDLkBLAcWBwR81ey7NPNzNsO6EFSLK1MH+BFkp3BX4qIjxQ2EfGepAVA71Zuc7Na+1qsToaZVY+LHbO2ewzYS9KAiFjQnhVIEnAHyRf+xcBskp6ZBpIjmY6houc1Ir4jaRJwEMnQ0UnANySdFxH/lS5zv6SBwH7AmPR2DPAdSXtExFL+fTj2N4BHVrJ5i1vZjLcj4o+tXPadZuYJ+DvwtRZ+r6VCKBNtfS3MrPa42DFru5uAvUgKjm+3cx3DgE/QZB8UAEknNfcLaWF1CXBJuu/NDOAMSRdExJJ0mbfS7bspXdcXgcuAE0kOBX8mXV1bCpW8PANsBNwVER+uYtkFwL6Selb27khak6TX5/VW5K1sB8U2vxZmVlv814pZ210NPAV8XdK45haQNCItNFamoXHRJr+3PcmRQZXzejU9dDw9R03jkUS90+X6NJPzUPpzg/TnDGAJ8E1JGzRdWFIPSas9RNdKvwA2ZSU9O5Iqh9OmAV2A05ss9n9J9qFqjbeA3mlPTqVWvxZmVpvcs2PWRhHxjqSxJPvD/E7SHSQ71L5G0lMxhmQoaaVHTpEUKo+T9MysTVI8bQNMJBnaqTx/zBjgSkk3pcu9lT5+EvBgRDzVuE5JDwAPkgxFbQZMINmfZkq67W9LOo5k356n0qGx+ST7pAwGDiP5gr+nXU9O21xMssP0+ZI+RbIz8DJgc+DTJOfjGZMue23alu9J2gq4H9iR5DD5Z2ndZ9kDwFjgUkn3kRQ5d9G218LMapCLHbN2iIj56YnvJgKHk5zjZl2Sc9bMJjlHy0rPzRIRDen5bn6SLrsOyb5A40mGVCq/YB8lOS/OaODzJD0cLwD/w0ePTroAOBD4Msn5apaQfMH/KCIercieoeQMz98kOSJqI5JhoGdJDgWf29bnoz0i4v30Ofgi8AXgv9OHFgMz+ff5g4iI5ZL2IRmK+yzJcz6LpFj6CcllIFblIpIhr88Bp5D0bI+JiHva8FqYWQ3yeXbMzMys1LzPjpmZmZWaix0zMzMrNRc7ZmZmVmoudszMzKzUXOyYmZlZqbnYMTMzs1JzsWNmZmal5mLHzMzMSs3FjpmZmZXa/wd7xPB1WYVmWQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}